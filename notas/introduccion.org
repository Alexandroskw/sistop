#+SETUPFILE: ../setup_notas.org
#+TITLE: Sistemas Operativos — Introducción

* ¿Qué es un sistema operativo?

El /sistema operativo/ es el principal programa que corre en toda
computadora de propósito general.

Hay sistemas operativos de todo tipo, desde muy simples hasta
terriblemente complejos, y entre más casos de uso hay para el cómputo
en la vida diaria, más variedad habrá en ellos.

No nos referiremos al sistema operativo como lo ve el usuario final, o
como lo vende la mercadotecnia — El ambiente gráfico, los programas
que se ejecutan en éste, la diferencia en el uso son sólo –y si mucho–
/consecuencias/ del diseño de un sistema operativo. Más aún, con el
mismo sistema operativo –como pueden constatarlo comparando dos
distribuciones de Linux, o incluso la forma de trabajo de dos usuarios
en la misma computadora– es posible tener /entornos operativos/
completamente disímiles.

La importancia de este curso radica no sólo en comprender los
mecanismos que emplean los sistemas operativos para cumplir sus tareas
sino en que comprendan estos mecanismos para evitar los errores más
comunes al programar, que pueden resultar desde un rendimiento
deficiente hasta pérdida de información.

Como desarrolladores, comprender el funcionamiento básico de los
sistemas operativos y las principales alternativas que nos ofrecen en
muchos de puntos, o saber diseñar algoritmos y procesos que se ajusten
mejor al sistema operativo en que vayamos a correrlo, puede resultar
en una diferencia cualitativa decisiva en nuestros productos.

* Funciones y objetivos de los sistemas operativos

El sistema operativo es el único programa que interactúa directamente
con el hardware de la computadora. Sus funciones primarias son:

- Abstracción :: Los programas no deben tener que preocuparse de los
                 detalles del acceso a hardware, o de la configuración
                 particular de una computadora. Un sistema operativo
                 se encarga de proporcionar una serie de abstracciones
                 para que los programadores puedan enfocarse en
                 resolver las necesidades particulares de sus
                 usuarios. Un ejemplo de la abstracción sería el que
                 la información esté organizada en /archivos/ y
                 /directorios/ (en uno o muchos /dispositivos de
                 almacenamiento/).

- Manejo de recursos :: Una sistema de cómputo puede tener a su
     disposición una gran cantidad de /recursos/ (memoria, espacio de
     almacenamiento, tiempo de procesamiento, etc.), y los diferentes
     /procesos/ que corran en él /compiten/ por ellos. Al gestionar
     toda la asignación de recursos, el sistema operativo puede
     implementar políticas que los asignen de forma efectiva y acorde
     a las necesidades establecidas para dicho sistema.

- Aislamiento :: Cada proceso y cada usuario no tendrán que
                 preocuparse por otros que estén usando el mismo
                 sistema — Idealmente, su /experiencia/ será la misma
                 que si el sistema estuviera exclusivamente dedicado a
                 su atención (aunque fuera un sistema menos
                 poderoso).

		 Para implementar correctamente las funciones de
		 aislamiento hace falta que el sistema operativo
		 cuente con ayuda del hardware.

* Evolución de los sistemas operativos

** Proceso por lotes (/batch processing/)

Los antecedentes a lo que hoy comprendemos como sistema operativo
podemos encontralros en la primer automatización de proceso de
diferentes programas que encontramos en los primeros centros de
cómputo: Cuando en los 1950 aparecieron los dispositivos
perforadores/lectores de tarjetas de papel, el tiempo que una
computadora estaba improductiva esperando a que estuviera lista una
/tarea/ (como se designaba a una ejecución de cada determinado
programa) para ejecutarse disminuyó fuertemente: Los programadores
entregaban sus /tambaches/ o lotes de tarjetas perforadas (en inglés,
batches) a los operadores, quienes las alimentaban a los dispositivos
lectores, que lo cargaban en memoria en un tiempo razonable, iniciaban
y monitoreaban la ejecución, y producían los resultados.

En esta primer época en que las computadoras se especializaban en
tareas de cálculo intensivo y los dispositivos que interactuatan con
medios externos eran prácticamente desconocidos, el rol del sistema
/monitor/ o /de control/ era básicamente asistir al operador en la
carga de los programas y las bibliotecas requeridas, la notificación
de resultados, y la contabilidad de recursos empleados para su cobro.

Los sistemas monitor se fueron sofisticando al implementar
protecciones que evitaran la corrupción de /otros trabajos/ (por
ejemplo, lanzar erróneamente la instrucción /leer siguiente tarjeta/
causaría que el siguiente trabajo encolado perdiera sus primeros
caracteres, corrompiéndolo e impidiendo su ejecución), o que entraran
en un ciclo infinito, estableciendo /alarmas/ (/timers/) que
interrumpirían la ejecución de un proceso si éste duraba más allá del
tiempo estipulado. Estos monitores implicaban la modificación del
hardware para contemplar dichas características de seguridad — Y ahí
podemos ya hablar de la característica básica de gestión de recursos
que identifica a los sistemas operativos.

Cabe añadir que el tiempo de carga y puesta a punto de una tarea
seguía representando una parte importante del tiempo que la
computadora dedicaba al proceso: Un lector de cintas rápido procesaba
del órden de cientos de caracteres por minuto, y a pesar de la
lentitud relativa de las computadoras de los 1950s ante los estándares
de hoy (las mediríamos por miles de instrucciones por segundo, KHz, en
vez de miles de millones como lo hacemos hoy, GHz), esperar cinco o
diez minutos con el sistema completamente detenido por la carga de un
programa moderado resulta a todas luces un desperdicio.

** Sistemas en lotes con dispositivos de carga (/spool/)

Una mejoría natural a este último punto fue la invención del /spool/:
Un mecanismo de entrada/salida que permitía que una computadora de
propósito específico, mucho más económica y limitada, leyera las
tarjetas y las fuera convirtiendo a cinta magnética, un medio mucho
más rápido, teniéndola lista para que la computadora central la
cargara cuando terminara con el trabajo anterior. Del mismo modo, la
computadora central guardaría sus resultados en cinta para que equipos
especializados la leyeran e imprimieran para el usuario solicitante.

La palabra /spool/ (/bobina/) se tomó como /acrónimo inverso/ hacia
/Simultaneous Peripherial Operations On-Line/, /Operación simultánea
de periféricos en línea/.

** Sistemas multiprogramados

A lo largo de su ejecución, un programa normalmente pasa por etapas
con muy distintas características: Al estar en un ciclo fuertemente
dedicado al cálculo numérico, el sistema opera /limitado por el CPU/
(/CPU-bound/), mientras que al leer o escribir resultados a medios
externos (incluso a través de /spools/) el límite es impuesto por los
dispositivos, esto es, opera /limitado por entrada-salida/ (/I-O
bound/). La /programación multitareas/ o los /sistemas
multiprogramados/ buscaban maximizar más aún el tiempo de uso efectivo
del procesador ejecutando varios procesos al mismo tiempo.

El hardware requerido cambió fuertemente. Si bien se esperaba que cada
usuario fuera responsable con el uso de recursos, se hizo necesario
que apareciera la infraestructura de protección de recursos: Un
proceso no debe sobreescribir el espacio de memoria de otro (ni el
código ni los datos), mucho menos el espacio del monitor. Esta
protección la encontramos en la /Unidad de Manejo de Memoria/ (MMU),
presente en todas las computadoras de uso genérico desde los 1990.

Ciertos dispositivos requieren bloqueo para ofrecer acceso
exclusivo/único — Cintas e impresoras, por ejemplo, son de acceso
estrictamente secuencial, y si dos usuarios intentaran usarlas al
mismo tiempo, el resultado para ambos se corrompería. Para estos
dispositivos, el sistema debe implementar otros /spools/ y mecanismos
de bloqueo.

** Sistemas de tiempo compartido

El modo de interactuar con las computadoras cambió fuertemente al
aparecer, durante los 1960s, al extenderse la multitarea para
convertirse en sistemas /interactivos/ y /multiusuarios/, en buena
medida diferenciados de los anteriores por la aparición de las
/terminales/ (primero teletipos seriales, posteriormente equipos con
una pantalla completa como las conocemos hasta hoy).

En primer término, la tarea de programación y depuración del código se
simplificó fuertemente al poder el programador hacer directamente
cambios y someter el programa a ejecución de inmediato. En segundo
término, la computadora /nunca más estaría simplemente esperando a
estar lista/: Mientras un programador editaba o compilaba su programa,
la computadora seguiría calculando lo que otros procesos requirieran.

Un cambio fundamental entre el modelo de /multiprogramación/ y de
/tiempo compartido/ es el tipo de control sobre la multitarea:
(abundaremos al respecto en la sección de /[[./administracion_de_procesos.org][Administración de
procesos]]/)

- Multitarea /cooperativa/ o /no apropiativa/ :: (/Cooperative
     multitasking) La implementan los sistemas multiprogramados: Cada
     proceso tenía control del CPU hasta que éste hacía una llamada al
     sistema (o indicara su /disposición a cooperar/ por medio de la
     llamada =yield=: /ceder el paso/).

     Un cálculo largo no sería interrumpido por el sistema operativo,
     lo que permitía que un error de programador congelara a la
     computadora completa.

- Multitarea /preventiva/ o /apropiativa/ :: (/Preemptive
     multitasking/) En los sistemas de tiempo compartido, el reloj del
     sistema interrumpe periódicamente a los diversos procesos,
     transfiriendo /forzosamente/ el control de vuelta al sistema
     operativo.

Además, fueron naciendo de forma natural y paulatina las abstracciones
que conocemos hoy en día, como el concepto de /archivos/ y
/directorios/, y el código necesario para emplearlos iba siendo
enviado a través de las /bibliotecas de sistema/ y, cada vez más (por
su centralidad) hacia el núcleo mismo del –ahora sí– sistema
operativo.

Más alla del cambio del dispositivo de acceso, un cambio importante
entre los sistemas multiprogramados y de tiempo compartido es la
velocidad del cambio entre una tarea y otra es mucho más rápido: Si
bien en un sistema multiprogramado un /cambio de contexto/ podía
producirse sólo cuando la tarea cambiara de uno a otro modos de
ejecución y el resultado no se vería fuertemente afectado, en un
sistema interactivo, para dar la /ilusión/ de uso directo de la
computadora, el hardware emitiría al sistema operativo
/interrupciones/ (señales) que le indicaran múltiples veces /por
segundo/ para que cambie el /proceso/ activo (como ahora se le
denomina a una instancia de un programa en ejecución).

Diferentes tipos de proceso pueden tener distinto nivel de importancia
— Ya sea porque son más importantes para el funcionamiento de la
computadora misma (procesos de sistema), porque tienen mayor carga de
interactividad (por la experiencia del usuario) o por diversas
categorías de usuarios (sistemas con contabilidad por tipo de
atención). Esto requiere la implementación de diversas /prioridades/
para cada uno de estos.

* Y del lado de las computadoras personales

Si bien la discusión hasta este momento asume una computadora central
con operadores dedicados y múltiples usuarios, en la década de los
1970 comenzaron a aparecer las /computadoras personales/, sistemas en
un inicio verdaderamente reducidos en prestaciones y a un nivel de
precios que los ponían al alcance, primero, de los aficionados
entusiastas y, posteriormente, de cualquiera.

** Primeros sistemas para entusiastas

#+attr_html: height="350"
#+attr_latex: width=0.5\textwidth
#+caption: La /microcomputadora Altair 8800/, primer computadora personal con distribución masiva, a la venta a partir de 1975 ([[http://web.ncf.ca/dunfield/classic.htm][Imagen de Dave Dunfield]])
[[./img/altair.jpg]]

Las primeras computadoras personales tampoco eran distribuídas con
sistemas operativos o lenguajes de programación; la interfaz primaria
para programarlas era a través de /switches/, y para recibir sus
resultados, de bancos de LEDs. Claro está, esto requería conocimientos
especializados, y las computadoras personales eran aún vistas sólo
como juguetes caros.

** La revolución de los 8 bits

La verdadera revolución apareció cuando‚ poco tiempo más tarde,
comenzaron a venderse computadoras personales con salida de video
(típicamente a través de una televisión) y entrada a través de un
teclado. Estas computadoras popularizaron el lenguaje de programación
BASIC, diseñado para usuarios novatos en los 1960, y para permitir a
los usuarios gestionar sus recursos (unidades de cinta, pantalla
posicionable, unidades de disco, impresoras, modem, etc.) llevaban un
software mínimo de sistema — Nuevamente, un proto-sistema operativo.

#+attr_html: height="350"
#+attr_latex: width=0.5\textwidth
#+caption: La /Commodore Pet 2001/, en el mercado desde 1977, una de las primeras con intérprete de BASIC. ([[http://www.classiccmp.org/dunfield/pet/index.htm][Imagen de Dave Dunfield]])
[[./img/commodore_pet.jpg]]

** La computadora para fines "serios": La familia PC

Al aparecer las computadoras personales "serias", orientadas a la
oficina más que al hobby, a principios de los 1980 (particularmente
representadas por la IBM PC, 1981), sus sistemas operativos se
comenzaron a diferenciar de los equipos previos al separar el /entorno
de desarrollo/ en algún lenguaje de programación del /entorno de
ejecución/. El rol principal del sistema operativo ante el usuario era
para poder administrar los archivos de las diversas aplicaciones a
través de una sencilla interfaz de línea de comando, y lanzar las
aplicaciones propiamente.

La PC de IBM fuer la primer arquitectura de computadoras personales en
desarrollar una amplia familia de /clones/, computadoras compatibles
diseñadas para correr con el mismo sistema operativo, y que
eventualmente capturaron prácticamente el 100% del
mercado. Prácticamente todas las computadoras de escritorio y
portátiles en el mercado hoy derivan de la arquitectura de la IBM PC.

#+attr_html: height="350"
#+attr_latex: width=0.5\textwidth
#+caption: La computadora IBM PC modelo 5150 (1981), iniciadora de la arquitectura predominantemente en uso hasta el día de hoy. (Imagen de la Wikipedia: /IBM Personal Computer/)
[[./img/ibmpc.jpg]]

Ante las aplicaciones, el sistema operativo (PC-DOS, en las versiones
distribuídas directamente por IBM, o el que se popularizó más, MS-DOS,
en los /clones/) ofrecía la ya conocida serie de interfaces y
abstracciones para administrar los archivos y la entrada/salida a
través de sus puertos. Cabe destacar que, particularmente en sus
primeros años, muchos programas corrían directamente sobre el
hardware, arrancando desde el BIOS y sin emplear el sistema operativo.

** El impacto del entorno gráfico (WIMP)

Hacia mediados de los 1980 comenzaron a aparecer computadoras con
interfaces gráficas basadas en el paradigma WIMP (/Windows, Icons,
Menus, Pointer/; Ventanas, Iconos, Menúes, Apuntador), que permitían
la interacción con varios programas al mismo tiempo. Esto /no
necesariamente/ significa que sean sistemas multitarea — Por ejemplo,
la primer interfaz de MacOS permitía visualizar a varias ventanas
abiertas simultáneamente, pero sólo el proceso que estuviera activo se
ejecutaba.

#+attr_html: height="350"
#+attr_latex: width=0.5\textwidth
#+caption: Apple Macintosh (1984), popularizó la interfaz usuario gráfica (GUI). (Imagen de la Wikipedia: /Macintosh/)
[[./img/mac128.png]]


Esto comenzó, sin embargo, a plantear inevitablemente las necesidades
de concurrencia a los programadores. Los programas ya no tenían acceso
directo a la pantalla para manipular a su antojo, sino que a una
abstracción (la /ventana/) que podía variar sus medidas, y que
requería que toda la salida fuera estrictamente a través de llamadas a
bibliotecas de primitivas gráficas que comenzaron a verse como parte
integral del sistema operativo.

Además, los problemas de protección y separación entre procesos
concurrentes comenzaron a hacerse evidentes: Los programadores tenían
ahora que programar con la conciencia de que compartirían recursos —
Con el limitante (que no tenían en las máquinas /profesionales/) de no
contar con hardware especializado para esta protección: Los
procesadores en uso comercial en los 1980 no manejaban /anillos/ o
/niveles de ejecución/ ni /unidad de administración de memoria/ (MMU),
por lo que un programa /mal comportado/ podía corromper la operación
completa del equipo. Y si bien los entornos que más éxito tuvieron
(Apple MacOS y Microsoft Windows) no implementaban multitarea real, sí
hubo desde el principio sistemas como la Commodore Amiga o la Atari ST
que hacían un multitasking /preventivo/ verdadero.

#+attr_html: height="350"
#+attr_latex: width=0.5\textwidth
#+caption: Commodore Amiga 1000 (1985), computadora con amplias capacidades multimedia y multitarea preventiva, una verdadera maravilla para su momento. ([[http://oldcomputers.net/amiga1000.html][Imagen de /OldComputers.net/]])
[[./img/A1000.jpg]]

Naturalmente, ante el uso común de un entorno de ventanas, los
programas que se ejecutaban sin requerir de la carga del sistema
operativo cayeron lentamente en el olvido.

** Convergencia de los dos grandes mercados

Conforme fueron apareciendo los CPUs con características suficientes
en el mercado para ofrecer la protección y aislamiento necesario
(particularmente, Intel 80386 y Motorola 68030), la brecha de
funcionalidad entre las computadoras personales y las /estaciones de
trabajo/ y /mainframes/ se fue cerrando.

Hacia principios de los 1990, la mayor parte de las computadoras de
arquitecturas /alternativas/ fueron cediendo a las presiones del
mercado, y hacia mediados de la década sólo quedaban dos arquitecturas
principales: La derivada de IBM y la derivada de la Apple Macintosh.

Los sistemas operativos primarios para ambas plataformas fueron
respondiendo a las nuevas características del hardware: En las IBM, la
presencia de Microsoft Windows (originalmente un /entorno operativo/
desde su primer edición en 1985, evolucionando hacia un sistema
operativo completo corriendo sobre una base de MS-DOS en 1995) se fue
haciendo prevalente hasta ser la norma. Windows pasó de ser un sistema
meramente de aplicaciones propias y operaba únicamente por reemplazo
de aplicación activa a ser un sistema de multitarea cooperativa, a ser
finalmente un sistema que requería protección en hardware (80386) e
implementaba multitarea preventiva.

A partir del 2003, el núcleo de Windows en más amplio uso fue
reemplazado por un desarrollo hecho de inicio como un sistema
operativo completo y ya no como una aplicación dependiente de MS-DOS:
El núcleo de Nueva Tecnología (Windows NT), que, sin romper
compatibilidad con los /APIs/ históricos de Windows, ofreció una mucho
mayor estabilidad.

Por el lado de Apple, la evolución fue muy en paralelo: Ante un
sistema ya agotado y obsoleto, el MacOS 9, en 2001 anunció una
nueva versión de su sistema operativo que fue en realidad un
relanzamiento completo: MacOS X es un sistema basado en un núcleo Unix
BSD, sobre el /microkernel/ Mach.

Y otro importante jugador que entró en escena durante los 1990s fue el
software libre, por medio de varias implementaciones distintas de
sistemas tipo Unix — principalmente, Linux y los *BSD (FreeBSD,
NetBSD, OpenBSD). Estos sistemas implementaron, colaborativamente y a
escala mundial, software compatible con el que corría en las
estaciones de trabajo a gran escala, con alta confiabilidad, y
cerrando por fin la divergencia del árbol del desarrollo de la
computación en /fierros grandes/ y /fierros chicos/.

Al día de hoy, la arquitectura derivada de Intel (y la PC) es el claro
ganador de este proceso de 35 años, habiendo conquistado casi la
totalidad de los casos de uso. Hoy en día, la arquitectura Intel corre
desde subportátiles hasta supercomputadoras y centros de datos; el
sistema operativo específico varía según el uso, yendo
mayoritariamente hacia Windows, con los diferentes Unixes concentrados
en los equipos servidores.

En el frente de los dispositivos /embebidos/ (las computadoras más
pequeñas, desde microcontroladores hasta teléfonos y tabletas), la
norma es la arquitectura ARM, también bajo versiones específicas de
sistemas operativos Unix y Windows (en ese órden).

* Organización de los sistemas operativos

Para comenzar el estudio de los sistemas operativos, la complejidad
del tema requerirá que lo hagamos de una forma modular. En este curso
no buscamos enseñar cómo se usa un determinado sistema operativo, ni
siquiera comparar el uso de uno con otro (fuera de hacerlo con fines
de explicar diferentes implementaciones).

Al nivel que vamos a estudiarlo, un sistema operativo es más bien un
gran programa, que ejecuta a otros muchos programas y les expone un
conjunto de interfaces para que puedan aprovechar los recursos de
cómputo. Hay dos formas primarias de organización /hacia adentro/ del
sistema operativo: Los sistemas monolíticos y los sistemas
microkernel. Y si bien no podemos marcar una línea clara a rajatabla
que indique en qué clasificiación cae cada sistema, no es dificil
encontrar líneas base.

- Monolíticos :: La mayor parte de los sistemas operativos
		 históricamente han sido /monolíticos/ — Esto
		 significa que hay un sólo /proceso privilegiado/ que
		 opera en modo supervisor, y dentro del cual se
		 encuentran todas las rutinas para las diversas tareas
		 que realiza el sistema operativo.


- Microkernel :: El núcleo del sistema operativo se mantiene en el
                 mínimo posible de funcionalidad, descargando en
                 /procesos especiales/ las tareas que implementan el
                 acceso a dispositivos y las diversas políticas de uso
                 del sistema.

Las principales ventaja de diseñar un sistema siguiendo un esquema
monolítico es la simplificación de una gran cantidad de mecanismos de
comunicación, que lleva a una mayor velocidad de ejecución (al
requerir menos cambios de contexto para cualquier operación
realizada). Además, al manejarse la comunicación directa como paso de
estructuras en memoria, la mayor acoplación permite más flexibilidad
al adecuarse para nuevos requisitos (al no tener que modificar no sólo
al núcleo y a los procesos especiales, sino también la interfaz
pública entre ellos).

Por otro lado, los sistemas microkernel siguen esquemas lógicos más
limpios, permiten implementaciones más elegantes y facilitan la
comprensión por separado de cada una de sus piezas. Pueden
/auto-repararse/ con mayor facilidad, dado que en caso de fallar uno
de los componentes (por más que parezca ser de muy bajo nivel), el
núcleo puede reiniciarlo o incluso reemplazarlo.

- Sistemas con concepciones híbridas :: No podemos hablar de
     concepciones únicas ni de verdades absolutas. A lo largo del
     curso veremos ejemplos de /concepciones híbridas/ en este sentido
     — Sistemas que son mayormente monolíticos pero manejan algunos
     procesos que parecerían centrales a través de procesos de nivel
     usuario como los microkernel (por ejemplo, los sistemas de
     archivos en espacio de usuario, FUSE, en Linux).

#+attr_html: width="100%"
#+attr_latex: width=0.5\textwidth
#+caption: Esquematización de la arquitectura básica de los sistemas monolíticos, microkernel e híbridos. ([[https://commons.wikimedia.org/wiki/File:OS-structure2.svg][Imagen de la Wikipedia: Monolithic kernel]])
[[./img/monolithic_micro_hybrid.png]]

# Discusión interesante y reciente (diciembre 2012): [[http://tech.slashdot.org/story/12/12/02/1526240/multi-server-microkernel-os-genode-1211-can-build-itself?utm_source=rss1.0mainlinkanon&utm_medium=feed][Multi-server
# microkernel OS Genode 12.11 can build itself]]. Ver también: [[http://genode.org/documentation/general-overview/index][Genode –
# General overview]]

* Estructuras y funciones básicas

Repasaremos brevemente algunos conceptos de arquitectura de
computadoras que nos resultarán fundamentales para abordar el tema que
nos ocupa.

** Jerarquía de almacenamiento

Las computadoras que siguen la arquitectura /von Neumann/, esto es,
prácticamente la totalidad hoy en día podrían resumir su operación
general a alimentar a una /unidad de proceso/ (CPU) con los datos e
instrucciones almacenados en /memoria/, que pueden incluir llamadas a
servicio (y respuestas a eventos) originados en medios externos.

Una computadora von Neumann significa básicamente que es una
computadora de /programa almacenado en la memoria primaria/ — Esto es,
se usa el mismo almacenamiento para el programa que está siendo
ejecutado y para sus datos, sirviéndose de un /registro/ especial para
indicar al CPU cuál es la dirección en memoria de la siguiente
instrucción a ejecutar.

La arquitectura von Neumann fue planteada, obviamente, sin considerar
la posterior diferencia entre la velocidad que adquiriría el CPU y la
memoria. En 1977, John Backus presentó al recibir el premio Turing un
artículo describiendo el /cuello de botella de von Neumann/. Los
procesadores son cada vez más rápidos (se logró un aumento de 1000
veces tanto entre 1975 y 2000 tan sólo en el reloj del sistema), pero
la memoria aumentó su velocidad a un ritmo mucho menor —
Aproximadamente un factor de 50 para la tecnología en un nivel
costo-beneficio suficiente para usarse como memoria primaria.

#+attr_latex: height=0.5\textheight
#+attr_html: height="350"
#+caption: Jerarquía de memoria entre diversos medios de almacenamiento.
#+begin_src dot :file ltxpng/jearquia_memoria.png
digraph G {
	layout = dot;
	node [shape = box];
	rankdir = TB;
	
	Registros ;
	Cache ;
	Principal [label = "Memoria principal"];
	Electr [label = "Disco electrónico"];
	Magnet [label = "Disco magnético"];
	Optico [label = "Disco óptico"];
	Cinta [label = "Cintas magnéticas"];
	
	Registros -> Cache [dir = both];
	
	Cache -> Principal [dir = both];
	
	Principal -> Electr [dir = both];
	Principal -> Magnet [dir = both];
	
	Electr -> Magnet [dir = both];
	
	Electr -> Optico [dir = both];
	Magnet -> Optico [dir = both];
	
        Optico -> Cinta [dir = both];
	Electr -> Cinta [dir = both, minlen=2];
	Magnet -> Cinta [dir = both, minlen=2];
}
#+end_src

#+begin_html
<p align="center">Jerarquía de memoria entre diversos medios de almacenamiento.</p>
#+end_html

Una respuesta parcial a este problema es la creación de una jerarquía
de almacenamiento, yendo de una pequeña área de memoria mucho más cara
hasta un gran espacio de memoria muy económica. En particular, la
relación entre las capas superiores está administrada por hardware
especializado de modo que su existencia resulta transparente al
programador.

#+caption: Velocidad y gestor de los principales niveles de memoria. (Silberschatz, Galvin, Gagne; p.28)
| Nivel           | 1                 | 2              | 3              | 4          |
|-----------------+-------------------+----------------+----------------+------------|
| *Nombre*        | Registros         | Cache          | Memoria princ. | Disco      |
| *Tamaño*        | <1KB              | <16MB          | <64GB          | >100GB     |
| *Tecnología*    | Multipuerto, CMOS | SRAM CMOS      | CMOS DRAM      | Magnética  |
| *Acceso (ns)*   | 0.25-0.5          | 0.5-25         | 80-250         | 5,000,000  |
| *Transf (MB/s)* | 20,000-100,000    | 5,000-10,000   | 1,000-5,000    | 20-150     |
| *Administra*    | Compilador        | Hardware       | Sist. Op.      | Sist. op.  |
| *Respaldado en* | Cache             | Memoria princ. | Disco          | CD o cinta |

** Registros

La memoria más rápida de la computadora son los /registros/, ubicados
dentro de cada /uno de los/ núcleos de cada uno de los CPUs. La
arquitecturas tipo RISC sólo contmplan la ejecución de instrucciones
(excepto, claro, las de carga y almacenamiento a memoria primaria)
entre registros.

Los primeros CPUs trabajaban con pocos CPUs de propósito específico —
Trabajaban más bien con una lógica de /registro acumulador/. Por
ejemplo, el MOS 6502 (en el cual se basaron las principales
computadoras de 8 bits) tenía un acumulador de 8 bits (A), dos
registros índice de 8 bits (X y Y), un registro de estado del
procesador de 8 bits (P), un apuntador al /stack/ de 8 bits (S), y un
apuntador al programa de 16-bit (PC). El otro gran procesador de su
era, el Zilog Z80, tenía 14 registros (3 de 8 bits y el resto de 16),
pero sólo uno era un acumulador de propósito general.

El procesador Intel 8088, en el cual se basó la primer generación de
la arquitectura PC, ofrecía cuatro registros de uso /casi/ general. En
los 1980 comenzaron a producirse los primeros procesadores tipo RISC,
muchos de los cuales ofrecían 32 registros, todos ellos de propósito
general.

Todas las operaciones que el CPU deba realizar reiteradamente, donde
la rapidez es fundamental, se realiza con los operadores cargados en
los registros. Pero, lo que es más importante para nuestro curso: El
estado del CPU en un momento dado está determinado por el contenido de
los registros. El contenido de la memoria, obviamente, debe estar
sincronizado con lo que ocurre dentro de éste — Pero el estado actual
del CPU, lo que está haciendo, las indicaciones respecto a las
operaciones recién realizadas que se deben entregar al programa en
ejecución están todos representados en los registros. Debemos mantener
esto en mente cuando posteriormente hablemos de todas las situaciones
en que el flujo de ejecución debe ser tomado de un proceso y entregado
a otro.

** Interrupciones y excepciones

La ejecución de los procesos podría seguir siempre linealmente, pero
en el modelo de uso de cómputo actual, eso no nos serviría de mucho:
Para que un proceso acepte interacción, su ejecución debe poder
responder a los /eventos/ que ocurran alrededor del sistema. Y los
eventos son manejados a través de las /interrupciones/ y /excepciones/
(o /trampas/).

Cuando ocurre algún evento que requiera la atención del sistema
operativo, el hardware encargado de procesarlo escribe directamente a
una ubicación predeterminada de memoria la naturaleza de la solicitud
(el /vector de interrupción/) y, levantando una solicitud de
interrupción, /roba/ el procesamiento del proceso que estaba siendo
ejecutado. El sistema operativo entonces ejecuta su /rutina de manejo
de interrupciones/ (típicamente comienza grabando el estado de los
registros del CPU y otra información relativa al estado del proceso
desplazado) y posteriormente la atiende.

Las interrupciones pueden organizarse por /prioridades/, de modo que
una interrupción de menor jerarquía no interrumpa a una más
importante — Dado que las interrupciones muchas veces indican que hay
datos disponibles en algún buffer, el no atenderlas a tiempo podría
llevarnos a perder datos.

El sistema operativo puede elegir ignorar (/enmascarar/) a ciertas
interrupciones — Pero hay interrupciones que son /no enmascarables/.

Hacemos la distinción entre interrupciones y excepciones según su
origen: Una interrupción es generada por causas externas al sistema
(un dispositivo requiere atención), mientras que una excepción es una
evento generado por un proceso (una condición en el proceso que
requiere la intervención del sistema operativo). Si bien hay
distinciones sutiles entre interrupciones, trampas y excepciones, al
nivel de discusión que abordaremos basta esta distinción.

Los eventos pueden ser, como mencionamos, indicadores de que hay algún
dispositivo requiriendo atención, pero pueden también provenir del
mismo sistema, como una /alarma/ o /temporizador/ (que se emplea para
obligar a todo programa a entregar el control en un sistema
multitareas) o indicando una condición de error (por ejemplo, una
división sobre cero o un error leyendo de disco).

** Llamadas al sistema

De forma de cierto modo análoga a las interrupciones, podemos hablar
de las llamadas al sistema. El sistema operativo protege a un proceso
de otro, y previene que un proceso ejecutándose en espacio no
privilegiado tenga acceso directo a los dispositivos. Cuando un
proceso requiere de alguna de estas acciones, acede a ellas levantando
una /llamada al sistema/. Las llamadas al sistema pueden agruparse, a
grandes rasgos, en:

- Control de procesos :: Crear o finalizar un proceso, obtener
     atributos del proceso, esperar cierto tiempo, asignar o liberar
     memoria, etc.

- Manipulación de archivos :: Crear, borrar o renombrar un archivo;
     abrir o cerrar un archivo existente; modificar sus /metadatos/;
     leer o escribir de un /descriptor de archivo/ abierto, etc.

- Manipulación de dispositivos :: Solicitar o liberar un archivo;
     leer, escribir o reposicionarlo, y otras varias. Muchas de estas
     llaadas son análogas a las de manipulación de archivos, y varios
     sistemas operativos las ofrecen como una sola.

- Mantenimiento de la información :: Obtener o modificar la hora del
     sistema; obtener detalles acerca de procesos o archivos, etc.

- Comunicaciones :: Establecer una comunicación con determinado
                    proceso (local o remoto), aceptar una solicitud de
                    comunicación de otro proceso, intercambiar
                    información sobre un canal establecido

- Protección :: Consultar o modificar la información relativa al
                acceso de objetos en el disco, otros procesos, o la
                misma sesión de usuario

Cada sistema operativo /expone/ una serie de llamadas al
sistema. Estas son, a su vez, expuestas al programador a través de las
/interfaces de aplicación al programador/ (API), que se alínean de
forma cercana (pero no exacta). Del mismo modo que cada sistema
operativo ofrece un conjunto de llamadas al sistema distinto, cada
implmentación de un lenguaje de programación puede ofrecer un API
ligeramente distinto de otros.

#+attr_latex: width=0.7\textwidth
#+attr_html: height="350"
#+caption: Un API expone una interfaz en un lenguaje de alto nivel hacia una llamada al sistema. (Imagen: /Operating System Concepts Essentials/; Silberschatz, Galvin, Gagne; p.56)
[[./img/llamando_syscall.png]]


*** Llamadas al sistema, arquitecturas y APIs

Cada familia de sistemas operativos distintas llamadas al sistema, y
sus lenguajes/bibliotecas implementan distintos APIs. Esto es el que
distingue principalmente a uno de otro. Por ejemplo, los sistemas
Windows 95 en adelante implementan Win32, Win16 (compatibilidad con
Windows previos) y MSDOS; MacOS implementa Cocoa (aplicaciones MacOS
X) y Carbon (compatibilidad con aplicaciones de MacOS previos), y
Linux y los *BSDs, POSIX (el estándar que define a Unix). El caso de
MacOS X es interesante, porque también implementa POSIX, ofreciendo la
/semántica/ de dos sistemas muy distintos entre sí.

Los lenguajes basados en /máquinas virtuales abstractas/, como Java o
la familia .Net, exponen un API con mucha mayor distancia respecto al
sistema operativo; la máquina virtual se presenta como un
pseudo-sistema operativo intermedio que se ejecuta dentro del real, y
esta distinción se hace especialmente notoria cuando buscamos conocer
los detalles del sistea operativo. Sugiero para este curso emplear
plataformas que presenten de la forma más transparente al sistema
subyacente.

*** Depuración por /trazas/ (trace)

La mayor parte de los sistemas operativos ofrecen programas que, para
fines de depuración, /envuelven/ al API del sistema y permiten ver la
/traza/ de las llamadas al sistema que va realizando un
proceso. Algunos ejemplos de estas herramientas son =strace= en Linux,
=truss= en la mayor parte de los Unixes históricos o =ktrace= y
=kdump= en los *BSD. A partir de Solaris 10 (2005), Sun incluye una
herramienta mucho más profunda y programable para esta tarea llamada
=dtrace=, misma que ha sido /portada/ a otros Unixes (*BSD, MacOS).

La salida de una traza nos brinda amplio detalle acerca de la
actividad realizada por un proceso, y nos permite comprender a grandes
rasgos su interacción con el sistema. El nivel de información que nos
da es, sin embargo, a veces demasiado — Consideren la siguiente
traza, ante uno de los comandos más sencillos: =pwd= (obtener el
directorio actual)

#+latex: {\scriptsize
#+begin_src c
$ strace pwd
execve("/bin/pwd", ["pwd"], [/* 43 vars */]) = 0
brk(0)                                  = 0x8414000
access("/etc/ld.so.nohwcap", F_OK)      = -1 ENOENT (No such file or directory)
mmap2(NULL, 8192, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0xb773d000
access("/etc/ld.so.preload", R_OK)      = -1 ENOENT (No such file or directory)
open("/etc/ld.so.cache", O_RDONLY)      = 3
fstat64(3, {st_mode=S_IFREG|0644, st_size=78233, ...}) = 0
mmap2(NULL, 78233, PROT_READ, MAP_PRIVATE, 3, 0) = 0xb7729000
close(3)                                = 0
access("/etc/ld.so.nohwcap", F_OK)      = -1 ENOENT (No such file or directory)
open("/lib/i386-linux-gnu/libc.so.6", O_RDONLY) = 3
read(3, "\177ELF\1\1\1\0\0\0\0\0\0\0\0\0\3\0\3\0\1\0\0\0po\1\0004\0\0\0"..., 512) = 512
fstat64(3, {st_mode=S_IFREG|0755, st_size=1351816, ...}) = 0
mmap2(NULL, 1366328, PROT_READ|PROT_EXEC, MAP_PRIVATE|MAP_DENYWRITE, 3, 0) = 0xb75db000
mprotect(0xb7722000, 4096, PROT_NONE)   = 0
mmap2(0xb7723000, 12288, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_DENYWRITE, 3, 0x147) = 0xb7723000
mmap2(0xb7726000, 10552, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_ANONYMOUS, -1, 0) = 0xb7726000
close(3)                                = 0
mmap2(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0xb75da000
set_thread_area({entry_number:-1 -> 6, base_addr:0xb75da8d0, limit:1048575, seg_32bit:1, contents:0, read_exec_only:0, limit_in_pages:1, seg_not_present:0, useable:1}) = 0
mprotect(0xb7723000, 8192, PROT_READ)   = 0
mprotect(0xb775c000, 4096, PROT_READ)   = 0
munmap(0xb7729000, 78233)               = 0
brk(0)                                  = 0x8414000
brk(0x8435000)                          = 0x8435000
open("/usr/lib/locale/locale-archive", O_RDONLY|O_LARGEFILE) = 3
fstat64(3, {st_mode=S_IFREG|0644, st_size=1534672, ...}) = 0
mmap2(NULL, 1534672, PROT_READ, MAP_PRIVATE, 3, 0) = 0xb7463000
close(3)                                = 0
getcwd("/home/gwolf/vcs/sistemas_operativos", 4096) = 36
fstat64(1, {st_mode=S_IFCHR|0620, st_rdev=makedev(136, 1), ...}) = 0
mmap2(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0xb773c000
write(1, "/home/gwolf/vcs/sistemas_operati"..., 36/home/gwolf/vcs/sistemas_operativos
) = 36
close(1)                                = 0
munmap(0xb773c000, 4096)                = 0
close(2)                                = 0
exit_group(0)                           = ?
#+end_src
#+latex: }

* Otros recursos

- [[http://cs.gordon.edu/courses/cs322/lectures/history.html][CS322: A Brief History of Computer Operating Systems]]
- [[http://lwn.net/Articles/532771/][Making EPERM friendlier]] (LWN): Explica algunas de las limitantes de
  la semántica POSIX: Falta de granularidad en el reporte de mensajes
  de error (=EPERM=), y =errno= global por hilo.
