#+SETUPFILE: ../setup_notas.org
#+TITLE: Relación con el hardware - Estructuras y funciones básicas

* Introducción 
# <<HW>>

Todos los sitemas de cómputo están compuestos por al menos una unidad de proceso
junto con dispositivos que permiten ingresar datos  (teclado, mouse, micrófono, 
etc) y otros que permiten obtener resultados (pantalla, impresora, parlantes, 
etc). Como vimos antes, una de las funciones del sistema operativo es la de 
abstraer el hardware de la computadora y presentar al usuario una 
versión unificada y simplificada de los dispositivos.  
En este Capítulo veremos la relación que mantiene el sistema operativo 
con el hardware, las funciones que cumplen y algunas abstracciones
comunes utilizadas en sistemas operativos modernos.

* Unidad de Procesamiento

La /unidad de procesamiento/ es la parte fundamental de todo sistema de cómputo.
Es la encargada de ejecutar tanto los programas del usuario como el sistema 
operativo en sí mismo.  La funciones del sistema operativo respecto a la
unidad de procesamiento son: 

- Inicialización :: Luego de ser cargado el sistema operativo debe realizar 
                    varias tareas de inicialización como habilitar 
                    las interrupciones de hardware y software 
                    (excepciones y trampas), configurar el sistema de 
                    memoria virtual (paginación, segmentación), etc.
- Atender las Interrupciones y Excepciones :: Como veremos más adelante, 
                     la unidad de procesamiento 
                     puede encontrar una situación que no puede resolver
                     por sí misma (una instrucción o dirección inválida, 
                     una división por cero, etc) ante lo cual le pasa el
                     control al sistema operativo para que este trate o
                     resuelva esta situación.
- Multiplexación :: En un sistema multiproceso, el sistema operativo es el 
                    encargado de administrar la unidad de procesamiento 
                    dando la ilusión a los procesos que están ejecutando 
                    de forma exclusiva. 


** Jerarquía de almacenamiento


Las computadoras que siguen la arquitectura /von Neumann/, esto es,
prácticamente la totalidad hoy en día[fn:: Algunos argumentarán que
muchas de las computadoras en uso hoy en día siguen la arquitectura
/Harvard modificada/, dado que empleando distintos bancos de memoria
caché, un procesador puede tanto referirse a la siguiente instrucción
como iniciar una transferencia de memoria primaria. Esta distinción no
tiene mayor relevancia para este tema, la referencia se incluye
únicamente por no llevar a confusión.] podrían resumir su operación
general a alimentar a una /unidad de proceso/ (CPU) con los datos e
instrucciones almacenados en /memoria/, que pueden incluir llamadas a
servicio (y respuestas a eventos) originados en medios externos.

Una computadora von Neumann significa básicamente que es una
computadora de /programa almacenado en la memoria primaria/ — Esto es,
se usa el mismo almacenamiento para el programa que está siendo
ejecutado y para sus datos, sirviéndose de un /registro/ especial para
indicar al CPU cuál es la dirección en memoria de la siguiente
instrucción a ejecutar.

La arquitectura von Neumann fue planteada, obviamente, sin considerar
la posterior diferencia entre la velocidad que adquiriría el CPU y la
memoria. En 1977, John Backus presentó al recibir el premio Turing un
artículo describiendo el /cuello de botella de von Neumann/. Los
procesadores son cada vez más rápidos (se logró un aumento de 1000
veces tanto entre 1975 y 2000 tan sólo en el reloj del sistema), pero
la memoria aumentó su velocidad a un ritmo mucho menor —
Aproximadamente un factor de 50 para la tecnología en un nivel
costo-beneficio suficiente para usarse como memoria primaria.

#+attr_latex: height=0.5\textheight
#+label: HW_jerarquia_memoria
#+caption: Jerarquía de memoria entre diversos medios de almacenamiento.
[[./img/dot/jerarquia_memoria.png]]

Una respuesta parcial a estos problemas es la creación de una jerarquía
de almacenamiento, yendo de una pequeña área de memoria mucho más cara
hasta un gran espacio de memoria muy económica. En particular, la
relación entre las capas superiores está administrada por hardware
especializado de modo que su existencia resulta transparente al
programador.

#+caption: Velocidad y gestor de los principales niveles de memoria. (Silberschatz, Galvin, Gagne; p.28)
| Nivel           | 1                 | 2              | 3              | 4          |
|-----------------+-------------------+----------------+----------------+------------|
| *Nombre*        | Registros         | Cache          | Memoria princ. | Disco      |
| *Tamaño*        | <1KB              | <16MB          | <64GB          | >100GB     |
| *Tecnología*    | Multipuerto, CMOS | SRAM CMOS      | CMOS DRAM      | Magnética  |
| *Acceso (ns)*   | 0.25-0.5          | 0.5-25         | 80-250         | 5,000,000  |
| *Transf (MB/s)* | 20,000-100,000    | 5,000-10,000   | 1,000-5,000    | 20-150     |
| *Administra*    | Compilador        | Hardware       | Sist. Op.      | Sist. op.  |
| *Respaldado en* | Cache             | Memoria princ. | Disco          | CD o cinta |

Ahora bien, si bien la relación entre estos medios de almacenamiento
nos resulta natural a nosotros, para una computadora tienen una
realidad completamente distinta: Los registros son parte integral del
procesador, y la memoria está a sólo un paso de distancia (el
procesador puede referirse a ella directamente, de forma transparente,
indicando la dirección desde un programa). El caché no existe para
efectos prácticos: El procesador no hace referencia directa a él, sino
que es manejado por los controladores de acceso a memoria.

Como veremos, el sistema operativo es el encargado de mantener todas estas 
jerarquías de memoria consistentes y de realizar las transferencias entre unas 
y otras.

*** Registros

La memoria más rápida de la computadora son los /registros/, ubicados
dentro de cada /uno de los/ núcleos de cada uno de los CPUs. La
arquitecturas tipo RISC sólo contmplan la ejecución de instrucciones
(excepto, claro, las de carga y almacenamiento a memoria primaria)
entre registros.

Los primeros CPUs trabajaban con pocos registros, muchos de ellos de
propósito específico — Trabajaban más bien con una lógica de /registro
acumulador/. Por ejemplo, el MOS 6502 (en el cual se basaron las
principales computadoras de 8 bits) tenía un acumulador de 8 bits (A),
dos registros índice de 8 bits (X y Y), un registro de estado del
procesador de 8 bits (P), un apuntador al /stack/ de 8 bits (S), y un
apuntador al programa de 16 bits (PC). El otro gran procesador de su
era, el Zilog Z80, tenía 14 registros (3 de 8 bits y el resto de 16),
pero sólo uno era un acumulador de propósito general.

El procesador Intel 8088, en el cual se basó la primer generación de
la arquitectura PC, ofrecía cuatro registros de uso /casi/ general. En
los 1980 comenzaron a producirse los primeros procesadores tipo RISC,
muchos de los cuales ofrecían 32 registros, todos ellos de propósito
general.

#+attr_html: width=444px
#+attr_latex: width=0.6\textwidth
#+label: HW_registros_8086
#+caption: Ejemplo de registros: Intel 8086/8088 (Imagen de la Wikipedia: /Intel 8086 y 8088/)
[[./img/registros_8086.png]]

El compilador [fn:: A veces asistido por instrucciones explíticas por
parte del programador, pero muchas veces como resultado del análisis
del código] busca realizar tantas operaciones que deban ocurrir
reiteradamente, donde la rapidez es fundamental, con sus operadores
cargados en los registros. Pero, lo que es más importante para nuestro
curso: El estado del CPU en un momento dado está determinado por el
contenido de los registros. El contenido de la memoria, obviamente,
debe estar sincronizado con lo que ocurre dentro de éste — Pero el
estado actual del CPU, lo que está haciendo, las indicaciones respecto
a las operaciones recién realizadas que se deben entregar al programa
en ejecución están todos representados en los registros. Debemos
mantener esto en mente cuando posteriormente hablemos de todas las
situaciones en que el flujo de ejecución debe ser tomado de un proceso
y entregado a otro.

La relación de la computadora y del sistema operativo con la memoria principal 
será estudiada en el capítulo \ref{MEM}.

** Interrupciones y excepciones
# <<HW_interrupciones>>

La ejecución de los procesos podría seguir siempre linealmente,
atendiendo a las instrucciones de los programas como fueron escritas,
pero en el modelo de uso de cómputo actual, eso no nos serviría de
mucho: Para que un proceso acepte interacción, su ejecución debe poder
responder a los /eventos/ que ocurran alrededor del sistema. Y los
eventos son manejados a través de las /interrupciones/ y /excepciones/
(o /trampas/).

Cuando ocurre algún evento que requiera la atención del sistema
operativo, el hardware encargado de procesarlo escribe directamente a
una ubicación predeterminada de memoria la naturaleza de la solicitud
(el /vector de interrupción/) y, levantando una solicitud de
interrupción, /detiene/ el proceso que estaba siendo
ejecutado. El sistema operativo entonces ejecuta su /rutina de manejo
de interrupciones/ (típicamente comienza grabando el estado de los
registros del CPU y otra información relativa al estado del proceso
desplazado) y posteriormente la atiende.

Las interrupciones pueden organizarse por /prioridades/, de modo que
una interrupción de menor jerarquía no interrumpa a una más
importante — Dado que las interrupciones muchas veces indican que hay
datos disponibles en algún buffer, el no atenderlas a tiempo podría
llevarnos a perder datos.

Hay un número limitado de interrupciones definidas para cada
arquitectura, mucho más limitado que el número de dispositivos que
tiene un equipo de cómputo actual. Las interrupciones son, por tanto,
generadas /por el controlador del canal/ en que son producidas. Si
bien esto resuelve la escasez de interrupciones, dificulta su
priorización — Con canales de uso tan variado como el USB[fn:: Algunas
arquitecturas, particularmente de sistemas embebidos y por un criterio
altamente económico, están estructuradas íntegramente alrededor de un
bus USB.], una interrupción puede indicar que hay desde un /teclazo/
para ser leído hasta un paquete de red esperando a ser procesado — Y
si bien demorar la atención al primero no llevaría a pérdida notable
de información, no ateneder el paquete de red sí.

El sistema operativo puede elegir ignorar (/enmascarar/) a ciertas
interrupciones — Pero hay interrupciones que son /no enmascarables/.

Hacemos la distinción entre interrupciones y excepciones según su
origen: Una interrupción es generada por causas externas al sistema
(un dispositivo requiere atención), mientras que una excepción es una
evento generado por un proceso (una condición en el proceso que
requiere la intervención del sistema operativo). Si bien hay
distinciones sutiles entre interrupciones, trampas y excepciones, al
nivel de discusión que abordaremos basta esta distinción.

Los eventos pueden ser, como mencionamos, indicadores de que hay algún
dispositivo requiriendo atención, pero pueden también provenir del
mismo sistema, como una /alarma/ o /temporizador/ (que se emplea para
obligar a todo programa a entregar el control en un sistema
multitareas) o indicando una condición de error (por ejemplo, una
división sobre cero o un error leyendo de disco).

Las funciones del sistema operativo respecto a las interrupciones son:

- Administrar el hardware manejador de interrupciones ::
                                  Esto incluye el enmascarado y desenmascarado 
                                  de las interrupciones, configurar y asignar
                                  interrupciones a cada dispositivo, 
                                  notificar al manejador cuando la interrupción
                                  ya ha sido atendida, etc.
- Abstraer las interrupciones ::  El sistema operativo oculta a los programas de
                                  usuario la existencia de interrupciones de
                                  hardware ya que estas son dependientes de la
                                  arquitectura del procesador. En cambio el
                                  sistema operativo lo comunica de una forma
                                  unificada a través de distintos mecanismos,
                                  por ejemplo mensajes o señales o detiendo el
                                  proceso que espera la acción relacionada con
                                  esa interrupción y continuando su ejecución
                                  cuando esta ocurre.
- Punto de entrada al sistema operativo :: Como veremos más adelante en la 
                                Sección \ref{HW_SYSCALLS}, muchos procesadores y
                                sistemas operativos utilizan las interrupciones
                                como medio por el cual un proceso de usuario
                                realiza una llamada al sistema.
                                Por ejemplo, en Linux para arquitecturas x86
                                el programa de usuario genera la interrupción
                                0x80 para iniciar una llamada al sistema.
                                En arquitecturas más recientes como x86_64,
                                MIPS y ARM esto ha sido reemplazado por una
                                instrucción especial =syscall=.
- Atender excepciones y fallas :: Como dijimos antes, durante la ejecución de un
                                  programa pueden ocurrir situaciones anómalas como, por
                                  ejemplo, una división sobre cero. Desde el punto de 
                                  vista del CPU, esto es similar a una
                                  interrupción de hardware y debe ser tratada
                                  por el sistema operativo. Dependiendo de la
                                  causa de la excepción, el sistema operativo
                                  tomará acción para resolver en lo posible
                                  esta situación. En muchos casos las
                                  excepciones resultan en una señal
                                  enviada al proceso, y este último es el
                                  encargado de tratar la excepción.
                                  En otros casos la falla o excepción son
                                  irrecuperables (una instrucción inválida o
                                  un error de bus) ante la cual el sistema  
                                  operativo terminará el proceso que la generó. 
                                  En el capítulo \ref{MEM} veremos a mucho
                                  mayor detalle un tipo de excepción muy importante que debe tratar el 
                                  sistema operativo: El fallo de paginación.




* Terminales
Las terminales son dispositivos electrónicos utilizados para ingresar datos
y emitir resultados dentro de un sistema de cómputo. 
Las primeras terminales utilizaban tarjetas
perforadas e impresiones en papel. Debido a su limitada velocidad e
imposibilidad de "editar" el papel ya impreso, este tipo de terminales
fue cediendo terreno ante la aparación sobre principios de los 1970 
de las terminales de texto con pantalla de video y teclado.

Conceptualmente una terminal de texto es dispositivo mediante el cual
la computadora envía y recibe un flujo de caracteres del usuario.
Las operaciones más complejas, como edición, borrado y movimiento
en general son tratadas con secuencias de escape, esto es, una serie
de caracteres simples que tomados en conjunto representan una acción
a realizar en la terminal. 

Durante la década del 70 también se desarrollaron terminales 
gráficas las cuales podían representar imágenes junto 
con texto. Junto con la inclusión del ratón o "mouse"
estas terminales dieron lugar a lo que hoy conocemos
como Interfaz Gráfica de Usuario (/Graphical User Interface/ o /GUI/)
y a los sistemas de ventana.

En los sistemas operativos modernos es común referirse al /emulador de
terminal/, un programa especializado ya sea para tener múltiples
instancias o para ejectuar una terminal de texto dentro de una
terminal gráfica. Estos programas se denominan de esta forma dado que
sólo replican el comportamiento de las terminales (que eran
originalmente equipos independientes), siendo únicamente un programa
que recibe la entrada del usuario a través del teclado enviándola al
sistema operativo como un flujo de datos, y recibe otro flujo de datos
del sistema operativo, presentándolo en una representación adecuada al
usuario.

* Dispositivos de almacenamiento

El almacenamiento en memoria primaria es /volátil/, esto es, se pierde
al interrumpirse el suministro eléctrico. Si bien esto no era muy
importante en la época definitoria de los conceptos que ahora estamos
presentando, dado que el tiempo total de vida de un conjunto de datos
en almacenamiento bajo el control del procesador iba únicamente desde
la entrada y hasta el fin de la ejecución del trabajo del usuario,
desde la década de 1960 la expectativa de poder almacenar en la
computadora información /a largo plazo/ y con expectativas razonables
de permanencia.

De las muchas tecnologías de almacenamiento, la que ha dominado
fuertemente durante los últimos 40 años ha sido la de los discos
magnéticos[fn:: Veremos en la sección \ref{FS_estado_solido} detalles
acerca de las tecnologías de almacenamiento /en estado sólido/, que
pueden poner fin a esta larga dominación.]. El acceso a disco (miles
de veces más lento que el acceso a memoria) no es realizado
directamente por el procesador, sino que requiere de la comunicación
con controladores externos, con lógica propia, que podrían ser vistos
como computadoras independientes de propósito limitado.

El procesador no puede referirse directamente más información que la
que forma parte del almacenamiento primario — Esto es, de la memoria
RAM. Veremos a continuación, en las secciones \ref{HW_interrupciones}
(/Interrupciones y excepciones/) y \ref{HW_dma} (/Acceso directo a
memoria/), cómo es que se efectúan dichas referencias.

Los dispositivos de almacenamiento (discos, memorias flash, cintas) 
pueden ser vistos como una región donde la computadora puede 
leer y escribir una serie de bytes que preservarán su valor incluso 
luego de apagada la computadora.

A nivel de hardware el sistema operativo  no accede al 
dispositivo de almacenamiento byte por byte, sino que
estos se agrupan en /bloques/ de tamaño fijo.
El manejo de estos bloques (adminstración de bloques libres,
lectura y escritura) es una tarea fundamental del sistema operativo.
El sistema operativo también es el encargado de presentar abstracciones 
como la de archivos y directorios al usuario. Esto lo veremos en el capítulo
\ref{FS}.

* Relojes y temporizadores
Todas las computadoras viene acompañadas de uno o varios relojes y 
temporizadores que son utilizados para funciones varias como 
mantener la hora del sistema actualizada, implementar alarmas tanto para los
programas de usuario como para el sistema operativo, ejecutar
tareas de mantenimiento periódicas, cumplir con requisitos
temporales de aplicaciones de tiempo real, etc.

Mantener el tiempo correctamente dentro del sistema operativo
es algo crucial. Permite establecer un orden cronológico 
entre los eventos que ocurren dentro del sistema, por ejemplo
la creación de un archivo, y de otro o el tiempo consumido
en la ejecución de un proceso. 

Por otro lado si el sistema operativo utiliza una política de 
planificación de procesos preventiva (capítulo \ref{PLAN}), 
como la /Ronda/ (/Round Robin/), debe interrumpir al proceso
en ejecución luego de cierta cantidad de unidades de tiempo. Esto
se implementa haciendo que el temporizador de la computadora
genere interrupciones periódicamente, lo cual luego invocará al planificador
de procesos.

* Canales y puentes

Los diferentes componentes de un sistema de cómputo se comunican a
través de los diferentes /canales/ (generalmente se hace referencia a
ellos por su nombre en inglés, en inglés, /buses/). Al nivel más
básico, los canales son líneas de comunicación entre el procesador
y los demás componentes del chipset[fn:: Los chips que forman parte de
un equipo, casi siempre provistos por el mismo fabricante que el
procesador mismo], a los cuales a su vez se conectan los diferentes
dispositivos del sistema — Desde aquellos que requieren mayor
velocidad, como la misma memoria, hasta los puertos más sencillos.

Un chipset provee distintos buses, con un agrupamiento lógico
según la velocidad requerida por sus componentes y otras
características que determinan su topología.

#+attr_html: height=618px
#+attr_latex: width=0.5\textwidth
#+label: HW_northbridge_southbridge
#+caption: Diagrama de la comuniacación entre componentes de un sistema de cómputo basado en /puente norte/ y /puente sur/
[[./img/northbridge_southbridge.png]]

Hoy en día, el acomodo más frecuente[fn:: La separación aquí descrita
ha sido característica de las computadoras x86 de los últimos 20 años,
aunque la tendencia apunta a que se abandone paulatinamente para dar
paso a procesadores que integren en un sólo paquete todos estos
componentes. Sin embargo, el acomodo funcional electrónico, al menos
hasta el momento, sigue basado en estos puntos.] de estos buses es a
través de una separación en dos chips: El /puente norte/
(/Northbridge/), conectado directamente al CPU, encargado de gestionar
los buses de más alta velocidad y que, además, son fundamentales para
el más básico inicio de la operación del sistema: La memoria y el
reloj. La comunicación con algunas tarjetas de video se incorpora al
puente norte a través del canal dedicado /AGP/ (/Advanced Graphics
Port/, /Puerto Gráfico Avanzado/).

Al puente norte se conecta el /puente sur/ (/Southbridge/), que
controla el resto de los dispositivos del sistema — Normalmente
veremos aquí a las interfaces de almacenamiento (SCSI, SATA, IDE), de
expansión interna (PCI, PCIe) y de expansión externa (USB, Firewire,
puertos /heredados/ seriales y paralelos).

**** Contención

Una de las principales razones de la existencia de tantos /canales/
(buses) distintos en un mismo sistema es a la frecuencia acorde a los
dispositivos para los cuales está diseñado: La cantidad de datos que
tiene que viajar entre el procesador y la memoria a lo largo de la
operación del sistema es muy superior que la que tiene que
transferirse desde los discos, y a su vez, esta es mucho mayor que la
que enviarse a la impresora, o la que se recibe del teclado. Claro
está, los demás dispositivos podrían incrementar su frecuencia para
participar en un canal más rápido, aunque su costo se incrementaría,
dado que harían falta componentes capaces de sostener un reloj varios
órdenes de magnitud más rápido.

Pero incluso obviando la diferencia económica: Cuando el sistema
requiere transferir datos de o hacia varios dispositivos de la misma
categoría, es frecuente que ocurra /contención/: Puede saturarse el
ancho de banda máximo que alcanza uno de los canales y, aún si los
dispositivos tienen información lista, tendrán que esperar a que los
demás dispositivos desocupen el canal.

#+attr_html: height=490px
#+attr_latex: width=\textwidth
#+label: HW_chipset_857
#+caption: Esquema simplificado del chipset Intel 875 (para el procesador Pentium 4) ilustrando la velocidad de cada uno de los canales
[[./img/dot/chipset_857.png]]

En la figura \ref{HW_chipset_857} podemos ver el diseño general del chipset Intel 875,
introducido en el 2003, incluyendo el ancho de banda de cada uno de
los canales del sistema. Hay que recordar que hay canales como el USB
que permiten la conexión de múltiples dispositivos, los cuales
deberán compartir el ancho de banda total permitido por el canal: En
la figura presentamos dos discos duros sobre el canal SATA y dos
unidades ópticas en el ATA paralelo; el canal USB permite el uso de
un máximo de 127 unidades por canal, por lo cual la contención puede
ser muy alta.


** Acceso directo a memoria (DMA)
# <<HW_dma>>

La operación de dispositivos de entrada/salida puede ser altamente
ineficiente. Cuando un proceso está en una sección /limitada por
entrada-salida/ (esto es, donde la actividad principal es la
transferencia de información entre la memoria principal y cualquier
otra área del sistema), si el procesador tiene que encargarse de la
transferencia de toda la información[fn:: Este modo de operación es
también conocido como /entrada/salida programada/.], se crearía un
cuello de botella por la cantidad y frecuencia de interrupciones. Hoy
en día, para evitar que el sistema se detenga cada que hay una
transferencia grande de datos, todas las computadoras implementan
controladores de /acceso directo a memoria/ (DMA) en uno o más de sus
subsistemas.

El DMA se emplea principalmente al tratar con dispositivos con un
gran ancho de banda, como unidades de disco, subsistemas multimedia,
tarjetas de red, e incluso para transferir información entre niveles
del caché.

Las transferencias DMA se hacen en /bloques/ preestablecidos; en vez
de que el procesador reciba una interrupción cada que hay una palabra
lista para ser almacenada en la memoria, el procesador indica al
controlador DMA la dirección física base de memoria en la cual
operará, la cantidad de datos a transferir, la /dirección/ en que se
efectuará la operación (del dispositivo a memoria o de memoria al
dispositivo), y el /puerto/ del dispositivo en cuestión; el
controlador DMA efectuará la transferencia solicitada, y sólo una vez
terminada ésta (o en caso de encontrar algún error en el proceso)
lanzará una interrupción al sistema; el procesador queda libre para
realizar otras tareas, sin más limitante que la posible /contención/
que tendrá que enfrentar en el bus de acceso a la memoria.

*** Coherencia de cache

Cuando se realiza una transferencia DMA de un dispositivo a la
memoria, puede haber /páginas/ de la memoria en cuestión que estén en
alguno de los niveles de la memoria caché; dado que el caché está uno
o más niveles por encima de la memoria principal, es posible que la
información haya ya cambiado pero el caché retenga la información
anterior.

Los sistemas de /caché coherente/ implementan mecanismos en hardware
que notifican a los controladores de caché que las páginas que alojan
están /sucias/ y deben ser vueltas a cargar para ser empleadas, los
sistemas /no coherentes/ requieren que el subsistema de memoria del
sistema operativo hagan esta operación.

Los procesadores actuales implementan típicamente varios niveles de
caché, estando algunos dentro del mismo CPU, por lo que típicamente
encontramos sistemas híbridos, en los que los cachés de nivel 2 son
coherentes, pero los de nivel 1 no, y deben ser manejados por
software.



* Interfaz del Sistema Operativo -- Llamadas al sistema
# <<HW_SYSCALLS>>
De forma de cierto modo análoga a las interrupciones, podemos hablar
de las llamadas al sistema. El sistema operativo protege a un proceso
de otro, y previene que un proceso ejecutándose en espacio no
privilegiado tenga acceso directo a los dispositivos. Cuando un
proceso requiere de alguna de estas acciones, acede a ellas levantando
una /llamada al sistema/. Las llamadas al sistema pueden agruparse, a
grandes rasgos, en:

- Control de procesos :: Crear o finalizar un proceso, obtener
     atributos del proceso, esperar cierto tiempo, asignar o liberar
     memoria, etc.

- Manipulación de archivos :: Crear, borrar o renombrar un archivo;
     abrir o cerrar un archivo existente; modificar sus /metadatos/;
     leer o escribir de un /descriptor de archivo/ abierto, etc.

- Manipulación de dispositivos :: Solicitar o liberar un dispositivo;
     leer, escribir o reposicionarlo, y otras varias. Muchas de estas
     llamadas son análogas a las de manipulación de archivos, y varios
     sistemas operativos las ofrecen como una sola.

- Mantenimiento de la información :: Obtener o modificar la hora del
     sistema; obtener detalles acerca de procesos o archivos, etc.

- Comunicaciones :: Establecer una comunicación con determinado
                    proceso (local o remoto), aceptar una solicitud de
                    comunicación de otro proceso, intercambiar
                    información sobre un canal establecido

- Protección :: Consultar o modificar la información relativa al
                acceso de objetos en el disco, otros procesos, o la
                misma sesión de usuario

Cada sistema operativo /expone/ una serie de llamadas al
sistema. Estas son, a su vez, expuestas al programador a través de las
/interfaces de aplicación al programador/ (API), que se alínean de
forma cercana (pero no exacta). Del mismo modo que cada sistema
operativo ofrece un conjunto de llamadas al sistema distinto, cada
implmentación de un lenguaje de programación puede ofrecer un API
ligeramente distinto de otros.

#+attr_latex: width=0.7\textwidth
#+attr_html: height="350"
#+label: HW_llamando_syscall
#+caption: Un API expone una interfaz en un lenguaje de alto nivel hacia una llamada al sistema. (Imagen: /Operating System Concepts Essentials/; Silberschatz, Galvin, Gagne; p.56)
[[./img/llamando_syscall.png]]

#+attr_latex: width=\textwidth
#+label: HW_llamada_al_sistema
#+caption: Transición del flujo entre espacio usuario y espacio núcleo en una llamada al sistema
[[./img/dot/llamada_al_sistema.png]]

** Llamadas al sistema, arquitecturas y APIs

Cada familia de sistemas operativos distintas llamadas al sistema, y
sus lenguajes/bibliotecas implementan distintos APIs. Esto es el que
distingue principalmente a uno de otro. Por ejemplo, los sistemas
Windows 95 en adelante implementan Win32, Win16 (compatibilidad con
Windows previos) y MSDOS; MacOS implementa Cocoa (aplicaciones MacOS
X) y Carbon (compatibilidad con aplicaciones de MacOS previos), y
Linux y los *BSDs, POSIX (el estándar que define a Unix). El caso de
MacOS X es interesante, porque también implementa POSIX, ofreciendo la
/semántica/ de dos sistemas muy distintos entre sí.

Los lenguajes basados en /máquinas virtuales abstractas/, como Java o
la familia .NET, exponen un API con mucha mayor distancia respecto al
sistema operativo; la máquina virtual se presenta como un
pseudo-sistema operativo intermedio que se ejecuta dentro del real, y
esta distinción se hace especialmente notoria cuando buscamos conocer
los detalles del sistea operativo. Sugiero para este curso emplear
plataformas que presenten de la forma más transparente al sistema
subyacente.

*** Depuración por /trazas/ (trace)

La mayor parte de los sistemas operativos ofrecen programas que, para
fines de depuración, /envuelven/ al API del sistema y permiten ver la
/traza/ de las llamadas al sistema que va realizando un
proceso. Algunos ejemplos de estas herramientas son =strace= en Linux,
=truss= en la mayor parte de los Unixes históricos o =ktrace= y
=kdump= en los *BSD. A partir de Solaris 10 (2005), Sun incluye una
herramienta mucho más profunda y programable para esta tarea llamada
=dtrace=, misma que ha sido /portada/ a otros Unixes (*BSD, MacOS).

La salida de una traza nos brinda amplio detalle acerca de la
actividad realizada por un proceso, y nos permite comprender a grandes
rasgos su interacción con el sistema. El nivel de información que nos
da es, sin embargo, a veces demasiado — Consideren la siguiente
traza, ante uno de los comandos más sencillos: =pwd= (obtener el
directorio actual)

#+latex: {\scriptsize
#+begin_src c
$ strace pwd
execve("/bin/pwd", ["pwd"], [/* 43 vars */]) = 0
brk(0)                                  = 0x8414000
access("/etc/ld.so.nohwcap", F_OK)      = -1 ENOENT (No such file or directory)
mmap2(NULL, 8192, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0xb773d000
access("/etc/ld.so.preload", R_OK)      = -1 ENOENT (No such file or directory)
open("/etc/ld.so.cache", O_RDONLY)      = 3
fstat64(3, {st_mode=S_IFREG|0644, st_size=78233, ...}) = 0
mmap2(NULL, 78233, PROT_READ, MAP_PRIVATE, 3, 0) = 0xb7729000
close(3)                                = 0
access("/etc/ld.so.nohwcap", F_OK)      = -1 ENOENT (No such file or directory)
open("/lib/i386-linux-gnu/libc.so.6", O_RDONLY) = 3
read(3, "\177ELF\1\1\1\0\0\0\0\0\0\0\0\0\3\0\3\0\1\0\0\0po\1\0004\0\0\0"..., 512) = 512
fstat64(3, {st_mode=S_IFREG|0755, st_size=1351816, ...}) = 0
mmap2(NULL, 1366328, PROT_READ|PROT_EXEC, MAP_PRIVATE|MAP_DENYWRITE, 3, 0) = 0xb75db000
mprotect(0xb7722000, 4096, PROT_NONE)   = 0
mmap2(0xb7723000, 12288, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_DENYWRITE, 3, 0x147) = 0xb7723000
mmap2(0xb7726000, 10552, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_ANONYMOUS, -1, 0) = 0xb7726000
close(3)                                = 0
mmap2(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0xb75da000
set_thread_area({entry_number:-1 -> 6, base_addr:0xb75da8d0, limit:1048575, seg_32bit:1, contents:0, read_exec_only:0, limit_in_pages:1, seg_not_present:0, useable:1}) = 0
mprotect(0xb7723000, 8192, PROT_READ)   = 0
mprotect(0xb775c000, 4096, PROT_READ)   = 0
munmap(0xb7729000, 78233)               = 0
brk(0)                                  = 0x8414000
brk(0x8435000)                          = 0x8435000
open("/usr/lib/locale/locale-archive", O_RDONLY|O_LARGEFILE) = 3
fstat64(3, {st_mode=S_IFREG|0644, st_size=1534672, ...}) = 0
mmap2(NULL, 1534672, PROT_READ, MAP_PRIVATE, 3, 0) = 0xb7463000
close(3)                                = 0
getcwd("/home/gwolf/vcs/sistemas_operativos", 4096) = 36
fstat64(1, {st_mode=S_IFCHR|0620, st_rdev=makedev(136, 1), ...}) = 0
mmap2(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0xb773c000
write(1, "/home/gwolf/vcs/sistemas_operati"..., 36/home/gwolf/vcs/sistemas_operativos
) = 36
close(1)                                = 0
munmap(0xb773c000, 4096)                = 0
close(2)                                = 0
exit_group(0)                           = ?
#+end_src
#+latex: }

* Abstracciones comunes 
Como mencionamos antes una de las funciones del sistema operativo es
la de abstraer el hardware de la computador. Cuál es esa abstracción
que ve efectivamente el usuario varía de un sistema operativo a otro.
veremos en esta sección algunas abstracciones utilizadas en varios
sistemas dejando las respectivas a sistemas de archivos para el 
capítulo \ref{FS}.

** Sistemas tipo Windows
Los sistemas del tipo Windows presentan una abstracción diversa
para cada uno de los componentes de la computadora. 
Por ejemplo los volúmenes de almacentamiento secundario (discos rígidos, 
discos compactos, memorias flash, etc) son relacionados 
con una letra cada uno, así (en general) /C:/ es el volumen o partición
del disco principal, /A:/ y /B:/ se utilizan para discos extraibles. 
Una desventaja de esta abstracción es que no queda claro cuáles unidades
pertenecen al mismo disco físico y cuáles no.
A los puertos de entrada/salida más utilizados también se les asignan
nombres alfanuméricos, por ejemplo el primer puerto paralelo se denomina
/LPT1/ y el segundo puerto serie /COM2/. 

** Sistemas tipo Unix
Unix introdujo el concepto de que /todo es un archivo/: En el sistema
Unix original, todos los dispositivos podían ser controlados a través
de un /archivo especial/ que, en vez de almacenar información, apunta
a estructuras en el sistema que controlan a cada dispositivo. Este
concepto sobrevive en los sistemas derivados de Unix al día de hoy,
aunque varias clases de dispositivo rompen esta lógica. El sistema
operativo /Plan9/ de Bell Labs hace mantiene y amplía este concepto e
introduce los /espacios de nombres mutables/, que presenta con
interfaz de archivo archivos prácticamente cualquier objeto empleado
por el sistema.

Las principales estructuras relacionadas que encontraremos en un
sistema tipo Unix son:

- Dispositivos de caracteres :: Dispositivos con los cuales la
     información es leída o escrita un caracter a la vez y se
     presentan como /streams/ (flujos) de información, ya sea
     entrante, saliente o mixta. Algunos pueden permitir operaciones
     adicionales (por ejemplo, rebobinado), pero la manipulación de la
     información se efectúa de forma secuencial.

     Ejemplos: Impresora, unidad de cinta, modem
- Dispositivos de bloques :: Dispositivos que presentan una interfaz
     de /acceso aleatorio/ y entregan o reciben la información en
     /bloques/ de tamaño predeterminado.

     El ejemplo más claro de este tipo de dispositivos es una unidad
     de disco o una de sus particiones.

- Archivos especiales :: Los sistemas Unix actuales incluyen también
  un gran número de archivos especiales por los cual el usuario puede
  monitorear el estado del sistema (memoria libre, número de procesos,
  consumo de procesador, etc) e incluso puede modificar la configuración
  del sistema operativo a través de un archivo, por ejemplo 
  escribir un valor de "100" al archivo /proc/sys/vm/swappiness hará
  que el sistema envíe a espacio de intercambio la mayor cantidad de
  programas.


* Cuando dos cabezas piensan mejor que una
** Multiprocesamiento

El /multiprocesamiento/ es todo entorno donde hay más de un procesador
(CPU). En un entorno multiprocesado, el conjunto de procesadores se
vuelven un recurso más a gestionar por el sistema operativo — Y el que
haya concurrencia /real/ tiene un fuerte impacto en su diseño.

Si bien en el día a día se usan de forma intercambiable[fn:: O poco
más que eso, al grado de que rara vez empleamos el término
/multiprogramación/, mucho más acorde a los equipos que empleamos día
a día.], es importante enfatizar en la diferencia fundamental entre el
/multiprocesamiento/, que abordaremos en esta sección, y la
/multiprogramación/, de la cual hablamos en la sección
\ref{INTRO_multiprogramados} (/Sistemas multiprogramados/). Un sistema
multiprogramado nos da la /ilusión/ de que está ejecutando varios
procesos al mismo tiempo, pero en realidad está alternando entre los
diversos procesos que compiten por su atención. Un sistema
multiprocesador tiene la capacidad de estar atendiendo
/simultáneamente/ a diversos procesos.

#+attr_latex: width=0.5\textwidth
#+attr_html: height=210
#+label: HW_multiproceso_y_multiprogramacion
#+caption: Esquema de la ejecución de tres procesos en un sistema secuencial, multiprogramado, multiprocesado, e híbrido
[[./img/ditaa/multiproceso_y_multiprogramacion.png]]

En la figura \ref{HW_multiproceso_y_multiprogramacion}, el primer diagrama ilustra una ejecución
estrictamente secuencial: Cada uno de los procesos que demandan
atención del sistema es ejecutado hasta que termina; el segundo
muestra cómo se comportaría un sistema multiprogramado, alternando
entre los tres procesos, de modo que el usuario vea que los tres
avanzan de forma simultánea; el tercero corresponde a un sistema de
multitarea pura: Cada proceso es ejecutado por un procesador
distinto, y avanzan en su ejecución de forma simultánea. El cuarto
caso, un esquema híbrido, presenta cómo reaccionaría un equipo con
capacidad de atender a dos procesos al mismo tiempo, pero con tres
procesos solicitando ser atendidos. Este último esquema es el que más
comunmente encontraremos en equipos de uso general hoy en día.

Probablemente el tema que abordaremos más recurrentemente del curso
será precisamente la complejidad que proviene de la multiprogramación;
la abordaremos particularmente en los capítulos \ref{PROC}
(/Administración de procesos/) y \ref{PLAN} (/Planificación de
procesos/). Valga la nota en este momento únicamente para aclarar la
diferencia entre los dos conceptos.

El multiprocesamiento se emplea ampliamente desde los 1960 en los
entornos de cómputo de alto rendimiento, pero por muchos años se vio
como el área de especialización de muy pocos — Las computadoras con
más de un procesador eran prohibitivamente caras, y para muchos
sistemas, ignorar el problema resultaba una opción válida. Muchos
sistemas operativos ni siquiera detectaban la existencia de
procesadores adicionales, y en presencia de éstos, ejecutaban en uno
sólo.

#+attr_latex: width=0.5\textwidth
#+attr_html: height=415
#+label: HW_moore_orig
#+caption: La /Ley de Moore/, en su artículo publicado en 1965, prediciendo la miniaturización por diez años
[[./img/moore_orig.png]]

Esto cambió hacia el 2005. Tras más de 40 años de cumplirse, el modelo
conocido como la /Ley de Moore/, enunciando que cada dos años la
densidad de transistores por circuito integrado se duplicaría,
llevaba a velocidades de CPU que, en el ámbito comercial, excedían los
3GHz, lo cual presentaba ya problemas serios de calentamiento. Además,
el diferencial de velocidad con el acceso a memoria era cada vez más
alto. Esto motivó a que las principales compañías productoras de CPUs
cambiaran de estrategia, introduciendo chips que son, para propósitos
prácticos, /paquetes/ con 2 o más procesadores dentro.

#+attr_latex: width=0.7\textwidth
#+attr_html: height="512"
#+label: HW_ley_de_moore
#+caption: La /Ley de Moore/ se sostiene al día de hoy: Conteo de transistores por procesador de 1971 al 2012
[[./img/gnuplot/ley_de_moore.png]]

Con este cambio, el /reloj/ de los procesadores se ha mantenido casi
sin cambios, cerca de 1GHz, pero el rendimiento de los equipos sigue
aumentando. Sin embargo, como programadores de sistemas operativos y
programas de aplicación ya no podemos ignorar esta complejidad
adicional.

Se denomina /multiprocesamiento simétrico/ (típicamente abreviado SMP)
a la situación en la que todos los procesadores del sistema son
iguales y pueden realizar en el mismo tiempo las mismas
operaciones. Todos los procesadores del sistema tienen acceso a la
misma memoria (aunque cada uno puede tener su propio /caché/, lo cual
obliga a mantener en mente los puntos relacionados con la /coherencia
de caché/ abordados en la sección anterior).

Existe también el /multiprocesamiento asimétrico/; dependiendo de la
implementación, la asimetría puede residir en diferentes puntos. Puede
ir desde que los procesadores tengan una /arquitectura/ distinta
(típicamente dedicada a una tarea específica), en caso en el cual
pueden verse como /coprocesadores/ o /procesadores coadyuvantes/, casi
computadoras independientes contribuyendo sus resultados a un mismo
cómputo. Hoy en día, este sería el caso de las tarjetas gráficas 3D,
que son computadoras completas con su propia memoria y
responsabilidades muy distintas del sistema central.

Es posible tener diferentes procesadores con la misma arquitectura
pero funcionando a diferente frecuencia. Esto conlleva una fuerte
complejidad adicional, y no se utiliza hoy en día.

Por último, existen los diseños de /Acceso No-Uniforme a Memoria/
(/Non-Uniform Memory Access/, /NUMA/). En este esquema, cada
procesador tiene /afinidad/ con bancos específicos de memoria — Para
evitar que los diferentes procesadores estén esperando al mismo tiempo
al bus compartido de memoria, cada uno tiene acceso exclusivo a su
área. Los sistemas NUMA pueden ubicarse como en un punto intermedio
entre el procesamiento simétrico y el cómputo distribuído, y puede ser
visto como un /cómputo distribuído fuertemente acoplado/.

** Cómputo distribuído

Se denomina cómputo distribuído a un proceso de cómputo realizado
entre computadoras independientes, o, más formalmente, entre
procesadores que /no comparten memoria/ (almacenamiento primario).
Puede verse que un equipo de diseño NUMA está a medio camino entre una
computadora multiprocesada y el cómputo distribuído.

Hay diferentes modelos para implementar el cómputo distribuído,
siempre basados en la transmisión de datos sobre una /red/. Estos son
principalmente:

- /Cúmulos/ (clusters) :: Computadoras conectadas por una red local
     (de alta velocidad), corriendo cada una su propia instancia de
     sistema operativo. Pueden estar orientadas al /alto rendimiento/,
     /alta disponibilidad/ o al /balanceo de cargas/. Típicamente son
     equipos homogéneos, y dedicados a la tarea en cuestión.

- /Mallas/ (Grids) :: Computadoras distribuídas geográficamente y
     conectadas a través de una red de comunicaciones. Las
     computadoras participantes pueden ser heterogéneas (en
     capacidades y hasta en arquitectura); la comunicación tiene que
     adecuarse a enlaces de mucho menor velocidad que en el caso de un
     cluster, e incluso presentar la elasticidad para permitir las
     conexiones y desconexiones de nodos en el transcurso del
     cómputo.

- Cómputo /en la nube/ :: Un caso específico de cómputo distribuído
     con partición de recursos (al estilo del modelo
     cliente-servidor); este modelo de servicio está fuertemente
     orientado a la /tercerización/ de servicios específicos. A
     diferencia del modelo cliente-servidor tradicional, en un entorno
     de cómputo en la nube lo más común es que tanto el cliente como
     el servidor sean procesos que van integrando la información,
     posiblemente por muchos pasos, y que sólo eventualmente llegarán
     a un usuario final. La implementación de cada uno de los
     servicios empleados deja de ser relevante, para volverse un
     servicio /opaco/. Algunos conceptos relacionados son:

  - Servicios Web :: Mecanismo de descripción de funcionalidad, así
                     como de solicitud y recepción de resultados,
                     basado en el estándar HTTP y contenido XML

  - Software como servicio :: El proveedor ofrece una /aplicación
       completa y cerrada/ sobre la red, /exponiendo/ únicamente su
       interfaz (API) de consultas

  - Plataforma como servicio :: El proveedor ofrece la /abstracción/
       de un entorno específico de desarrollo de modo que un equipo de
       programadores pueda /desplegar/ una aplicación desarrollada
       sobre dicha plataforma tecnológica. Puede ser visto como un
       conjunto de piezas de infraestructura sobre de un servidor
       administrado centralmente.

  - Infraestructura como servicio :: El proveedor ofrece computadoras
       completas (en hardware real o máquinas virtuales); la principal
       ventaja de esta modalidad es que los usuarios, si bien retienen
       la capacidad plena de administración sobre sus /granjas/,
       tienen mucho mayor flexibilidad para aumentar o reducir el
       consumo de recursos (y por tanto, el pago) según la demanda que
       alcancen.

  El tema del cómputo en la nube va muy de la mano de la
  virtualización, que abordaremos en el apéndice \ref{VIRT}.

** Amdahl y Gustafson: ¿qué esperar del paralelismo?

Al programar una aplicación de forma que aproveche al paralelismo
(esto es, diseñarla para que realice en distintos procesadores o nodos
sus /porciones paralelizables/) ¿cuál es el incremento al rendimiento
que podemos esperar?

En 1967, Gene Amdahl presentó un artículo[fn:: [[http://turing.eas.asu.edu/cse520fa08/Alaw.pdf][Validity of the Single
Processor Approach to Achieving Large Scale Computing Capabilities]],
Amdahl, 1967] en que indica los límites máximos en que resultará la
programación multiprocesada ante determinado programa: Partiendo de la
observación de que aproximadamente 40% del tiempo de ejecución de un
programa se dedicaba a administración y mantenimiento de los datos,
esto es, a tareas secuenciales.

Si únicamente el 60% del tiempo de procesamiento es susceptible, pues,
de ser paralelizado, el rendimiento general del sistema no se
incrementará en una proporción directa con el número de procesadores,
sino que debe sumársele la porción estrictamente secuencial. Puesto en
términos más formales: La ganancia en la velocidad de ejecución de un
programa al ejecutarse en un entorno paralelo estará limitado por el
tiempo requerido por su fracción secuencial. Esto significa que, si
$T(1)$ representa al tiempo de ejecución del programa con un sólo
procesador y $T(P)$ al tiempo de ejecución con $P$ procesadores, y si
$t_s$ es el tiempo requerido para ejecutar la porción secuencial del
programa, y $t_p(P)$ el tiempo que requiere la ejecución de la porción
paralelizable, repartida entre $P$ procesadores, podemos hablar de una
ganancia $g$ en términos de:

$$g = \frac{T(1)}{T(P)} = \frac{t_s + t_p(1)}{t_s + \frac{t_p(1)}{P}}$$

#+begin_latex
\begin{figure}
\centering
\subfigure[Procesadores: 1, $t=500$ \label{HW_amdahl_1}]{\hskip 2em \includegraphics[height=0.33\textheight]{img/dot/amdahl_1.png} \hskip 2em}
\hfill
\subfigure[Procesadores: 2, $t=400$, ganancia: 1.25x \label{HW_amdahl_2}]{\includegraphics[height=0.33\textheight]{img/dot/amdahl_2.png} \hskip 1em}
\hfill
\subfigure[Procesadores: 4, $t=350$, ganancia: 1.4x \label{HW_amdahl_4}]{\includegraphics[height=0.33\textheight]{img/dot/amdahl_4.png}}
\caption {Ley de Amdahl: Ejecución de un programa con 500 unidades de tiempo total de trabajo con uno, dos y cuatro procesadores.}
\label{HW_amdahl}
\end{figure}
#+end_latex

#+begin_html
<table class="figure" style="margin-right:auto; margin-left:auto;" >
  <tr>
    <td style="padding: 1em">
      <span id="amdahl_1">
        <p><img src="./img/dot/amdahl_1.png" alt="./img/dot/amdahl_1.png" /></p>
        <p>Procesadores: 1, <em>t=500</em></p>
      </span>
    </td><td style="padding: 1em">
      <span id="amdahl_2">
        <p><img src="./img/dot/amdahl_2.png" alt="./img/dot/amdahl_2.png" /></p>
        <p>Procesadores: 2, <em>t=400</em>, ganancia: 1.25x</p>
      </span>
    </td><td style="padding: 1em">
      <span id="amdahl_4">
        <p><img src="./img/dot/amdahl_4.png" alt="./img/dot/amdahl_4.png" /></p>
        <p>Procesadores: 4, <em>t=350</em>, ganancia: 1.4x</p>
      </span>
    </td>
  </tr>
  <caption style="caption-side: bottom">Ley de Amdahl: Ejecución de un programa con 500 unidades de tiempo total de trabajo con uno, dos y cuatro procesadores.</caption>
</table>
#+end_html

Esta observación, conocida como la /Ley de Amdahl/, llevó a que por
varias décadas el cómputo paralelo fuera relegado al cómputo de
propósito específico, para necesidades muy focalizadas en soluciones
altamente paralelizables, como el cómputo científico.

En términos del ejemplo presentado en la figura \ref{HW_amdahl}, vemos
un programa que, ejecutado secuencialmente, resulta en $T=500$. Este
programa está dividido en tres secciones secuenciales, de $t=100$ cada
una, y dos secciones paralelizables, totalizando $t=100$ cada una,
como lo podemos ver al representar una ejecución estrictamente
secuencial (\ref{HW_amdahl_1}).

Al agregar un procesador adicional (\ref{HW_amdahl_2}), obtenemos una
ganancia de 1.25x — La ejecución se completa en $T=400$ (con
$g=1.25$). Las secciones paralelizables sólo toman un tiempo /externo/
de 50 cada una, dado que la carga fue repartida entre dos unidades de
ejecución. Al ejecutar con cuatro procesadores (\ref{HW_amdahl_4}), si
bien seguimos encontrando mejoría, esta apenas nos lleva a $T=350$,
con $g=1.4$.

Si el código fuera infinitamente paralelizable, y ejecutáramos este
programa en una computadora con un número infinito de procesadores,
este programa no podría ejecutarse en menos de $T=300$, lo cual nos
presentaría una ganancia de apenas $g=1.66$. Esto es, al agregar
procesadores adicionales, rápidamente llegaríamos a un crecimiento
asintótico — El comportamiento descrito por la Ley de Amdahl es
frecuentemente visto como una demostración de que el desarrollo de
sistemas masivamente paralelos presenta /rendimientos decrecientes/.

#+attr_latex: width=0.6\textwidth
#+attr_html: height="480"
#+label: HW_amdahl_porcentajes
#+caption: Ganancia máxima al paralelizar un programa, según la Ley de Amdahl
[[./img/gnuplot/amdahl.png]]

Si bien el ejemplo que presentamos resulta poco optimizado, con sólo
un 40% de código paralelizable, podemos ver en la gráfica
\ref{HW_amdahl_porcentajes} que el panorama no cambia tan fuertemente
con cargas típicas. Un programa relativamente bien optimizado, con 80%
de ejecución paralela, presenta un crecimiento atractivo en la región
de hasta 20 procesadores, y se estaciona apenas arriba de una ganancia
de 4.5 a partir de los 40.[fn:: De un máximo de 5 al que puede
alcanzar con un número infinito de procesadores] Incluso el hipotético
95% llega a un tope en su crecimiento, imposibilitado de alcanzar una
ganancia superior a 20.

Dado que el factor económico resulta muy importante para construir
computadoras masivamente paralelas,[fn:: Dado que los componentes más
caros son necesariamente los procesadores] y que vemos claramente que
el poder adicional que nos da cada procesador es cada vez menor, la
Ley de Amdahl resultó (como ya mencionamos) en varias décadas de mucho
mayor atención a la miniaturización y aumento de reloj, y no al
multiprocesamiento.

Fue hasta 1988 que John Gustafson publicó una observación a esta
ley[fn:: [[http://www.johngustafson.net/pubs/pub13/amdahl.htm][Reevaluating Amdahl's Law]], John L. Gustafson, Communications
of the ACM, vol. 31, mayo de 1988] que, si bien no la invalida,
permite verla bajo una luz completamente diferente y mucho más
optimista. Gustafson publicó este artículo corto tras haber obtenido
ganancias superiores a 1020 en una supercomputadora con 1024
procesadores — Un incremento casi perfectamente lineal al número de
procesadores. Sí, respondiendo a una carga altamente optimizada, pero
no por eso menos digna de análisis.

El argumento de Gustafson es que al aumentar el número de
procesadores, típicamente veremos una modificación /al problema
mismo/. Citando de su artículo (traducción propia),

#+begin_quote
(...)Asumen implícitamente que el tiempo que se ejecuta en paralelo es
independiente del número de procesadores, /lo cual virtualmente nunca
ocurre de este modo/. Uno no toma un problema de tamaño fijo para
correrlo en varios números de procesadores como no sea para hacer un
ejercicio académico; en la práctica, /el tamaño del problema crece con
el número de procesadores/. Al obtener procesadores más poderosos, el
problema generalmente se expande para aprovechar las facilidades
disponibles. Los usuarios tienen control sobre cosas como la
resolución de la malla, el número de pasos, la complejidad de los
operadores y otros parámetros que usualmente se ajustan para permitir
que el programa corra en el tiempo deseado. Por tanto, podría ser más
realista que el /tiempo de ejecución/, no el /tamaño del problema/, es
constante.
#+end_quote

Lo que escribe Gustafson se traduce a que es posible obtener la
eficiencia deseada de cualquier cantidad de procesadores /aumentando
suficientemente el tamaño del problema/. Al enfrentarse explícitamente
con el /bloqueo mental/ contra el paralelismo masivo que nació de esta
lectura errónea de lo comentado por Amdahl. Su artículo, sencillo y de
apenas más de una cuartilla de extensión, cambió la percepción acerca
de la utilidad misma del paralelismo masivo.

* Otros recursos

- [[https://dl.acm.org/citation.cfm?doid=359576.359579][Can programming be liberated from the von Neumann style?: a
  functional style and its algebra of programs]]; John Backus, 1978
- [[http://cs.utexas.edu/~fussell/courses/cs352h/papers/moore.pdf][Cramming more components onto integrated circuits]]; Gordon E. Moore,
  1965
- [[http://www.intel.com/content/www/us/en/io/quickpath-technology/quick-path-interconnect-introduction-paper.html][An Introduction to the Intel® QuickPath Interconnect]]; Intel, 2009
  (Document Number: 320412-001US)
- [[http://downloadmirror.intel.com/15199/eng/D875PBZ_TechProdSpec.pdf][Intel® Desktop Board D875PBZ Technical Product Specification]]
  (Intel, 2003)
