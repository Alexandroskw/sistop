#+SETUPFILE: ../setup_notas.org
#+TITLE: Virtualización

* Introducción
# <<VIRT>>

La /virtualización/ no es un concepto nuevo. Sin embargo, tras largos
años de estar relegado a un segundo plano, en la actualidad se torna
fundamental en referencia a los sistemas operativos, particularmente en
rol de servidores. Este tema se abordará de momento desde una
óptica más bien descriptiva, y posteriormente se profundizará en
algunos de sus asepectos.

En primer término, es importante aclarar que el concepto de /virtualización/ 
no se refiere a una única tecnología o metodología, es un término que
agrupa a muy distintas tecnologías que existen – de
diversas formas – desde hace décadas. Cada una de ellas tiene su lugar,
con diferentes usos y propósitos, algunos de los cuales se usan de forma
transparente para el usuario promedio.

Del mismo modo, aunque se abordarán diversas tecnologías que pueden
clasificarse como virtualización, la línea divisoria entre cada una de ellas no
siempre es clara. Una implementación específica puede caer en más
de una categoría, o puede ir migrando naturalmente de un tipo hacia
otro.

A nivel general, /virtualizar/ consiste en proveer algo que no está ahí,
aunque parece estarlo. Más específicamente, presentar a un sistema elementos
que se comporten de la misma forma que un componente físico (hardware), sin que 
exista en realidad — un acto de ilusionismo o de magia, en cual se busca
presentar el elemento de forma tan convincente que la ilusión se mantenga tanto
como sea posible.[fn:: Una aproximación inicial a este concepto puede ser
un archivo con la imagen de un disco en formato ISO: mediante determinados mecanismos, es posible
"engañar" a un sistema operativo de forma que "piense" que al acceder al archivo ISO
está efectivamente leyendo un CD o DVD de una unidad que no existe físicamente.]

La naturaleza de dichos elementos, y el cómo se implementan, dependen del
tipo de virtualización.

Para casi todos los casos que se presentan, se emplearán los siguientes términos:

- Anfitrión :: El hardware o sistema /real/, que ofrece el mecanismo de
               virtualización. En inglés se le denomina /host/.

- Huésped :: El sistema o las aplicaciones que se ejecutan en el entorno
	     virtualizado. En inglés se les denomina /guest/.

* Emulación

La técnica de virtualización más sencilla, y que hace más tiempo
existe en las computadoras personales, es la emulación. Emular
consiste en implementar /en software/ algo que se presente como el
hardware de un sistema de cómputo completo, típicamente de una arquitectura hardware
distinta a la del anfitrión (la arquitectura /nativa/).[fn:: A lo largo de esta discusión, se hará
referencia a la /arquitectura hardware/ como al juego de
instrucciones que puede ejecutar /nativamente/ un procesador. Por
ejemplo, un procesador x86 moderno puede ejecutar nativamente código
i386 y x86_64, pero no ARM.] El emulador puede ser visto (de una forma
tremendamente simplificada) como una lista de equivalencias, de cada
una de las instrucciones en la arquitectura /huésped/ a la
arquitectura del sistema /anfitrión/.

Vale la pena recalcar que una emulación no se limita con traducir del
lenguaje y la estructura de un procesador a otro — para que una
computadora pueda ser utilizada, requiere de una serie de chips de
apoyo — desde los controladores de cada uno de los /buses/ hasta los
periféricos básicos (teclado, video). Casi todas las emulaciones
incluirán un paso más allá: los periféricos mismos (discos, interfaces
de red, puertos). Todo esto tiene que ser implementado por el
emulador.

Resulta obvio que emular un sistema completo es /altamente/
ineficiente. Los sistemas huéspedes resultantes típicamente tendrán un
rendimiento cientos o miles de veces menor al del anfitrión.

Ahora bien, ¿qué pasa cuando hay dos arquitecturas de cómputo que
emplean al mismo procesador? Este caso fue relativamente común en la
década de los 80 y 90; si bien en general las computadoras de 8 bits no tenían
el poder de cómputo necesario para implementar la emulación de
arquitecturas similares, al aparecer tres líneas de computadoras
basadas en el CPU Motorola 68000 (Apple Macintosh, Atari ST y
Commodore Amiga), diferenciadas principalmente por sus /chipsets/,
aparecieron emuladores que permitían ejecutar programas de una línea
en la otra, prácticamente a la misma velocidad que en el sistema nativo.

Hoy en día, la emulación se emplea para hacer /desarrollos cruzados/,
más que para emplear software /ya escrito y compilado/.  La mayor
parte de la emulación tradicional hoy se emplea para el /desarrollo de
software/. Hoy en día, la mayor parte de las computadoras vendidas son
sistemas /embebidos/[fn:: Computadoras pequeñas, limitadas en
recursos, y típicamente carentes de una interfaz usuario — desde
puntos de acceso y ruteadores hasta los controladores de cámaras,
equipos de sonido, automóviles, y un larguísimo etcétera] o
dispositivos móviles, que hacen imposible (o, por lo menos, muy
difícil) desarrollar software directamente en ellos. Los programadores
desarrollan en equipos de escritorio, ejecutan entornos de prueba en
emuladores del equipo destino. A pesar del costo computacional de
realizar la emulación, la diferencia de velocidad entre los equipo de
escritorio de gama alta y los embebidos permiten que frecuentemente la
velocidad del emulador sea muy similar –incluso superior– a la del
hardware emulado.

** Emulando arquitecturas inexistentes

Pero la emulación no se limita a hardware existente, y no sólo se
emplea por la comodidad de no depender de la velocidad de equipos
específicos. Es posible crear emuladores para arquitecturas que /nunca
han sido implementadas/ en hardware real.

Esta idea viene de los 1970, cuando comenzó la explosión de
arquitecturas. La Universidad de California en San Diego propuso una
arquitectura llamada /p-system/, o /sistema-p/, la cual definiría una
serie de instrucciones a las que hoy se clasificarían como /código intermedio/ o
/bytecode/, a ser ejecutado en una /máquina-p/, o /p-machine/. El
lenguaje base para este sistema fue el /Pascal/, mismo que fue
adoptado muy ampliamente de manera principal en entornos académicos a
lo largo de los 1970 y 1980 por su limpieza y claridad
estructural. Todo programa compilado para ejecutarse en un /sistema-p/
ejecutaría sin modificaciones en cualquier arquitectura hardware que lo
implementara.

Los /sistemas-p/ gozaron de relativa popularidad hasta mediados de los
1980, logrando implementaciones para las arquitecturas de
microcomputadoras más populares — el MOS 6502, el Zilog Z80 y el Intel
80x86.

Hay una diferencia muy importante entre la emulación de una
arquitectura real y la de una arquitectura inexistente: emular una
computadora entera requiere implementar no sólo las
instrucciones de su procesador, sino que /todos los chips de apoyo/,
¡incluso hay que convertir la entrada del teclado en las
interrupciones que generaría un controlador de teclado! Emular una
arquitectura hipotética permite manejar diversos componentes de forma
abstracta, y permite definir estructuras de mucho más alto nivel que
las que se encuentran implementadas en hardware. Por ejemplo, si bien
resultaría impráctico crear como tipo de datos nativo para una
arquitectura en hardware una abstracción como las cadenas de
caracteres, estas sí existen como /ciudadanos de primera clase/ en
casi todas las arquitecturas meramente virtuales.

Esta idea ha sido ampliamente adoptada y forma parte de
la vida diaria. En la década de los 1990, /Sun Microsystems/
desarrolló e impulsó la arquitectura /Java/, actualizando la idea de
las /máquinas-p/ a los paradigmas de desarrollo que aparecieron a lo
largo de veinte años, y dado que el cómputo había dejado de ser un campo
especializado y escaso para masificarse, invirtiendo fuertemente en
publicidad para impulsar su adopción.

Uno de los slogans que mejor describen la intención de Sun fue /WORA/:
/Write Once, Run Anywhere/ (escribe una vez, ejecuta donde sea). El
equivalente a una /máquina-p/ (rebautizada como /JVM/: /Máquina
Virtual Java/) se implementaría para las arquitecturas hardware más
limitadas y más poderosas. Sun creó también el lenguaje Java, diseñado
para aprovechar la arquitectura de la JVM, enfatizando en la
orientación a objetos e incorporando facilidades multi-hilos. Al día
de hoy existen distintas implementaciones de la JVM, de diferentes
empresas y grupos de desarrolladores y con diferentes focos de
especialización, pero todas ellas deben poder ejecutar el /bytecode/
de Java.

A principios de los años 2000, y como resultado del litigio con Sun
que imposibilitó a Microsoft a desarrollar extensiones propietarias a
Java (esto es, desarrollar máquinas virtuales que se salieran del
estándar de la JVM), Microsoft desarrolló la arquitectura /.NET/. Su
principal aporte en este campo es la separación definitiva entre
lenguaje de desarrollo y código intermedio producido: la máquina
virtual de /.NET/ está centrada en el /CLI/ (/Common Language
Infrastructure/, Infraestructura de Lenguajes Comunes), compuesta a su
vez por el /CIL/ (/Common Intermediate Language/, Lenguaje Intermedio
Común, que es la especificación del /bytecode/ o código intermedio) y
el /CLR/ (/Common Language Runtime/, Ejecutor del Lenguaje Común, que
es la implementación de la máquina virtual sobre la arquitectura
hardware nativa).

#+attr_latex: width=0.6\textwidth
#+attr_html: height="600"
#+label: VIRT_maquina_virtual_dotnet
#+caption: Arquitectura de la infraestructura de lenguajes comunes (CLI) de .NET (Imagen de la Wikipedia: /Common Language Infrastructure/)
[[./img/maquina_virtual_dotnet.png]]

En los años 90, una de las principales críticas a Java (y esta crítica
podría ampliarse hacia cualqueir otra plataforma comparable) era el
desperdicio de recursos de procesamiento al tener que traducir, una y
otra vez, el código intermedio para su ejecución en el
procesador. Hacia el 2010, el panorama había ya cambiado
fuertemente. Hoy en día las máquinas virtuales implementan varias
técnicas para reducir el tiempo que se desperdicia emulando:

- Traducción dinámica :: Compilación parcial del código a ejecutar a
     formatos nativos, de modo que sólo la primera vez que se ejecuta
     el código intermedio tiene que ser traducido.
- Traducción predictiva :: Anticipar cuáles serán las siguientes
     secciones de código que tendrán que ser ejecutadas para,
     paralelamente al avance del programa,  traducirlas a código
     nativo de forma preventiva.
- Compilación /justo a tiempo/ (JIT) :: Almacenar copia del código ya
     traducido de un programa, de modo que no tenga que traducirse ni
     siquiera a cada ejecución, sino que sólo una vez en la vida de
     la máquina virtual.

A través de estas estrategias, el rendimiento de las
arquitecturas emuladas es ya prácticamente idéntico al del código
compilado nativamente.

** De lo abstracto a lo concreto

Si bien las arquitecturas de máquinas virtuales planteadas en el
apartado anterior se plantearon directamente para no ser
implementadas en hardware, el éxito comercial de la plataforma llevó
a crear una línea de chips que ejecutara /nativamente/ código
intermedio Java, con lo cual podrían ahorrarse pasos y obtener mejor
rendimiento de los sistemas destino. Sun definió la arquitectura
/MAJC/ (/Microprocessor Architecture for Java Computing/, Arquitectura
de microprocesadores para el cómputo con Java) en la segunda mitad de
los 1990, e incluso produjo un chip de esta arquitectura, el
/MAJC 5200/.

La arquitectura MAJC introdujo conceptos importantes que han sido
retomados para el diseño de procesadores posteriores, pero la
complejidad llevó a un rendimiento deficiente, y el chip resultó un
fracaso comercial.

Es importante  mencionar otra aproximación. Transitando en el sentido 
inverso al de Sun con MAJC, /Transmeta/, una empresa hasta entonces 
desconocida, anunció en el 2000 el procesador /Crusoe/, orientado al 
mercado de bajo consumo energético. Este procesador, en vez de implementar 
una arquitectura ya existente para entrar a un mercado ya muy competido 
y dinámico, centró su oferta en que Crusoe trabajaría mano a mano con un módulo llamado
CMS (/Code Morphing Software/, Software de Transformación de Código),
siendo así el primer procesador diseñado para /emular por hardware/ a
otras arquitecturas. Crusoe fue lanzado al mercado con el CMS para la
arquitectura x86 de Intel, y efectivamente, la emulación era
completamente transparente al usuario.[fn:: Empleando Transmeta, se
podían observar ciertos comportamientos curiosos: por ejemplo, dado el
amplio espacio de caché que implementaba el CMS, el código ejecutable
se mantenía /ya traducido/ listo para el procesador, por lo cual la
primera vez que se ejecutaba una función era notablemente más lenta
que en ejecuciones posteriores. Sin embargo, si bien estas diferencias
son medibles y no deben escapar a la vista de quien está analizando a
conciencia estos procesadores, resultaban invisibles para el usuario
final.] El procesador mismo, además, no implementaba algunas
características que hoy en día se consideran fundamentales, como una
unidad de manejo de memoria, dado que eso podía ser implementado por
software en el CMS. Separando de esta manera las características
complejas a una segunda capa, podían mantenerse más bajos tanto el
número de transistores (y, por tanto, el gasto eneergético) y los
costos de producción.

La segunda generación de chips Transmeta (/Efficeon/) estaba basada
en una arquitectura muy distinta, buscando un rendimiento mejorado.
Pero, gracias al CMS, esto resulta imperceptible al usuario.

A pesar de estas ideas interesantes y novedosas, Transmeta no pudo
mantener el dinamismo necesario para despegar, y cesó sus operaciones
en 2009.

** ¿Emulación o simulación?

Una pregunta frecuente que se presenta al hablar de este tema es
acerca de la diferencia entre la /emulación/ y la /simulación/. Todos
los casos presentados anteriormente se tratan de /emulación/.

Emular significa /imitar las acciones de otro, procurando igualarlas e
incluso excederlas/ (Diccionario de la Real Academia Española, 23ª
edición). Esto significa que un emulador reproduce todos los procesos
internos que realizaría el sistema nativo, y busca cubrir todos los
comportamientos respectivos implementando los mismos mecanismos.

/Simular/, por otra parte y según este mismo diccionario, significa
/Representar algo, fingiendo o imitando lo que no es/. Un sistema
simulador simula o finge las áreas de determinado sistema que
interesan al usuario; puede emplear datos pre-cargados para generar
ciertas respuestas, obviando los procesos que los generarían.

A diferencia de los ejemplos presentados a lo largo de esta sección,
que llevan a ejecutar software arbitrario para la plataforma destino
buscando idealmente que éstos no detecten siquiera una diferencia en
comportamiento, un simulador puede presentar mucho mayor detalle en
determinadas áreas, pero no realiza las funciones substantivas del
sistema simulado. Por ejemplo, es muy común (incluso para el
entrenamiento de pilotos reales) el uso de simuladores de vuelo; estos
programas pueden representar una cabina equivalente a la de un avión
real, con todos sus monitores y controles, pero nadie esperaría que lo
trasladen de un lugar a otro. Muchos de los lectores habrán empleado
software de simulación de circuitos electrónicos, que permiten el
diseño y pruebas simples de circuitos, pero no esperarán que simular
en la computadora un núcleo de ferrita rodeado por una bobina resulte
en un receptor de radio.

* Virtualización asistida por hardware
# <<VIRT_asist_por_hw>>

Actualmente se usa la virtualización como una herramienta para la 
consolidación de servicios, de gran ayuda para los
administradores de sistemas. Este uso se refiere principalmente a lo
que se presentará en este apartado, así como en las secciones
\ref{VIRT_paravirt} (/Paravirtualización/) y \ref{VIRT_contenedores}
(/Contenedores/). Y si bien este /zumbido/ de la virtualización se ha
producido mayormente a partir del 2006-2007, no se trata de
tecnologías o ideas novedosas — existe desde fines de los 1960. Hasta
hace algunos años, sin embargo, se mantenía dentro del ámbito de los
servidores a gran escala, fuera del alcance de la mayor parte de los
usuarios. Es necesario estudiar la génesis de esta herramienta, para poder
comprender mejor cómo opera y cómo se implementa.

En 1964, IBM creó la primer /familia de computadoras/, la
serie 360. Presentaron la entonces novedosa idea de que una
organización podía adquirir un modelo sencillo y, si sus necesidades
se ajustaban al modelo de cómputo, podrían migrar facilmente hacia
modelos más poderosos dado que tendrían /compatibilidad binaria/.

Uno de los modelos de esta familia fue la /S-360-67/, con la
característica distintiva en ser la única de la serie 360 en ofrecer
una unidad de manejo de memoria (MMU), con lo cual permitía la
reubicación de programas en memoria. Esto, sin embargo, creaba un
problema: el software desarrollado para los equipos más pequeños de la
familia estaba creado bajo un paradigma de usuario único, y si bien
podría ser ejecutado en este modelo, eso llevaría a un desperdicio de
recursos (dado que el modelo 67 tenía todo lo necesario para operar en
modo multitarea).

La respuesta de IBM fue muy ingeniosa: desarrollar un sistema
operativo mínimo, /CP/ (/Control Program/, Programa de Control) con el
único propósito de crear y gestionar /máquinas virtuales/ dentro del
hardware S/360-67, dentro de /cada una de las cuales/ pudiera
ejecutarse /sin requerir modificaciones/ un sistema operativo estándar
de la serie 360. De entre los varios sistemas operativos disponibles
para la S/360, el que más frecuentemente se utilizó fue el /CMS/,[fn::
Originalmente, las siglas CMS eran por el /Cambridge Monitor System/,
por haber sido desarrollado en la división de investigación de IBM en
Cambridge, pero posteriormente fue renombrado a /Conversational
Monitor System/, /Sistema de Monitoreo Conversacional/] un sistema
sencillo, interactivo y monousuario. La combinación CP/CMS
proporcionaba un sistema operativo multiusuario, con plena protección
entre procesos, y con compatibilidad con los modelos más modestos de
la serie 360.

Aún después de la vida útil de la serie 360 original, IBM mantuvo
compatibilidad con este modelo hacia la serie 370, e incluso hoy, 50
años más tarde, se encuentra aún como /z/VM/ en la línea de
/Sistemas z/.

Vale la pena mencionar que tanto CP como CMS fueron distribuídos desde
el principio de forma consistente con lo que en la actualidad se conoce como
/software libre/: IBM los distribuía en fuentes, con permiso de
modificación y redistribución, y sus diferentes usuarios fueron
enviando las mejoras que realizaban de vuelta a IBM, de modo que hoy
en día incorpora el trabajo de 50 años de desarrolladores.

** El hipervisor

El modelo CP/CMS lleva a una separación bastante limpia entre un
/multiplexador de hardware/ (CP) y el sistema operativo propiamente
dicho (CMS). Y si bien la dupla puede ser vista como un sólo sistema
operativo, conforme se fueron ejecutando en máquinas virtuales
sistemas operativos más complejos se hizo claro que el CP tendría que
ser /otra cosa/. Partiendo del concepto de que el sistema operativo
es el /supervisor/ de la actividad de los usuarios, yendo un paso más
hacia arriba, se fue popularizando el nombre de /hipervisor/ para el
programa que administra y virtualiza a los supervisores. Algunas
características primarias que definen qué es un hipervisor son:

- Es únicamente un /micro-sistema operativo/, dado que no cubre
  muchas de las áreas clásicas ni presenta las interfaces abstractas
  al usuario final — sistemas de archivos, mecanismos de comunicación
  entre procesos, gestión de memoria virtual, evasión de bloqueos,
  etcétera.

- Se limita a gestionar bloques de memoria física contiguos y fijos,
  asignación de dispositivos y /poco/ más que eso.

- Normalmente no tiene una interfaz usuario directa, sino que es
  administrado a través de llamadas privilegiadas desde alguno de los
  sistemas operativos huésped.

Estas líneas se han ido haciendo borrosas con el tiempo. Ahora,
por ejemplo, muchos hipervisores entienden a los sistemas de archivos,
permitiendo que los espacios de almacenamiento ofrecidos a sus
sistemas operativos huésped sean simples archivos para el sistema
anfitrión (y no particiones o dispositivos enteros). Algunos
hipervisores, como /KVM/ bajo Linux se presentan integrados como un
componente más de un sistema operativo estándar.

** Virtualización asistida por hardware en x86

Hasta alrededor del año 2005, la virtualización no se mencionaba muy
frecuentemente. Si bien había hardware virtualizable 40 años atrás,
era hardware bastante especializado — y caro. Ese año, Intel sacó al
mercado los procesadores con las extensiones necesarias para la
virtualización, bajo el nombre /Vanderpool Technology/ (o /VT-x/). Al
año siguiente, AMD hizo lo propio, denominándolas /extensiones
Pacifica/. Hoy en día, casi todas las computadoras de escritorio de
rango medio-alto tienen el sopote necesario para llevar a cabo
virtualización asistida por hardware. Y si bien en un principio el
tema tardó en tomar tracción, llevó a un replanteamiento completo de
la metodología de trabajo tanto de administradores de sistemas como
de programadores.

En contraste con las arquitecturas diseñadas desde un principio para
la virtualización, los usuarios de computadoras personales (inclusive
cuando estas son servidores en centros de datos — siguen estando
basadadas en la misma arquitectura básica) se enfrentan a una 
mayor variedad de dispositivos para todo tipo de tareas.[fn:: Una
descripción completa de la complejidad a la que debe enfrentarse un
hipervisor bajo arquitectura x86 excede con mucho el ámbito del
presente texto; se sugiere a los lectores interesados referirse al
excelente artículo de [[https://dl.acm.org/citation.cfm?doid=2382553.2382554][Bugnion et. al. (2012)]] detallando la
implementación de /VMWare/.] Y si bien la virtualización permite
aparentar varias computadoras distintas ejecutando sobre el mismo
procesador, esta no incluye a los dispositivos. Al presentarse una
máquina virtual, el sistema anfitrión esta casi siempre[fn:: Hay
mecanismos para reservar y dirigir un dispositivo físico existente a
una máquina virtual específica, pero hacerlo implica que éste
dispositivo no será /multiplexado/ hacia las demás máquinas virtuales
que se ejecuten paralelamente.] emulando hardware. Claro está, lo más
frecuente es que el hipervisor ofrezca a los huéspedes la emulación de
dispositivos relativamente viejos y simples.[fn:: Por ejemplo, KVM
bajo Linux emula tarjetas de red tipo NE2000, tarjetas de sonido tipo
Soundblaster16 y tarjetas de video Cirrus Logic, todos ellos de la
década de los 1990.] Esto no significa que estén limitados a las
prestaciones del equipo emulado (por ejemplo, a los 10Mbps para los
que estaba diseñada una tarjeta de red NE2000), sino que la interfaz
del núcleo para enviar datos a dicho dispositivo es una sencilla y que
ha sido empleada tanto tiempo que presenta muy poca inestabilidad.

Y este último punto permite un acercamiento mayor a una de las ventajas que
ofrecen los sistemas operativos virtualizados — la estabilidad. Los
controladores de dispositivos provistos por fabricante han sido
responsabilizados una y otra vez, y con justa razón, de la
inestabilidad de los sistemas operativos de escritorio. En particular,
son en buena medida culpables de la fama de inestabilidad que obtuvo
Windows. Los fabricantes de hardware no siempre gozan de suficiente
conocimiento acerca del sistema operativo como para escribir
controladores suficientemente seguros y de calidad, y por muchos años,
los sistemas Windows no implementaban mayor verificación al
comportamiento de los controladores — que, siendo un sistema
monolítico, eran código ejecutado con privilegios de núcleo.

Al emplear el sistema operativo huésped únicamente controladores
ampliamente probados y estabilizados a lo largo de muchos años, la
estabilidad que ofrece una máquina virtualizada muchas veces supera a
la que obtendría ejecutándose de forma nativa. Claro, el conjunto de
máquinas virtuales que se ejecute dentro de un sistema anfitrión
sigue siendo susceptible a cualquier inestabilidad del mismo sistema
anfitrión, sin embargo, es mucho menos probable que un programa mal
diseñado logre congelarse esperando respuesta del hardware (emulado),
y mucho menos afectar a los demás huéspedes.

* Paravirtualización
# <<VIRT_paravirt>>

La virtualización asistida por hardware, por conveniente que resulte,
sigue presentando algunas desventajas:

- No todos los procesadores cuentan con las extensiones de
  virtualización. Si bien cada vez es más común encontrarlas, es aún
  en líneas generales un factor de diferenciación entre las líneas
  económicas y de lujo.
- La capa de emulación, si bien es delgada, conlleva un cierto peso.
- Si bien es posible virtualizar arquitecturas como la x86, hay
  muchas arquitecturas para las cuales no existen las extensiones
  hardware necesarias.

La /paravirtualización/, o /virtualización asistida por el sistema
operativo/, parte de un planteamiento distinto: en vez de /engañar/ al
sistema operativo para que funcione sobre un sistema que parece real
pero no lo es, la paravirtualización busca hacerlo /con pleno
conocimiento y cooperación/ por parte de los sistemas huéspedes.  Esto
es, la paravirtualización consiste en alojar a sistemas operativos
huésped que, a sabiendas de que están ejecutando en hardware
virtualizado, /no hacen llamadas directas a hardware/ sino que las
traducen a llamadas al sistema operativo anfitrión.

Vale la pena reiterar en este punto: los sistemas operativos huésped
bajo un entorno paravirtualizado saben que no están ejecutando sobre
hardware real, por lo que en vez de enviar las instrucciones que
controlen al hardware, envían llamadas al sistema a su
hipervisor. Hasta cierto punto, el proceso de adecuación
de un sistema para que permita ser paravirtualizado puede ser equivalente
a adecuar al sistema operativo para que ejecute en una arquitectura
nueva — muy parecida a la del hardware /real/, sí, pero con
diferencias fundamentales en aspectos profundos.

Y si bien ya se explicó en la sección anterior que la virtualización puede
ayudar a presentar un sistema idealizado que reduzca la inestabilidad
en un sistema operativo, al hablar de paravirtualización este
beneficio naturalmente crece: los controladores de hardware sencillos
y bien comprendidos que se usaban para gestionar los
dispositivos emulados se convierten casi en simples pasarelas de
llamadas al sistema, brindando además de una sobrecarga mínima, aún
mayor estabilidad por simplicidad del código.

** Paravirtualización y software libre

La paravirtualización resulta muy atractiva, presentando muy obvias
ventajas. Pero a pesar de que es posible emplearla en cualquier
arquitectura hardware, no siempre es posible emplearla.

Como se mencionó anteriormente, incorporar dentro de un sistema operativo
 el soporte para una arquitectura de paravirtualización es casi equivalente a traducirlo a
una nueva arquitectura hardware. Para que los autores de un entorno que
implemente paravirtualización logren que un sistema operativo nuevo
pueda ser ejecutado en su arquitectura, deben poder manipular y
modificar su código fuente: de otra manera, ¿cómo se le podría adecuar
para que supiera desenvolverse en un entorno no nativo?

El proyecto de gestión de virtualización y paravirtualización /Xen/,
hoy impulsado por la empresa /XenSource/, nació como un proyecto
académico de la Universidad de Cambridge, presentando su versión 1.x a
través de un artículo en 2003 (ver [[http://www.cl.cam.ac.uk/netos/papers/2003-xensosp.pdf][Xen and the Art of
Virtualization]]). Este artículo presenta su experiencia
paravirtualizando a una versión entonces actual de Linux y de Windows
XP. Sin embargo, Xen sólo pudo ser empleado por muchos años como
plataforma de paravirtualización de Linux porque, dado que la
adaptación de Windows se realizó bajo los términos del /Academic
Licensing Program/, que permitía a los investigadores acceso y
modificación al código fuente, pero no su redistribución — la versión
paravirtualizable de Windows XP existe, pero no puede distribuirse
fuera de XenSource.

En tanto, el trabajo necesario para lograr la paravirtualización de
un sistema operativo libre, como Linux, FreeBSD u otros, puede ser
libremente redistribuído. No sólo eso, sino que el esfuerzo de
realizar la adaptación pudo compartirse entre desarrolladores de todo
el mundo, dado que esta entonces novedosa tecnología resultaba de gran
interes.

** Paravirtualización de dispositivos

Las ideas derivadas de la paravirtualización pueden emplearse también
bajo entornos basados en virtualización plena: Si el sistema operativo
está estructurado de una forma modular (sin que esto necesariamente
signifique que es un sistema /microkernel/, sino que permita la carga
dinámica de controladores o /drivers/ para el hardware, como
prácticamente la totalidad de sistemas disponibles comercialmente hoy
en día), no hace falta modificar al sistema operativo completo para
gozar de los beneficios de la paravirtualización en algunas áreas.

De esta manera, si bien es posible ejecutar un sistema operativo /sin
modificaciones/ que espera ser ejecutado en hardware real, los
dispositivos que típicamente generan más actividad de entrada y
salida[fn:: Medios de almacenamiento, interfaz de red y salida de
video] pueden ser atendidos por drivers paravirtuales. Por supuesto, varios
aspectos que son parte del núcleo /duro/ del sistema, como la
administración de memoria o el manejo de interrupciones (incluyendo al
temporizador) tendrán que seguirse manejando a través de una
emulación, aunque mucho más delgada.

Según mediciones empíricas realizadas en 2007 por Qumranet (quienes
liderearon el desarrollo del módulo de virtualización asistido por
hardware /KVM/ en Linux), las clases de dispositivos =virtio= y =pv=
resultaron entre 5 y 10 veces más rápidas que la emulación de
dispositivos reales.

Mediante esta estrategia es posible ejecutar sistemas operativos
propietarios, como los de la familia Windows, con buena parte de las
ventajas de la paravirtualización, sobre entornos de virtualización
asistida por hardware.

* Contenedores, o /virtualización a nivel sistema operativo/
# <<VIRT_contenedores>>

Una estrategia completamente distinta para la creación de máquinas
virtuales es la de /contenedores/. A diferencia de emulación,
virtualización asistida por hardware y paravirtualización, al emplear
contenedores /sólo se ejecuta un sistema operativo/, que es el mismo
para los sistemas anfitrión y huesped. El anfitrión implementará una
serie de medidas para /aumentar el grado de separación/ que mantiene
entre procesos, agregando la noción de /contextos/ o /grupos/ que
se describirán en breve. Dado que el sistema operativo es el
único autorizado para tener acceso directo al hardware, no hace falta
ejecutar un hipervisor.

Podría presentarse un símil: las tecnologías antes descritas de
virtualización implementan /hardware virtual/ para cada sistema
operativo, mientras que los contenedores más bien presentan un
/sistema operativo virtual/ para el conjunto de procesos que definen
el comportamiento de cada máquina virtual — muchos autores presentan a
la virtualización por contenedores bajo el nombre /virtualización a
nivel sistema operativo/. Y si bien el efecto a ojos del usuario
puede ser comparable, este método más que una multiplexación de
máquinas virtuales sobre hardware real opera a través de
restricciones adicionales sobre los procesos de usuario.

Al operar a un nivel más alto, un contenedor presenta algunas
limitantes adicionales (principalmente, se pierde la flexibilidad de
ejecutar sistemas operativos distintos), pero obtiene también
importantes ventajas.

El desarrollo histórico de los contenedores puede rastrearse a la
llamada al sistema =chroot()=, que restringe la visión del sistema de
archivos de un proceso a sólo el directorio hacia el cual ésta fue
invocada.[fn:: La llamada =chroot()= fue creada por Bill Joy en 1982
para ayudarse en el desarrollo del sistema Unix 4.2BSD. Joy buscaba
probar los cambios que iba haciendo en los componentes en espacio de
usuario del sistema sin modificar su sistema /vivo/ y en producción,
esto es, sin tener que reinstalar y reiniciar cada vez, y con esta
llamada le fue posible instalar los cambios dentro de un directorio
específico y probarlos como si fueran en la raiz.] Esto es, si dentro
de un proceso se invoca =chroot('/usr/local')= y posteriormente se le
pide abrir el archivo =/boot.img=, a pesar de que éste indique una
ruta absoluta, el archivo que se abrirá será =/usr/local/boot.img=

Ahora bien, =chroot()= no es (ni busca ser) un verdadero aislamiento,
sólo proporciona un inicio[fn:: Como referencia a por qué no es un
verdadero aislamiento, puede referirse al artículo /How to break out
of a =chroot()= jail/ (Simes, 2002)] — pero conforme más usuarios
comenzaban a utilizarlo para servicios en producción, se hizo claro
que resultaría útil ampliar la conveniencia de =chroot()= a un
verdadero aislamiento.

El primer sistema en incorporar esta funcionalidad fue /FreeBSD/,
creando el subsistema /Jails/ a partir de su versión 4.0, del
año 2000. No tardaron mucho en aparecer implementaciones comparables
en los distintos sistemas Unix. Hay incluso un producto propietario,
el /Parallels Virtuozzo Containers/, que implementa esta
funcionalidad para sistemas Windows.

Un punto importante a mencionar cuando se habla  de contenedores es que
se pierde buena parte de la universalidad mencionada en las secciones
anteriores. Si bien las diferentes implementaciones comparten
principios básicos de operación, la manera en que implementan la
separación e incluso la nomenclatura que emplean difieren
fuertemente.

El núcleo del sistema crea un /grupo/ para cada /contenedor/ (también
conocido como /contexto de seguridad/), aislándolos entre sí por lo
menos en los siguientes áreas:

- Tablas de procesos :: Los procesos en un sistema Unix se presentan
     como un árbol, en cuya raiz está siempre el proceso 1,
     =init=. Cada contenedor inicia su existencia ejecutando un =init=
     propio y enmascarando su identificador de proceso real por el
     número 1.
- Señales, comunicación entre procesos :: Ningún proceso de un
     contenedor debe poder interferir con la ejecución de uno en otro
     contenedor. El núcleo restringe toda comunicación entre procesos,
     regiones de memoria compartida y envío de señales entre procesos
     de distintos grupos.
- Interfaces de red :: Varía según cada sistema operativo e
     implementación, pero en líneas generales, cada contenedor tendrá
     una interfaz de red con una /dirección de acceso a medio (MAC)/
     distinta.[fn:: Es común referirse a las direcciones MAC como
     direcciones físicas, sin embargo, todas las tarjetas de red
     permiten configurar su dirección, por lo cual la apelación
     /física/ resulta engañosa.] Claro está, cada una de ellas
     recibirá una diferente dirección IP, y el núcleo ruteará e
     incluso aplicará reglas de firewall entre ellas.
- Dispositivos de hardware :: Normalmente los sistemas huesped no tienen
     acceso directo a ningún dispositivo en hardware. En algunos
     casos, el acceso a dispositivos será multiplexado, y en otros, un
     dispositivo puede especificarse a través de su
     configuración. Cabe mencionar que, dado que esta multiplexión no
     requiere /emulación/ sino que únicamente una cuidadosa
     /planificación/, no resulta tan oneroso como la emulación.
- Límites en consumo de recursos :: Casi todas las implementaciones
     permiten asignar cotas máximas para el consumo de recursos
     compartidos, como espacio de memoria o disco o tiempo de CPU
     empleados por cada uno de los contenedores.
- Nombre del equipo :: Aunque parezca trivial, el nombre con el que
     una computadora /se designa a sí misma/ debe también ser
     aislado. Cada contenedor debe poder tener un nombre único e
     independiente.

Una de las principales características que atrae a muchos
administradores a elegir la virtualización por medio de contenedores
es un consumo de recursos óptimo: bajo los demás métodos de
virtualización (y particularmente al hablar de emulación y de
virtualización asistida por hardware), una máquina virtual siempre
ocupará algunos recursos, así esté inactiva. El hipervisor tendrá que
estar notificando a los temporizadores, enviando los paquetes de red
recibidos, etcétera. Bajo un esquema de contenedores, una máquina
virtual que no tiene trabajo se convierte sencillamente en un grupo
de procesos /dormidos/, probables candidatos a ser /paginados/ a
disco.

* Otros recursos

- /Bringing Virtualization to the x86 Architecture with the Original
  VMware Workstation/
  #+latex: \otrorec{https://dl.acm.org/citation.cfm?doid=2382553.2382554}
  #+html: <br/><a href="https://dl.acm.org/citation.cfm?doid=2382553.2382554">https://dl.acm.org/citation.cfm?doid=2382553.2382554</a><br/>
  Bugnion et. al. (2012); ACM Transactions on Computer Systems
- /Performance Evaluation of Intel EPT Hardware Assist/
  #+latex: \otrorec{http://www.vmware.com/pdf/Perf_ESX_Intel-EPT-eval.pdf}
  #+html: <br/><a href="http://www.vmware.com/pdf/Perf_ESX_Intel-EPT-eval.pdf">http://www.vmware.com/pdf/Perf_ESX_Intel-EPT-eval.pdf</a><br/>
  VMWare Inc. (2006-2009)
- /Performance Aspects of x86 Virtualization/
  #+latex: \otrorec{http://communities.vmware.com/servlet/JiveServlet/download/1147092-17964/PS_TA68_288534_166-1_FIN_v5.pdf}
  #+html: <br/><a href="http://communities.vmware.com/servlet/JiveServlet/download/1147092-17964/PS_TA68_288534_166-1_FIN_v5.pdf">http://communities.vmware.com/servlet/JiveServlet/download/1147092-17964/PS_TA68_288534_166-1_FIN_v5.pdf</a><br/>
  Ole Agesen (2007); VMWare
- /Xen and the Art of Virtualization/
  #+latex: \otrorec{http://www.cl.cam.ac.uk/netos/papers/2003-xensosp.pdf}
  #+html: <br/><a href="http://www.cl.cam.ac.uk/netos/papers/2003-xensosp.pdf">http://www.cl.cam.ac.uk/netos/papers/2003-xensosp.pdf</a><br/>
  Paul Barham, Boris Dragovic et. al. (2003)
- /KVM: The Linux Virtual Machine Monitor/
  #+latex: \otrorec{http://kernel.org/doc/ols/2007/ols2007v1-pages-225-230.pdf}
  #+html: <br/><a href="http://kernel.org/doc/ols/2007/ols2007v1-pages-225-230.pdf">http://kernel.org/doc/ols/2007/ols2007v1-pages-225-230.pdf</a><br/>
  Avi Kivity, Yaniv Kamay, Dor Laor, Uri Lublin, Anthony Liguori (2007)
  Qumranet / IBM)
- /KVM PV devices/
  #+latex: \otrorec{http://www.linux-kvm.org/wiki/images/d/dd/KvmForum2007$kvm_pv_drv.pdf}
  #+html: <br/><a href="http://www.linux-kvm.org/wiki/images/d/dd/KvmForum2007$kvm_pv_drv.pdf">http://www.linux-kvm.org/wiki/images/d/dd/KvmForum2007$kvm_pv_drv.pdf</a><br/>
  Dor Laor (2007); Qumranet
- /How to break out of a =chroot()= jail/
  #+latex: \otrorec{http://www.bpfh.net/computing/docs/chroot-break.html}
  #+html: <br/><a href="http://www.bpfh.net/computing/docs/chroot-break.html">http://www.bpfh.net/computing/docs/chroot-break.html</a><br/>
  Simes (2002)
- /Notes from a container/
  #+latex: \otrorec{http://lwn.net/Articles/256389/}
  #+html: <br/><a href="http://lwn.net/Articles/256389/">http://lwn.net/Articles/256389/</a><br/>
  Jonathan Corbet (2007); Linux Weekly News
- /CGROUPS/
  #+latex: \otrorec{https://www.kernel.org/doc/Documentation/cgroups/cgroups.txt}
  #+html: <br/><a href="https://www.kernel.org/doc/Documentation/cgroups/cgroups.txt">https://www.kernel.org/doc/Documentation/cgroups/cgroups.txt</a><br/>
  Paul Menage (Google) (2004-2006), kernel.org
