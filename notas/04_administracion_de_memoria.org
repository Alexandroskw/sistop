#+SETUPFILE: ../setup_notas.org
#+TITLE: Sistemas Operativos — Administración de memoria

* Funciones y operaciones del administrador de memoria

El único espacio de almacenamiento que el procesador puede utilizar
directamente, más allá de los registros (que si bien le son internos y
sumamente rápidos, pero de capacidad muy escasa) es la memoria
física. Todas las arquitecturas de procesador tienen instrucciones
para interactuar con la memoria, pero ninguna lo tiene para hacerlo
con medios /persistentes/ de almacenamiento, como las unidades de
disco[fn:: Veremos en la unidad /Sistemas de entrada y salida/ cómo se
interactúa con estas]. Cabe mencionar que cuando veamos en un texto
referencia al /almacenamiento primario/ siempre se referirá a la
memoria, mientras que el /almacenamiento secundario/ se refiere a los
discos u otros medios de almacenamiento persistente.

Todos los programas que deseemos ejecutar deben cargarse a la memoria
del sistema antes de ser utilizados. En esta unidad veremos cómo
administra el sistema operativo a la memoria para permitir que varios
procesos la compartan — Esta tarea debe preverse desde el proceso de
compilación de nuestros programas (en particular, la fase de
/ligado/). Hoy en día, además, casi todos los sistemas operativos
emplean implementaciones que requieren de hardware especializado — La
/Unidad de Manejo de Memoria/ (MMU). Hablaremos de cómo se manejaban
los sistemas multitarea antes de la universalización de los MMU, y qué
rol juegan hoy en día.

En esta primer sección, veremos algunos conceptos base que iremos
hilando y empleando en las secciones subsecuentes.

** Espacio de direccionamiento

La memoria está estructurada como un arreglo direccionable de
bytes. Esto es, al solicitar los contenidos de una dirección
específica de memoria, el hardware nos entregará un byte (8 bits), y
no menos. Si queremos hacer una operación sobre /bits/ específicos,
tenemos que solicitar y almacenar bytes enteros. En algunas
arquitecturas, el /tamaño de palabra/ es mayor — Por ejemplo, los
procesadores Alpha incurrían en /fallas de alineación/ si se
solicitaba una dirección de memoria no alineada a 64 bits, y toda
llamada a direcciones /mal alineadas/ tenía que ser /atrapada/ por el
sistema operativo, re-alineada, y entregada.

Un procesador que soporta un /espacio de direccionamiento/ de 16 bits
puede referirse /directamente/ a hasta $2^{16}$ bytes, esto es, a
hasta 65,536 bytes (64K). Estos procesadores fueron comunes en las
décadas de 1970 y 1980 — Los más conocidos incluyen al Intel 8080 y
8085, Zilog Z80, MOS 6502 y 6510, y Motorola 6800. Hay que recalcar
que estos procesadores son reconocidos como procesadores de /8 bits/,
pero con /espacio de direccionamiento/ de 16 bits. El procesador
empleado en las primeras PC, el Intel 8086, manejaba un
direccionamiento de 20 bits (hasta 1024KB), pero al ser una
arquitectura /real/ de 16 bits requería del empleo de /segmentación/
para alcanzar toda su memoria.

Hoy en día, los procesadores dominantes son de 32 o 64 bits. Un
procesador de 32 bits puede direccionar hasta 4,294,967,296 bytes
(4GB), que está ya dentro de los parámetros de lo esperable hoy en
día; una arquitectura de 32 bits sin extensiones adicionales no puede
emplear más de 4GB RAM; a través de un mecanismo llamado /PAE/
(Extensión de Direcciónes Físicas, /Physical Address Extension/)
permite extender esto a rangos de hasta $2^{52}$ a cambio de un nivel
más de indirección.

Un procesador de 64 bits podría direccionar hasta
18,446,744,073,709,551,616 bytes (16 Exabytes). Los procesadores
comercialmente hoy en día no ofrecen esta capacidad de
direccionamiento principalmente por un criterio económico: Al resultar
tan poco probable que exista un sistema con estas capacidades, los
chips actuales están limitados a entre $2^{40}$ y $2^{48}$ bits — 1 y
256 terabytes. Esta restricción debe seguir teniendo sentido económico
por muchos años aún.

** Hardware: de la unidad de manejo de memoria (MMU)

A lo largo de la historia de las computadoras ha sido necesario
emplear más memoria de la que está directamente disponible — Por un
lado, ofrecer a los procesos más espacio de lo que puede direccionar
/la arquitectura (hardware) que empleamos/, por otro lado la
abstracción de un espacio virtualmente ilimitado para realizar sus
operaciones incluso cuando la memoria /real/ es mucho menor a la
solicitada, y por último, la ilusión de tener un bloque contiguo e
ininterrumpido de memoria, cuando en realidad puede haber alta
/fragmentación/.

Veremos cómo es que el MMU cubre estas necesidades, qué mecanismos
emplea para lograrlo — Y qué debemos cuidar, incluso como
programadores de aplicaciones de alto nivel, para aprovechar de la
mejor manera estas funciones (y evitar, por el contrario, que nuestros
programas se vuelvan lentos por no saber manejar la memoria)
correctamente.

El MMU es también el encargado de verificar que un proceso no tenga
acceso a leer o modificar los datos de otro — Si el sistema operativo
tuviera que verificar que ninguna de las instrucciones ejecutadas por
un programa resulta en una violación de seguridad, la penalización en
velocidad sería demasiado severa[fn:: Y de hecho está demostrado que
no puede garantizarse que una verificación estática sea
suficientemente exhaustiva].

Una primer aproximación a la protección de acceso es a través de un
/registro base/ y un /registro límite/: Si la arquitectura ofrece dos
registros del procesador que sólo pueden ser modificados por el
sistema operativo (Esto es, el hardware define la modificación de
dichos registros como una operación privilegiada que requiere estar
ejecutando en /modo supervisor/), el MMU puede comparar /cada acceso a
memoria/ para verificar que esté en el rango permitido.

Por ejemplo, si a un proceso le fue asignado un espacio de memoria de
64K (65535 bytes) a partir de la dirección 504214 (492K), el /registro
base/ contendría 504214, y el /registro límite/ 65535. Si hubiera una
instrucción por parte de dicho proceso que solicitara una dirección
menor a 504214 o mayor a 569749 (556K), el MMU lanzaría una excepción
o /trampa/ interrumpiendo el procesamiento, e indicando al sistema
operativo que ocurrió una /violación de segmento/ (/segmentation
fault/)[fn:: ¿Por qué /de segmento/? Ver la sección /segmentación/,
más adelante en esta misma unidad]. El sistema operativo entonces
procedería terminando la ejecución del proceso, reclamando todos los
recursos que tuviera asignados y notificando a su usuario.

#+html: <div class="figure">
#+attr_latex: width=\textwidth
#+caption: Espacio de direcciones válidas para el proceso 3 definido por un registro base y un registro límite
#+begin_src ditaa :file ltxpng/base_a_limite.png :cmdline -E
  0     +------------------+
        | Sist. Oper. cBLU |
  128K  +------------------+
        | Proceso 1        |
  256K  +------------------+
        | Proceso 2        |
        |                  |
  492K  +------------------+<-----504214 (base)
        | Proceso 3 cGRE   |    + 65536 (límite)
  556K  +------------------+<-----569749 (base+límite)
        | Espacio cPNK     |
        | Libre            |
  1024K +------------------+
  
#+end_src
#+html: <p align="center">Espacio de direcciones válidas para el proceso 3 definido por un registro base y un registro límite</p></div>

** La memoria /caché/

Hay otro proceso que hoy en día asumimos como un hecho: La memoria
/caché/. Si bien su manejo es (casi) transparente para el sistema
operativo, es muy importante mantenerlo en mente.

Conforme el procesador va avanzando sobre las instrucciones de un
programa (avanzando el registro de conteo de instrucción), se van
produciendo accesos a memoria. Por un lado, tiene que buscar en
memoria la siguiente instrucción a ejecutar. Por otro lado, estas
instrucciones pueden requerirle uno o más operadores adicionales que
deben ser traídos de la memoria. Por último, la instrucción puede
requerir guardar su resultado en cierta dirección de memoria.

Hace años esto no era un problema — La velocidad del procesador
estaba básicamente sincronizada con la del manejador de memoria, y el
flujo podía mantenerse básicamente estable. Pero conforme los
procesadores se fueron haciendo más rápido, y conforme se ha
popularizado el procesamiento en paralelo, la memoria no ha podido
acelerarse a la misma velocidad. La memoria de alta velocidad es
demasiado cara, e incluso las distancias de unos pocos centímetros se
van volviendo obstáculos insalvables por la velocidad máxima de los
electrones viajando por pistas conductoras.

Cuando el procesador solicitó el contenido de una dirección de memoria
y esta no está aún disponible, /tiene que detener su ejecución/
(/stall/) hasta que los datos estén disponibles. El CPU no puede, a
diferencia del sistema operativo, "congelar" todo y guardar el estado
para atender a otro proceso: Para el procesador, la lista de
instrucciones a ejecutar es estrictamente secuencial, y todo tiempo
que requiere esperar a una transferencia de datos es tiempo perdido.

La respuesta para reducir esa espera es la /memoria caché/. Esta es
memoria de alta velocidad, situada /entre/ la memoria principal y el
procesador propiamente, que guarda copias de las /páginas/ que van
siendo accesadas, partiendo del principio de la /localidad de
referencia/:

- Localidad temporal :: Es probable que un recurso que fue empleado
     recientemente vuelva a ser empleado en un futuro cercano.
- Localidad espacial :: La probabilidad de que un recurso /aún no
     requerido/ sea accesado es mucho mayor si fue requerido algún
     recurso cercano.
- Localidad secuencial :: Un recurso, y muy particularmente la
     memoria, tiende a ser requerido de forma secuencial.

#+caption: Patrones de acceso a memoria, demostrando la localidad espacial / temporal (Silberschatz, p.350)
#+attr_html: width:"330"
#+attr_latex: width=0.7\textwidth
[[./img/localidad_de_referencia.png]]

En base a esto, cuando el procesador solicita al hardware determinada
dirección de memoria, el hardware no sólo transfiere a la memoria
caché el byte o palabra solicitado, sino que un bloque o /página/
completo.

Cabe mencionar que hoy en día (particularmente desde que se detuvo la
/guerra de los Megahertz/ parte importante del diferencial en precios
de los procesadores líderes en el mercado es la cantidad de cache de
primero y segundo nivel con que cuentan.

** El espacio en memoria de un proceso

Cuando un sistema operativo inicia un proceso, no se limita a volcar
el archivo ejecutable a memoria, sino que tiene que proveer la
estructura para que éste vaya guardando la información de estado
relativa a su ejecución.

- Sección de texto :: Es el nombre que recibe la imagen en memoria de
     las instrucciones a ser ejecutadas. Típicamente, la sección de
     texto ocupa las direcciones /más bajas/ del espacio en memoria.

- Sección de datos :: Espacio fijo preasignado para las variables
     globales. Este espacio es fijado en tiempo de compilación, y no
     puede cambiar (aunque los datos que carga sí cambian en el tiempo
     de vida del proceso)

- Espacio de /libres/ :: (/Heap/) Espacio de memoria que se emplea
     para la asignación dinámica de memoria /durante la ejecución/ del
     proceso. Este espacio se ubica por encima de la sección de datos,
     y /crece hacia arriba/.

     Cuando el programa es escrito en lenguajes que requieren /manejo
     manual de la memoria/ (como C), esta área es la que se maneja a
     través de las llamadas de la familia de =malloc= y =free=; en
     lenguajes con gestión automática, esta área es monitoreada por
     los /recolectores de basura/ (volveremos a estos conceptos más
     adelante).

- Pila de llamadas :: (/Stack/) Estructuras representando a la serie
     de funciones que han sido llamadas dentro del proceso, con sus
     parámetros, direcciones de /retorno/, variables locales, etc. La
     pila ocupa la parte /más alta/ del espacio en memoria, y /crece
     hacia abajo/.

#+attr_html: height="294"
#+attr_latex: width=0.3\textwidth
#+caption: Regiones de la memoria para un proceso (Silberschatz, p. 100)
[[./img/proceso_en_memoria.png]]


** Resolución de direcciones

Un programa compilado no emplea nombres simbólicos para las variables
o funciones que llama[fn:: Cuando se hace /ligado dinámico/ a
bibliotecas externas sí se mantiene la referencia por nombre, pero
para los propósitos de esta sección, hablaremos de las referencias
internas únicamente]; el compilador, al convertir el programa a
lenguaje máquina, las substituye por la dirección en memoria donde se
encuentra.

Ahora bien, en los sistemas actuales, los procesos requieren coexistir
con otros, para lo cual las direcciones indicadas en el /texto/ del
programa pueden requerir ser traducidas al lugar /relativo al sitio de
inicio del proceso en memoria/ — Esto es, /resueltas/. Podemos hablar
de las siguientes tres estrategias de resolución:

- En tiempo de compilación :: El texto del programa tiene la dirección
     /absoluta/ de los datos y funciones. Esto era muy común en las
     computadoras previas al multiprocesamiento; en la arquitectura
     compatible con PC, el formato ejecutable =.com= es un volcado de
     memoria directo de un archivo objeto con las direcciones
     indicadas de forma absoluta. Esto lo podemos ver hoy
     principalmente en sistemas embebidos o de función específica.

- En tiempo de carga :: Al cargarse a memoria el programa y antes de
     iniciar su ejecución, el /cargador/ (componente del sistema
     operativo) actualiza las referncias a memoria dentro del texto
     para que apunten al lugar correcto — Claro está, esto depende de
     que el compilador indique dónde están todas las referencias a
     variables y funciones.

- En tiempo de ejecución :: El programa nunca hace referencia a una
     ubicación absoluta de memoria, sino que lo hace siempre relativo
     a una /base/ y un /desplazamiento/ (offset). Esto permite que el
     proceso sea incluso reubicado en la memoria mientras está siendo
     ejecutado sin tener que sufrir cambios, pero requiere de hardware
     específico (como un MMU).

Esto es, los nombres simbólicos (por ejemplo, la variable llamada
=contador=) para ser traducidos ya sea a ubicaciones en la memoria,
pueden resolverse en tiempo de compilación (y quedar plasmada en el
programa en disco con una ubicación explícita y definitiva: 510200),
en tiempo de carga (sería guardada en el programa en disco como
/inicio/ + 5986 bytes, y el proceso de carga incluiría substituirla
por la dirección resuelta a la suma del registro base, 504214, y el
/desplazamiento/, 5986, esto es, 510200).

Por último, para emplear la resolución en tiempo de ejecución, se
mantiene en las instrucciones a ser ejecutadas por el proceso la
etiqueta relativa al módulo actual, /inicio/ + 5986 bytes, y es
resuelta cada vez que sea requerido.

#+html: <div class="figure">
#+attr_latex: width=0.5\textwidth
#+caption: Proceso de compilación y carga de un programa, indicando el tipo de resolución de direcciones (Silberschatz, p.281)
#+begin_src dot :exports results :file ltxpng/tipo_resol_direcc.png
  digraph G {
          subgraph cluster0 {
                  label="Tiempo de compilación";
                  color=lightgray;
		  style=filled;
                  compilador;
                  objmod;
          }
          subgraph cluster1 {
                  label="Tiempo de carga";
                  color=lightgray;
		  style=filled;
                  ligado;
		  modulo;
		  cargador;
          }
          subgraph cluster2 {
                  label="Tiempo de ejecución";
                  color=lightgray;
		  style=filled;
                  imagenram;
          }
          fuente -> compilador -> objmod -> ligado -> modulo -> cargador -> imagenram;
          otrosobj -> ligado;
          bibliosist -> cargador;
          dll -> imagenram [label = "Carga dinámica"];

          fuente [label="Programa\nfuente"];
          compilador [label="Compilador o\nensamblador",
                      shape = box];
          objmod [label="Módulo\nobjeto"];
          otrosobj [label="Otros\nobjetos"];
          ligado [label="Editor de\nligado",
                  shape = box];
          modulo [label="Módulo\ncargable"];
          bibliosist [label="Biblioteca\nde sistema"]
          cargador [label="Cargador",
                    shape = box];
          dll [label="Biblioteca\nde sistema\nde carga\ndinámica"];
          imagenram [label="Imagen del\nbinario en\nmemoria",
                     shape = box];
  }
#+end_src

#+results:
[[file:ltxpng/tipo_resol_direcc.png]]
#+html: <p align="center">Proceso de compilación y carga de un programa, indicando el tipo de resolución de direcciones (Silberschatz, p.281)</p></div>

* Asignación de memoria contigua

En los sistemas de ejecución en lotes, así como en las primeras
computadoras personales, sólo un programa se ejecutaba a la vez, por
lo que, más allá de la carga del programa y la satisfacción de alguna
eventual llamada al sistema solicitando recursos, el sistema operativo
no tenía que ocuparse de la asignación de memoria.

Al nacer los primeros sistemas operativos multitarea, se hizo
necesario resolver cómo asignar el espacio en memoria a diferentes
procesos.

** Partición de la memoria

La primer respuesta, claro está, es la más sencilla: Asignar
a cada programa a ser ejecutado un bloque /contiguo/ de memoria de un
tamaño fijo. En tanto los programas permitieran la resolución de
direcciones en tiempo de carga o de ejecución, podrían emplear este
esquema.

El sistema operativo emplearía una región específica de la memoria del
sistema (típicamente la /región baja/ — Desde la dirección en memoria
0x00000000 hacia arriba), y una vez terminado el espacio necesario
para el núcleo y sus estructuras, el sistema asigna espacio a cada uno
de los procesos. Si la arquitectura en cuestión permite limitar los
segmentos disponibles a cada uno de los procesos (por ejemplo, con los
registros /base/ y /límite/ discutidos anteriormente), esto sería
suficiente para alojar en memoria a varios procesos y evitar que
interfieran entre sí.

Desde la perspectiva del sistema operativo, cada uno de los espacios
asignados a un proceso es una /partición/. Cuando el sistema operativo
inicia, toda la memoria disponible es vista como un sólo bloque, y
conforme se van lanzando procesos, este bloque va siendo subdividido
para satisfacer sus requisitos. Cada proceso debe indicar al sistema
operativo cuánta memoria va a requerir a lo largo de su vida prevista.

*** Fragmentación

La /fragmentación/ comienza a aparecer cuando más procesos van siendo
lanzados y van terminando: Al terminar la ejecución de un proceso, ya
no tenemos sólo un bloque de espacio libre, sino dos. Potencialmente,
cada programa que vaya terminando, irá devolviendo al sistema
operativo un bloque de distinto tamaño, que quede entre dos procesos
activos.

Si la computadora no tiene hardware específico que permita que los
procesos resuelvan sus direcciones en tiempo de ejecución, el sistema
operativo no puede reasignar los bloques existentes, y aunque pudiera
hacerlo, mover un proceso entero en memoria puede resultar una
operación cara en tiempo de procesamiento.

Al lanzarse un nuevo programa, el sistema operativo tiene tres
estrategias según las cuales podría asignarle uno de los bloques
disponibles:

- Primer ajuste :: Asigna al nuevo proceso el primer bloque que
                   encuentre donde éste quepa. Este mecanismo es el
                   más simple de implementar y el de más rápida
                   ejecución.

- Mejor ajuste :: El sistema busca entre todos los bloques disponibles
                  cuál es el que mejor se ajusta al tamaño requerido
                  por el nuevo proceso. Esto requiere la revisión
                  completa de la lista de bloques; lleva a que los
                  bloques remanentes, una vez que se ubicó al nuevo
                  proceso, sean tan pequeños como sea posible (esto
                  es, que haya menor desperdicio).

- Peor ajuste :: El sistema busca cuál es el bloque más grande
                 disponible, y se lo asigna al nuevo
                 proceso. Empleando una estrucura de datos como un
                 /montículo/, esta operación puede ser incluso más
                 rápida que la de primer espacio. Con este mecanismo
                 se busca que los bloques que queden después de
                 otorgarlos a un proceso sean tan grandes como sea
                 posible, de cierto modo balanceando su tamaño.

La /fragmentación externa/ se produce cuando hay muchos bloques libres
entre bloques asignados a procesos; la /fragmentación interna/ se
refiere a la cantidad de memoria perdida por asuntos administrativos —
Por ejemplo, si el sistema operativo maneja /bloques/ de 512 bytes y
un proceso requiere 768 bytes para su ejecución, el sistema le
entregará dos bloques (1024 bytes), con lo cual desperdicia 256. En el
peor de los casos, con un bloque de $n$ bytes, un proceso podría
solicitar $kn+1$ bytes de memoria, desperdiciando por fragmentación
interna $n-1$ bytes.

Según análisis estadísticos (Silberschatz, p.289), por cada /N/
bloques asignados, se perderán del órden de /0.5N/ bloques por
fragmentación interna y externa.

*** Compactación

Un problema importante que va surgiendo como resultado de esta
fragmentación es que el espacio total libre de memoria puede ser mucho
mayor que lo que requiere un nuevo proceso, pero al estar
/fragmentada/ en muchos bloques, éste no encontrará una partición
donde ser cargado.

Si los procesos emplean resolución de direcciones en tiempo de
ejecución, cuando el sistema operativo comience a detectar un alto
índice de fragmentación, puede lanzar una operación de /compresión/ o
/compactación/: Mover los contenidos en memoria de los procesos en
ejecución para que ocupen espacios contiguos, permitiendo unificar
varios bloques libres en uno solo.

#+attr_html: height="224"
#+attr_latex: width=0.5\textwidth
#+caption: Compactación de la memoria de procesos en ejecución (La Red, p.76)
[[./img/compactacion_memoria.png]]

La compactación tiene un costo alto — Involucra mover prácticamente la
totalidad de la memoria (probablemente más de una vez por bloque).

*** Intercambio con el almacenamiento secundario

Siguiendo de cierto modo la lógica requerida por la compactación
encontramos los sistemas que utilizan /intercambio/ (/swap/) entre la
memoria primaria y secundaria. En estos sistemas, el sistema operativo
puede /comprometer/ más espacio de memoria del que tiene físicamente
disponible. Cuando hay más procesos de los que caben en memoria, el
sistema suspende a uno de ellos y almacena una copia de su imagen en
memoria en almacenamiento secundario.

Hay algunas restricciones a observar previo a suspender un proceso. Un
proceso que tiene abierto alguna operación de entrada/salida en
curso. Una estrategia ante esto podría ser que todas las operaciones
se realicen únicamente a /buffers/ en el espacio del sistema operativo
y éste las transfiera al espacio del proceso interesado.

Esta técnica se popularizó en los sistemas de escritorio hacia fines
de los 1980 y principios de los 1990, en que las computadoras
personales tenían típicamente entre 1 y 8MB de memoria.

Recordemos que las unidades de disco son del órden de decenas de miles
de veces más lentas que la memoria, por lo que este proceso resulta
muy caro — Por ejemplo, si la imagen en memoria de un proceso es de
100MB, bastante conservador hoy en día, y la tasa de transferencia
sostenida al disco de 50MB/s, intercambiar un proceso al disco toma
dos segundos. Cargarlo de vuelta a memoria toma otros dos segundos — Y
a esto debe sumarse el tiempo de posicionamiento de la cabeza de
lectura/escritura, especialmente si el espacio a emplear no es
secuencial y contiguo. Resulta obvio por qué esta técnica ha caído en
desuso conforme aumenta el tamaño de los procesos.

* Paginación

La fragmentación externa y, por tanto, la necesidad de compactación
pueden evitarse por completo empleando la /paginación/. Esta consiste
en que cada proceso esté compuesto por una serie de /páginas/, dejando
de requerir que la asignación sea de un área /contigua/ de
memoria. Claro está, esto requiere de mayor espacialización por parte
del hardware, y mayor información relacionada a cada uno de los
procesos: No nos basta ya con indicar dónde inicia y dónde termina el
área de memoria de cada proceso, sino que debemos hacer un /mapeo/
entre la ubicación real (/física/) y la presentada a cada uno de los
procesos (/lógica/). La memoria se presentará a cada proceso como si
fuera de su uso exclusivo.

La memoria física se divide en una serie de /marcos/ (/frames/), todos
ellos del mismo tamaño, y el espacio cada proceso se divide en una
serie de páginas (/pages/), del mismo tamaño que los marcos. El MMU se
se encarga del mapeo entre páginas y marcos a través de /tablas/ de
traducción. Las direcciones que maneja el CPU ya no son presentadas de
forma absoluta, sino que como la combinación de un identificador de
página y un desplazamiento — De forma similar a lo que presentamos al
hablar de resolución de instrucciones en tiempo de ejecución.

El tamaño de los marcos (y, por tanto, las páginas) debe ser una
/potencia de 2/, de modo que el MMU pueda discernir fácilmente la
porción de una dirección de memoria que se refiere a la /página/ del
/desplazamiento/. El rango varía, según el hardware, entre los 512
bytes ($2^9$) y 16MB ($2^{24}$); al ser una potencia de 2, el MMU puede
separar la dirección en memoria entre los primeros $m$ bits
(referentes a la página) y los últimos $n$ bits (referentes al
desplazamiento).

#+html: <div class="figure">
#+attr_latex: width=\textwidth
#+caption: Página y desplazamiento, en un esquema de direccionamiento de 16 bits y páginas de 512 bytes
#+begin_src ditaa :file ltxpng/direccion_a_pag_y_despl.png :cmdline -E
Dirección especificada — 0001 1101 0111 0010
 Página (7 bits)
      ^
      |
  /---+---\
  |       |
  +-------+---------+
  |0001110|101110010|
  |  (14) |  (370)  |
  +-------+---------+
          |         |
          \----+----/
	       |
	       V
   Desplazamiento (9 bits)
#+end_src
#+html: <p align="center">Página y desplazamiento, en un esquema de direccionamiento de 16 bits y páginas de 512 bytes</p></div>

Para poder realizar este mapeo, el MMU requiere de una /tabla de
páginas/ (/page table/), que /resuelve/ la relación entre páginas y
marcos, convirtiendo la /dirección lógica/ (aquella que conoce el
proceso) en la /dirección física/ (la ubicación en que /realmente/ se
encuentra en la memoria del sistema).

Podemos tomar como ejemplo para explicar este mecanismo el esquema
presentado en el libro de Silberschatz, Galvin y Gagné. Este nos
presenta un esquema minúsculo: Un /espacio de direccionamiento/ de 32
bytes (5 bits), organizado en 8 páginas de 4 bytes cada una (esto es,
la página es representada con los 3 bits /más significativos/ de la
dirección, y el desplazamiento con los 2 bits /menos
significativos/).

#+attr_html: height="477"
#+attr_latex: width=0.5\textwidth
#+caption: Ejemplo (minúsculo) de paginación, con un espacio de direccionamiento de 32 bytes
[[./img/ejemplo_de_paginacion.png]]

El proceso que se nos presenta tiene una visión de la memoria como la
columna del lado izquierdo: Le parece que existen 4 páginas, y tiene
sus datos distribuidos en órden desde la dirección 00000 (0) hasta la
01111 (15), aunque en realidad en el sistema éstas se encuentren
desordenadas y desperdigadas.

Cuando el proceso quiere referirse a la letra /f/, lo hace indicando
la dirección 00101 (5). De esta dirección, los tres bits más
significativos (001, 1 — Y recordemos que para la computadora, lo
/natural/ es comenzar a contar por el 0) se refieren a la página
número 1, y los dos bits menos significativos (01, 1) indican al
/desplazamiento/ dentro de ésta.

El MMU verifica en la tabla de páginas, y encuentra que la página 1
corresponde al marco número 6 (110), por lo que traduce la dirección
lógica 00101 (5) a la física 11001 (26).

Podemos ver que la paginación resulta en una suerte de resolución de
direcciones en tiempo de ejecución, pero con una /base/ distinta para
cada una de las páginas.

** Tamaño de la página

Ahora, si bien la fragmentación externa se resuelve al emplear
paginación, seguiremos enfrentándonos con la fragmentación interna: Al
dividirse la memoria en bloques de longitud preestablecida de $2^n$
bytes, un proceso en promedio desperdiciará $\frac{2^n}{2}$ (y, en el
peor de los casos, hasta $2^n - 1$). Multiplicando esto por el número
de procesos que están en ejecución en todo momento en el sistema, para
evitar que una proporción sensible de la memoria se pierda en
fragmentación interna, podríamos vernos tentados a emplear un tamaño
de página tan pequeño como fuera posible.

Sin embargo, la sobrecarga administrativa en que incurriríamos por
gestionar demasiadas páginas pequeñas se vuelve una limitante en
sentido opuesto:

- Las transferencias entre unidades de disco y memoria son mucho más
  eficientes si pueden mantenerse como trechos contínuos. El
  controlador de disco puede responder a solicitudes de acceso directo
  a memoria (DMA) siempre que tanto los fragmentos en disco como en
  memoria sean continuos; fragmentar la memoria demasiado jugaría en
  contra de la eficiencia de estas solicitudes.

- El bloque de control de proceso (PCB) incluye la información de
  memoria. Entre más páginas tenga un proceso (aunque estas fueran muy
  pequeñas), más grande es su PCB, y más información requerirá
  intercambiar en un cambio de contexto.

Estas consideraciones opuestas apuntan a que debemos mantener el
tamaño de página más grande, y se regulan con las primeras expuestas
en esta sección.

Hoy en día, el tamaño habitual de las páginas es de 4KB u 8KB
($2^{12}$ o $2^{13}$ bytes). Hay algunos sistemas operativos que
soportan múltiples tamaños de página — Por ejemplo, Solaris puede
emplear páginas de 8KB y 4MB ($2^{13}$ o $2^{22}$ bytes), dependiendo
del tipo de información que se declare que almacenarán.

** Interfaz entre el sistema y el hardware

Algunos de los primeros equipos en manejar memoria paginada empleaban
un conjunto especial de registros para representar la tabla de
páginas. Esto era posible dado que eran sistemas de 16 bits, con
páginas de 8KB ($2^{13}). Esto significa que en el sistema había
únicamente 8 páginas posibles ($2^3$), por lo que resultaba sensato
dedicar un registro a cada una.

En los equipos actuales, mantener la tabla de páginas en registros
resultaría claramente imposible: Teniendo un procesaador de 32 bits, e
incluso si manejáramos un tamaño de página /muy/ grande (digamos,
4MB), tendríamos 1024 páginas posibles[fn:: $2^{32} - 2^{22} = 2^{10}
= 1024]. Los registros son muy rápidos, sin embargo, son
correspondientemente muy caros.

* TODO Segmentación
* TODO Memoria virtual
** TODO Concepto
** TODO Paginación
** TODO Segmentación
** TODO Paginación y segmentación combinadas
** TODO Reemplazo de páginas
** TODO Asignación de marcos e hiperpaginación
* TODO Consideraciones de seguridad
** TODO Bibliotecas de ligado estático y ligado dinámico
** TODO Secciones de texto no ejecutables
- Problemática con los programas /auto-relocalizables/
  (self-relocatable): ¿código auto-modificable?
** TODO Aleatorización de las direcciones
* Otros recursos

- [[http://www.hellion.org.uk/blog/posts/using-valgrind-on-xen-toolstacks/][Using Valgrind to debug Xen Toolstacks]] — Revisar, no sé si el texto
  propiamente sea del nivel adecuado. En todo caso, buscar algo de Valgrind.
- [[http://tech.slashdot.org/story/13/01/25/2146222/hacker-bypasses-windows-78-address-space-layout-randomization][Hacker Bypasses Windows 7/8 Address Space Layout Randomization]] (Slashdot)
- [[http://ghostbar.ath.cx/2013/01/27/less-swap/][Less swap]] (blog de Jose Luis Rivas) — Controlando el "swappiness" de
  Linux vía =vm.swappiness=
# My old X61 has 2G in RAM and 3G in Swap. It seems my using-habit for
# Google Chrome is heavy (more than 20 tabs open most of the time) so
# my swap is normally being used above the 1.8G-mark. That means, my
# disk is constantly being written and read, and since this is the
# original hard-drive scare comes to my mind: will I blow-up my disk
# if I continue doing this? and the heat this disk-use's generating
# was absurd.
#
# That's not good, at all, I prefer having cache used than swap; in
# Venezuela is not that easy to get a good sale on hard-drives (you
# know, is hard to get dollars here, since is illegal to buy them
# unless the govt gives you permission).
#
# So the first thing that comes to my mind is sysctl. If I wanted to
# cofigure swap it would be with a kernel parameter. So running sysctl
# -a | grep swap throws me vm.swappiness = 60, and a little google
# search tells me more about it.
#
# If the swappiness is close to 0 then it will use the swap only if it
# is really necessary, if it is close to 100 then it will use the swap
# aggressively. Mine was at 60, and it was really aggressive.
#
# The next steps for me was doing sudo echo 'vm.swappiness = 1' >>
# /etc/sysctl.conf && sudo sysctl -p.
#
# Now my system is really smooth and using Chrome + Terminal + Tmux +
# Rhythmbox is acceptable.
- [[http://troysunix.blogspot.mx/2011/07/process-memory-usage.html][Process memory usage]], ejemplos de pmap en diferentes Unixes
- [[http://www.adrien-revol.com/blog/index.php?post/2009/12/10/20-Linux-System-Monitoring-Tools][20 Linux system monitoring tools]], varias de ellas enfocadas a la
  memoria
- [[http://www.daemon-systems.org/man/pmap.1.html][Manual de pmap en NetBSD]], con varias opciones más
  explícitas/completas que las de Linux
