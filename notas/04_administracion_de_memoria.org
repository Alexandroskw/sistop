#+SETUPFILE: ../setup_notas.org
#+TITLE: Sistemas Operativos — Administración de memoria

* Funciones y operaciones del administrador de memoria

El único espacio de almacenamiento que el procesador puede utilizar
directamente, más allá de los registros (que si bien le son internos y
sumamente rápidos, pero de capacidad muy escasa) es la memoria
física. Todas las arquitecturas de procesador tienen instrucciones
para interactuar con la memoria, pero ninguna lo tiene para hacerlo
con medios /persistentes/ de almacenamiento, como las unidades de
disco[fn:: Veremos en la unidad /Sistemas de entrada y salida/ cómo se
interactúa con estas]. Cabe mencionar que cuando veamos en un texto
referencia al /almacenamiento primario/ siempre se referirá a la
memoria, mientras que el /almacenamiento secundario/ se refiere a los
discos u otros medios de almacenamiento persistente.

Todos los programas que deseemos ejecutar deben cargarse a la memoria
del sistema antes de ser utilizados. En esta unidad veremos cómo
administra el sistema operativo a la memoria para permitir que varios
procesos la compartan — Esta tarea debe preverse desde el proceso de
compilación de nuestros programas (en particular, la fase de
/ligado/). Hoy en día, además, casi todos los sistemas operativos
emplean implementaciones que requieren de hardware especializado — La
/Unidad de Manejo de Memoria/ (MMU). Hablaremos de cómo se manejaban
los sistemas multitarea antes de la universalización de los MMU, y qué
rol juegan hoy en día.

En esta primer sección, veremos algunos conceptos base que iremos
hilando y empleando en las secciones subsecuentes.

** Hardware: de la unidad de manejo de memoria (MMU)

A lo largo de la historia de las computadoras ha sido necesario
emplear más memoria de la que está directamente disponible — Por un
lado, ofrecer a los procesos más espacio de lo que puede direccionar
/la arquitectura (hardware) que empleamos/, por otro lado la
abstracción de un espacio virtualmente ilimitado para realizar sus
operaciones incluso cuando la memoria /real/ es mucho menor a la
solicitada, y por último, la ilusión de tener un bloque contiguo e
ininterrumpido de memoria, cuando en realidad puede haber alta
/fragmentación/.

Veremos cómo es que el MMU cubre estas necesidades, qué mecanismos
emplea para lograrlo — Y qué debemos cuidar, incluso como
programadores de aplicaciones de alto nivel, para aprovechar de la
mejor manera estas funciones (y evitar, por el contrario, que nuestros
programas se vuelvan lentos por no saber manejar la memoria)
correctamente.

El MMU es también el encargado de verificar que un proceso no tenga
acceso a leer o modificar los datos de otro — Si el sistema operativo
tuviera que verificar que ninguna de las instrucciones ejecutadas por
un programa resulta en una violación de seguridad, la penalización en
velocidad sería demasiado severa[fn:: Y de hecho está demostrado que
no puede garantizarse que una verificación estática sea
suficientemente exhaustiva].

Una primer aproximación a la protección de acceso es a través de un
/registro base/ y un /registro límite/: Si la arquitectura ofrece dos
registros del procesador que sólo pueden ser modificados por el
sistema operativo (Esto es, el hardware define la modificación de
dichos registros como una operación privilegiada que requiere estar
ejecutando en /modo supervisor/), el MMU puede comparar /cada acceso a
memoria/ para verificar que esté en el rango permitido.

Por ejemplo, si a un proceso le fue asignado un espacio de memoria de
64K (65535 bytes) a partir de la dirección 504214 (492K), el /registro
base/ contendría 504214, y el /registro límite/ 65535. Si hubiera una
instrucción por parte de dicho proceso que solicitara una dirección
menor a 504214 o mayor a 569749 (556K), el MMU lanzaría una excepción
o /trampa/ interrumpiendo el procesamiento, e indicando al sistema
operativo que ocurrió una /violación de segmento/ (/segmentation
fault/)[fn:: ¿Por qué /de segmento/? Ver la sección /segmentación/,
más adelante en esta misma unidad]. El sistema operativo entonces
procedería terminando la ejecución del proceso, reclamando todos los
recursos que tuviera asignados y notificando a su usuario.

#+html: <div class="figure">
#+attr_latex: width=\textwidth
#+caption: Espacio de direcciones válidas para el proceso 3 definido por un registro base y un registro límite
#+begin_src ditaa :file ltxpng/base_a_limite.png :cmdline -E
  0     +------------------+
        | Sist. Oper. cBLU |
  128K  +------------------+
        | Proceso 1        |
  256K  +------------------+
        | Proceso 2        |
        |                  |
  492K  +------------------+<-----504214 (base)
        | Proceso 3 cGRE   |    + 65536 (límite)
  556K  +------------------+<-----569749 (base+límite)
        | Espacio cPNK     |
        | Libre            |
  1024K +------------------+
  
#+end_src
#+html: <p align="center">Espacio de direcciones válidas para el proceso 3 definido por un registro base y un registro límite</p></div>

** La memoria /caché/

Hay otro proceso que hoy en día asumimos como un hecho: La memoria
/caché/. Si bien su manejo es (casi) transparente para el sistema
operativo, es muy importante mantenerlo en mente.

Conforme el procesador va avanzando sobre las instrucciones de un
programa (avanzando el registro de conteo de instrucción), se van
produciendo accesos a memoria. Por un lado, tiene que buscar en
memoria la siguiente instrucción a ejecutar. Por otro lado, estas
instrucciones pueden requerirle uno o más operadores adicionales que
deben ser traídos de la memoria. Por último, la instrucción puede
requerir guardar su resultado en cierta dirección de memoria.

Hace años esto no era un problema — La velocidad del procesador
estaba básicamente sincronizada con la del manejador de memoria, y el
flujo podía mantenerse básicamente estable. Pero conforme los
procesadores se fueron haciendo más rápido, y conforme se ha
popularizado el procesamiento en paralelo, la memoria no ha podido
acelerarse a la misma velocidad. La memoria de alta velocidad es
demasiado cara, e incluso las distancias de unos pocos centímetros se
van volviendo obstáculos insalvables por la velocidad máxima de los
electrones viajando por pistas conductoras.

Cuando el procesador solicitó el contenido de una dirección de memoria
y esta no está aún disponible, /tiene que detener su ejecución/
(/stall/) hasta que los datos estén disponibles. El CPU no puede, a
diferencia del sistema operativo, "congelar" todo y guardar el estado
para atender a otro proceso: Para el procesador, la lista de
instrucciones a ejecutar es estrictamente secuencial, y todo tiempo
que requiere esperar a una transferencia de datos es tiempo perdido.

La respuesta para reducir esa espera es la /memoria caché/. Esta es
memoria de alta velocidad, situada /entre/ la memoria principal y el
procesador propiamente, que guarda copias de las /páginas/ que van
siendo accesadas, partiendo del principio de la /localidad de
referencia/:

- Localidad temporal :: Es probable que un recurso que fue empleado
     recientemente vuelva a ser empleado en un futuro cercano.
- Localidad espacial :: La probabilidad de que un recurso /aún no
     requerido/ sea accesado es mucho mayor si fue requerido algún
     recurso cercano.
- Localidad secuencial :: Un recurso, y muy particularmente la
     memoria, tiende a ser requerido de forma secuencial.

#+caption: Patrones de acceso a memoria, demostrando la localidad espacial / temporal (Silberschatz, p.350)
#+attr_html: width:"330"
#+attr_latex: width=0.7\textwidth
[[./img/localidad_de_referencia.png]]

En base a esto, cuando el procesador solicita al hardware determinada
dirección de memoria, el hardware no sólo transfiere a la memoria
caché el byte o palabra solicitado, sino que un bloque o /página/
completo.

Cabe mencionar que hoy en día (particularmente desde que se detuvo la
/guerra de los Megahertz/ parte importante del diferencial en precios
de los procesadores líderes en el mercado es la cantidad de cache de
primero y segundo nivel con que cuentan.

** El espacio en memoria de un proceso

Cuando un sistema operativo inicia un proceso, no se limita a volcar
el archivo ejecutable a memoria, sino que tiene que proveer la
estructura para que éste vaya guardando la información de estado
relativa a su ejecución.

- Sección de texto :: Es el nombre que recibe la imagen en memoria de
     las instrucciones a ser ejecutadas. Típicamente, la sección de
     texto ocupa las direcciones /más bajas/ del espacio en memoria.

- Sección de datos :: Espacio fijo preasignado para las variables
     globales. Este espacio es fijado en tiempo de compilación, y no
     puede cambiar (aunque los datos que carga sí cambian en el tiempo
     de vida del proceso)

- Espacio de /libres/ :: (/Heap/) Espacio de memoria que se emplea
     para la asignación dinámica de memoria /durante la ejecución/ del
     proceso. Este espacio se ubica por encima de la sección de datos,
     y /crece hacia arriba/.

     Cuando el programa es escrito en lenguajes que requieren /manejo
     manual de la memoria/ (como C), esta área es la que se maneja a
     través de las llamadas de la familia de =malloc= y =free=; en
     lenguajes con gestión automática, esta área es monitoreada por
     los /recolectores de basura/ (volveremos a estos conceptos más
     adelante).

- Pila de llamadas :: (/Stack/) Estructuras representando a la serie
     de funciones que han sido llamadas dentro del proceso, con sus
     parámetros, direcciones de /retorno/, variables locales, etc. La
     pila ocupa la parte /más alta/ del espacio en memoria, y /crece
     hacia abajo/.

#+attr_html: height="294"
#+attr_latex: width=0.3\textwidth
#+caption: Regiones de la memoria para un proceso (Silberschatz, p. 100)
[[./img/proceso_en_memoria.png]]


** Resolución de direcciones

Un programa compilado no emplea nombres simbólicos para las variables
o funciones que llama[fn:: Cuando se hace /ligado dinámico/ a
bibliotecas externas sí se mantiene la referencia por nombre, pero
para los propósitos de esta sección, hablaremos de las referencias
internas únicamente]; el compilador, al convertir el programa a
lenguaje máquina, las substituye por la dirección en memoria donde se
encuentra.

Ahora bien, en los sistemas actuales, los procesos requieren coexistir
con otros, para lo cual las direcciones indicadas en el /texto/ del
programa pueden requerir ser traducidas al lugar /relativo al sitio de
inicio del proceso en memoria/ — Esto es, /resueltas/. Podemos hablar
de las siguientes tres estrategias de resolución:

- En tiempo de compilación :: El texto del programa tiene la dirección
     /absoluta/ de los datos y funciones. Esto era muy común en las
     computadoras previas al multiprocesamiento; en la arquitectura
     compatible con PC, el formato ejecutable =.com= es un volcado de
     memoria directo de un archivo objeto con las direcciones
     indicadas de forma absoluta. Esto lo podemos ver hoy
     principalmente en sistemas embebidos o de función específica.

- En tiempo de carga :: Al cargarse a memoria el programa y antes de
     iniciar su ejecución, el /cargador/ (componente del sistema
     operativo) actualiza las referncias a memoria dentro del texto
     para que apunten al lugar correcto — Claro está, esto depende de
     que el compilador indique dónde están todas las referencias a
     variables y funciones.

- En tiempo de ejecución :: El programa nunca hace referencia a una
     ubicación absoluta de memoria, sino que lo hace siempre relativo
     a una /base/ y un /desplazamiento/ (offset). Esto permite que el
     proceso sea incluso reubicado en la memoria mientras está siendo
     ejecutado sin tener que sufrir cambios, pero requiere de hardware
     específico (como un MMU).

Esto es, los nombres simbólicos (por ejemplo, la variable llamada
=contador=) para ser traducidos ya sea a ubicaciones en la memoria,
pueden resolverse en tiempo de compilación (y quedar plasmada en el
programa en disco con una ubicación explícita y definitiva: 510200),
en tiempo de carga (sería guardada en el programa en disco como
/inicio/ + 5986 bytes, y el proceso de carga incluiría substituirla
por la dirección resuelta a la suma del registro base, 504214, y el
/desplazamiento/, 5986, esto es, 510200).

Por último, para emplear la resolución en tiempo de ejecución, se
mantiene en las instrucciones a ser ejecutadas por el proceso la
etiqueta relativa al módulo actual, /inicio/ + 5986 bytes, y es
resuelta cada vez que sea requerido.

#+html: <div class="figure">
#+attr_latex: width=0.5\textwidth
#+caption: Proceso de compilación y carga de un programa, indicando el tipo de resolución de direcciones (Silberschatz, p.281)
#+begin_src dot :exports results :file ltxpng/tipo_resol_direcc.png
  digraph G {
          subgraph cluster0 {
                  label="Tiempo de compilación";
                  color=lightgray;
		  style=filled;
                  compilador;
                  objmod;
          }
          subgraph cluster1 {
                  label="Tiempo de carga";
                  color=lightgray;
		  style=filled;
                  ligado;
		  modulo;
		  cargador;
          }
          subgraph cluster2 {
                  label="Tiempo de ejecución";
                  color=lightgray;
		  style=filled;
                  imagenram;
          }
          fuente -> compilador -> objmod -> ligado -> modulo -> cargador -> imagenram;
          otrosobj -> ligado;
          bibliosist -> cargador;
          dll -> imagenram [label = "Carga dinámica"];

          fuente [label="Programa\nfuente"];
          compilador [label="Compilador o\nensamblador",
                      shape = box];
          objmod [label="Módulo\nobjeto"];
          otrosobj [label="Otros\nobjetos"];
          ligado [label="Editor de\nligado",
                  shape = box];
          modulo [label="Módulo\ncargable"];
          bibliosist [label="Biblioteca\nde sistema"]
          cargador [label="Cargador",
                    shape = box];
          dll [label="Biblioteca\nde sistema\nde carga\ndinámica"];
          imagenram [label="Imagen del\nbinario en\nmemoria",
                     shape = box];
  }
#+end_src

#+results:
[[file:ltxpng/tipo_resol_direcc.png]]
#+html: <p align="center">Proceso de compilación y carga de un programa, indicando el tipo de resolución de direcciones (Silberschatz, p.281)</p></div>

* Asignación de memoria contigua

En los sistemas de ejecución en lotes, así como en las primeras
computadoras personales, sólo un programa se ejecutaba a la vez, por
lo que, más allá de la carga del programa y la satisfacción de alguna
eventual llamada al sistema solicitando recursos, el sistema operativo
no tenía que ocuparse de la asignación de memoria.

Al nacer los primeros sistemas operativos multitarea, se hizo
necesario resolver cómo asignar el espacio en memoria a diferentes
procesos.

** Partición de la memoria

La primer respuesta, claro está, es la más sencilla: Asignar
a cada programa a ser ejecutado un bloque /contiguo/ de memoria de un
tamaño fijo. En tanto los programas permitieran la resolución de
direcciones en tiempo de carga o de ejecución, podrían emplear este
esquema.

El sistema operativo emplearía una región específica de la memoria del
sistema (típicamente la /región baja/ — Desde la dirección en memoria
0x00000000 hacia arriba), y una vez terminado el espacio necesario
para el núcleo y sus estructuras, el sistema asigna espacio a cada uno
de los procesos. Si la arquitectura en cuestión permite limitar los
segmentos disponibles a cada uno de los procesos (por ejemplo, con los
registros /base/ y /límite/ discutidos anteriormente), esto sería
suficiente para alojar en memoria a varios procesos y evitar que
interfieran entre sí.

Desde la perspectiva del sistema operativo, cada uno de los espacios
asignados a un proceso es una /partición/. Cuando el sistema operativo
inicia, toda la memoria disponible es vista como un sólo bloque, y
conforme se van lanzando procesos, este bloque va siendo subdividido
para satisfacer sus requisitos. Cada proceso debe indicar al sistema
operativo cuánta memoria va a requerir a lo largo de su vida prevista.

*** Fragmentación

La /fragmentación/ comienza a aparecer cuando más procesos van siendo
lanzados y van terminando: Al terminar la ejecución de un proceso, ya
no tenemos sólo un bloque de espacio libre, sino dos. Potencialmente,
cada programa que vaya terminando, irá devolviendo al sistema
operativo un bloque de distinto tamaño, que quede entre dos procesos
activos.

Si la computadora no tiene hardware específico que permita que los
procesos resuelvan sus direcciones en tiempo de ejecución, el sistema
operativo no puede reasignar los bloques existentes, y aunque pudiera
hacerlo, mover un proceso entero en memoria puede resultar una
operación cara en tiempo de procesamiento.

Al lanzarse un nuevo programa, el sistema operativo tiene tres
estrategias según las cuales podría asignarle uno de los bloques
disponibles:

- Primer ajuste :: Asigna al nuevo proceso el primer bloque que
                   encuentre donde éste quepa. Este mecanismo es el
                   más simple de implementar y el de más rápida
                   ejecución.

- Mejor ajuste :: El sistema busca entre todos los bloques disponibles
                  cuál es el que mejor se ajusta al tamaño requerido
                  por el nuevo proceso. Esto requiere la revisión
                  completa de la lista de bloques.

- Peor ajuste :: El sistema busca cuál es el bloque más grande
                 disponible, y se lo asigna al nuevo
                 proceso. Empleando una estrucura de datos como un
                 /montículo/, esta operación puede ser incluso más
                 rápida que la de primer espacio.

La /fragmentación externa/ se produce cuando hay muchos bloques libres
entre bloques asignados a procesos; la /fragmentación interna/ se
refiere a la cantidad de memoria perdida por asuntos administrativos —
Por ejemplo, si el sistema operativo maneja /bloques/ de 512 bytes y
un proceso requiere 768 bytes para su ejecución, el sistema le
entregará 1024, desperdiciando 256.

Según análisis estadísticos (Silberschatz, p.289), por cada /N/
bloques asignados, se perderán del órden de /0.5N/ bloques por
fragmentación interna y externa.

*** Compactación

Un problema importante que va surgiendo como resultado de esta
fragmentación es que el espacio total libre de memoria puede ser mucho
mayor que lo que requiere un nuevo proceso, pero al estar partida en
muchos bloques, éste no encontrará una partición donde ser cargado.

Si los procesos emplean resolución de direcciones en tiempo de
ejecución, cuando el sistema operativo comience a detectar un alto
índice de fragmentación, puede lanzar una operación de /compresión/ o
/compactación/: Mover los contenidos en memoria de los procesos en
ejecución para que ocupen espacios contiguos, permitiendo unificar
varios bloques libres en uno solo.

#+attr_html: height="224"
#+attr_latex: width=0.5\textwidth
#+caption: Compactación de la memoria de procesos en ejecución (La Red, p.76)
[[./img/compactacion_memoria.png]]

La compactación tiene un costo alto — Involucra mover prácticamente la
totalidad de la memoria (probablemente más de una vez por bloque).

*** Intercambio con el almacenamiento secundario

Siguiendo de cierto modo la lógica requerida por la compactación
encontramos los sistemas que utilizan /intercambio/ (/swap/) entre la
memoria primaria y secundaria. En estos sistemas, el sistema operativo
puede /comprometer/ más espacio de memoria del que tiene físicamente
disponible. Cuando hay más procesos de los que caben en memoria, el
sistema suspende a uno de ellos y almacena una copia de su imagen en
memoria en almacenamiento secundario.

Hay algunas restricciones a observar previo a suspender un proceso. Un
proceso que tiene abierto alguna operación de entrada/salida en
curso. Una estrategia ante esto podría ser que todas las operaciones
se realicen únicamente a /buffers/ en el espacio del sistema operativo
y éste las transfiera al espacio del proceso interesado.

Esta técnica se popularizó en los sistemas de escritorio hacia fines
de los 1980 y principios de los 1990, en que las computadoras
personales tenían típicamente entre 1 y 8MB de memoria.

Recordemos que las unidades de disco son del órden de decenas de miles
de veces más lentas que la memoria, por lo que este proceso resulta
muy caro — Por ejemplo, si la imagen en memoria de un proceso es de
100MB, bastante conservador hoy en día, y la tasa de transferencia
sostenida al disco de 50MB/s, intercambiar un proceso al disco toma
dos segundos. Cargarlo de vuelta a memoria toma otros dos segundos — Y
a esto debe sumarse el tiempo de posicionamiento de la cabeza de
lectura/escritura, especialmente si el espacio a emplear no es
secuencial y contiguo. Resulta obvio por qué esta técnica ha caído en
desuso conforme aumenta el tamaño de los procesos.

** TODO Paginación
** TODO Segmentación
* TODO Memoria virtual
** TODO Concepto
** TODO Paginación
** TODO Segmentación
** TODO Paginación y segmentación combinadas
** TODO Reemplazo de páginas
** TODO Asignación de marcos e hiperpaginación
* TODO Consideraciones de seguridad
** TODO Bibliotecas de ligado estático y ligado dinámico
** TODO Secciones de texto no ejecutables
- Problemática con los programas /auto-relocalizables/
  (self-relocatable): ¿código auto-modificable?
** TODO Aleatorización de las direcciones
* Otros recursos

- [[http://www.hellion.org.uk/blog/posts/using-valgrind-on-xen-toolstacks/][Using Valgrind to debug Xen Toolstacks]] — Revisar, no sé si el texto
  propiamente sea del nivel adecuado. En todo caso, buscar algo de Valgrind.
- [[http://tech.slashdot.org/story/13/01/25/2146222/hacker-bypasses-windows-78-address-space-layout-randomization][Hacker Bypasses Windows 7/8 Address Space Layout Randomization]] (Slashdot)
- [[http://ghostbar.ath.cx/2013/01/27/less-swap/][Less swap]] (blog de Jose Luis Rivas) — Controlando el "swappiness" de
  Linux vía =vm.swappiness=
# My old X61 has 2G in RAM and 3G in Swap. It seems my using-habit for
# Google Chrome is heavy (more than 20 tabs open most of the time) so
# my swap is normally being used above the 1.8G-mark. That means, my
# disk is constantly being written and read, and since this is the
# original hard-drive scare comes to my mind: will I blow-up my disk
# if I continue doing this? and the heat this disk-use's generating
# was absurd.
#
# That's not good, at all, I prefer having cache used than swap; in
# Venezuela is not that easy to get a good sale on hard-drives (you
# know, is hard to get dollars here, since is illegal to buy them
# unless the govt gives you permission).
#
# So the first thing that comes to my mind is sysctl. If I wanted to
# cofigure swap it would be with a kernel parameter. So running sysctl
# -a | grep swap throws me vm.swappiness = 60, and a little google
# search tells me more about it.
#
# If the swappiness is close to 0 then it will use the swap only if it
# is really necessary, if it is close to 100 then it will use the swap
# aggressively. Mine was at 60, and it was really aggressive.
#
# The next steps for me was doing sudo echo 'vm.swappiness = 1' >>
# /etc/sysctl.conf && sudo sysctl -p.
#
# Now my system is really smooth and using Chrome + Terminal + Tmux +
# Rhythmbox is acceptable.
- [[http://troysunix.blogspot.mx/2011/07/process-memory-usage.html][Process memory usage]], ejemplos de pmap en diferentes Unixes
- [[http://www.adrien-revol.com/blog/index.php?post/2009/12/10/20-Linux-System-Monitoring-Tools][20 Linux system monitoring tools]], varias de ellas enfocadas a la
  memoria
- [[http://www.daemon-systems.org/man/pmap.1.html][Manual de pmap en NetBSD]], con varias opciones más
  explícitas/completas que las de Linux
