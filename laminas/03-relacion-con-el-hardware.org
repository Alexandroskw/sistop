#+SETUPFILE: ../setup_laminas.org
#+TITLE: Relación con el hardware: Estructuras y funciones básicas
#+DATE: 2013-08-13 — 2013-08-20

* Objetivo
** Objetivo de la presentación (1)
- Identificar los elementos arquitecturales principales del
  almacenamiento /primario/ y /secundario/ en un sistema /von Neumann/
- Conocer el principal mecanismos de comunicación y transferencia de
  datos entre ellos
- Familiarizarse con los principales conceptos (y magnitudes) de
  medición de rendimiento en este campo
** Objetivo de la presentación (2)
- Conocer los mecanismos principales por medio de los que se comunican
  el procesador y los dispositivos del sistema
- Conocer los términos y mecanismos principales por medio de los
  cuales un sistema ofrece multiprogramación
  - Comprender la diferencia entre los principales modelos de multiprocesamiento
- Comprender la necesidad de adoptar un modelo de programación que
  considere al verdadero multiprocesamiento
* Fronteras del CPU
** ¿Qué es un /sistema von Neumann/?
- Computadora /de programa almacenado/
  - En la /memoria principal/
  - /Mismo almacenamiento/ para el programa siendo ejecutado que para
    sus datos
- Todas las computadoras que empleamos hoy en día son, para fines
  prácticos, sistemas von Neumann[fn:: Aunque podrían caracterizarse
  como /Harvard modificadas/ partiendo desde un formalismo
  excesivo...]

** Implicaciones de /von Neumann/
- La arquitectura /no considera/ la existencia de almacenamiento /persistente/
  - Dentro del procesador hay algunas (¡pocas!) localidaes para
    almacenar datos /muy limitados/, para /trabajar directamente con
    ellos/ \rarrow /Registros/
  - La computadora cuenta únicamente con la /memoria de trabajo/
    \rarrow RAM, /almacenamiento primario/
  - El almacenamiento a largo plazo debe hacerse empleando
    controladores / mecanismos alternos, en medios específicos \rarrow
    /almacenamiento secundario/

** Los registros
#+BEGIN_CENTER
¿Qué son los registros?
#+END_CENTER
- Memoria super-rápida (hoy en día, sub-nanosegundo), ubicada /dentro/
  del procesador
- Manejada /por referencia directa/, no por dirección
- Además de los datos del proceso guardan su /estado/
- ¿Qué significa /gestionados por el compilador/?

** Procesadores basados en /acumuladores/
- Primeros procesadores: Uno o pocos /acumuladores/. Por ejemplo:
  - MOS 6502:
    - 1 acumulador (A) de 8 bits
    - 2 registros índice de 8 bits (X y Y)
    - 1 registro de estado del procesador (P), un apuntador al stack
      de 8 bits (S), un apuntador a instrucciones (PC) de 8 bits
  - Zilog Z80 e Intel 8086:
    - 14 registros (3 de 8 bits, el resto de 16)
    - Pero sólo uno era un acumulador de propósito general

** Ejemplo de acumuladores: Intel 8086/8088
#+latex: \begin{columns}\begin{column}{0.5\textwidth}
#+attr_latex: width=\columnwidth
#+caption: Imagen de Wikipedia
[[../img/registros_8086.png]]
#+latex: \end{column}\begin{column}{0.5\textwidth}
Registros /bandera/ (vector de booleanos): Overflow, Dirección,
Interrupción, Trampa/depuración, Signo, Cero, Acarreo auxiliar,
Paridad, Acarreo
#+latex: \end{column}\end{columns}

** Registros de /propósito general/: Legado de RISC
- Procesadores RISC: A partir de los 1980
- Planteamiento base de instrucciones /sencillas y regulares/
  - Fáciles de codificar en un procesador pequeño (en número de
    transistores)
  - La arquitectura RISC más conocida hoy: ARM
- Típicamente ≥32 registros /largos/ (32, 64bits) de propósito
  general
  - Mas algunos de propósito específico

** Tipos de almacenamiento
#+BEGIN_CENTER
¿Cómo representar y guardar /adecuadamente/ los datos e instrucciones?
#+END_CENTER
- La memoria rápida es muy cara
  - Pero aún así, mucho más lenta que el procesador: /Cuello de
    botella de von Neumann/ ([[https://dl.acm.org/citation.cfm?doid=359576.359579][Backus, 1977]])
- La memoria barata es muy lenta (/hasta 1000 veces/ más lenta que el procesador)
- El almacenamiento /a largo plazo/ es mucho más barato, pero
  muchísimo más lento
  - Los discos llegan a ser /miles a millones/ de veces más lentos que
    la memoria
- El avance en hardware /juega en contra/ de reducir la diferencia

** La memoria
- El procesador puede referirse directamente a los datos ubicados en
  la /memoria principal/ (/almacenamiento primario/)
  - Indicando su dirección (varias notaciones/mecanismos posibles)
  - Algunos procesadores permiten /realizar operaciones/ directamente
    sobre la memoria
    - Mayormente los basados en acumulador
- Memoria /caché/
  - Acelera operaciones aprovechando la /localidad de referencia/
  - Transparente a la programación (gestionada por el controlador)
  - Varios niveles de caché

** Jerarquía de almacenamiento (vista clásica/idealizada)
#+attr_latex: height=0.6\textheight
#+caption: Jerarquía de almacenamiento (Silberschatz, Galvin, Gagne; p. 11)
[[../img/jerarquia.png]]
** Jerarquía de almacenamiento (vista más real)
#+attr_latex: height=0.7\textheight
##+attr_latex: width=\textwidth
#+caption: La realidad de los niveles es menos rígida... (e incluso esta representación admite varias mejorías)
[[../img/dot/jerarquia_memoria.png]]
** ¿Tiempo de acceso? ¿Tasa de transferencia?
#+BEGIN_CENTER
Manejaremos muchas mediciones de velocidad. Debemos siempre tener en cuenta:
#+END_CENTER
- Tiempo de acceso :: ¿Cuánto tiempo toma /iniciar/ una
     transferencia? (medido en s, ms, ns). También llamado /latencia/.
- Tasa de transferencia :: Una vez iniciada, ¿a qué velocidad
     /sostenida/ podemos mantenerla? (medido en b/s, Kb/s, Mb/s)
#+BEGIN_CENTER
En el /mejor caso/, la transferencia de $x$ bits nos tomará $t_a +
xt_t$
#+END_CENTER
** Jerarquía de almacenamiento
#+BEGIN_CENTER
#+latex: {\scriptsize
#+caption: Velocidad y gestor de los principales niveles de memoria. (Silberschatz, Galvin, Gagne; p.28)
| Nivel           | 1                 | 2              | 3              | 4          |
|-----------------+-------------------+----------------+----------------+------------|
| *Nombre*        | Registros         | Cache          | Memoria princ. | Disco      |
| *Tamaño*        | <1KB              | <16MB          | <64GB          | >100GB     |
| *Tecnología*    | Multipuerto, CMOS | SRAM CMOS      | CMOS DRAM      | Magnética  |
| *Acceso (ns)*   | 0.25-0.5          | 0.5-25         | 80-250         | 5,000,000  |
| *Transf (MB/s)* | 20,000-100,000    | 5,000-10,000   | 1,000-5,000    | 20-150     |
| *Administra*    | Compilador        | Hardware       | Sist. Op.      | Sist. op.  |
| *Respaldado en* | Cache             | Memoria princ. | Disco          | CD o cinta |
#+latex: }
#+END_CENTER
** Almacenamiento /primario/ y /secundario/
- El procesador /sólo puede manejar directamente/ a la memoria
  principal
  - Se le conoce también como /almacenamiento primario/
- Discos, cintas, almacenamiento /estado sólido/ son /almacenamiento
  secundario/
  - Todas las computadoras lo manejan a través de /controladores/

* Conectando hacia afuera
** Canales y puentes
- Los componentes /no directamente referenciables/ de un sistema se
  comunican a través de /canales/ (/buses/)
  - Líneas de comunicación entre el procesador y el /chipset/
- Acomodo /muy frecuente/ en sistemas x86 actuales:
  - Puente norte (Northbridge) :: Conectado directamente al CPU,
       encargado de los buses de alta velocidad y los dispositivos
       fundamentales para el inicio del sistema — Memoria, video (AGP)
  - Puente sur (Southbridge) :: Controla el resto de los dispositivos
       del sistema; de él se desprenden varios buses (SCSI / SATA /
       IDE, PCI / PCIe, USB / Firewire, puertos /heredados/)

** Canales y puentes
#+attr_latex: height=\textheight, angle=90
#+caption: Diagrama de la comuniacación entre componentes de un sistema de cómputo basado en /puente norte/ y /puente sur/
[[../img/northbridge_southbridge.png]]

** ¿Por qué tantos canales?
- Frecuencia acorde a distintas categorías de dispositivos
  - Criterio económico: Más barato usar señalización más lenta
  - Distintos mecanismos de acceso
- Permitir transferencias paralelas, agregarlas conforme subimos la
  jerarquía
  - Jerarquizar la comunicación
- Pero... Cuando el sistema requiere transferir datos de o hacia
  dispositivos pasando por el mismo bus, frecuentemente ocurre
  *contención*
  - Algunos canales, como el USB, permiten /hasta 127/ dispositivos
    conectados /serialmente/

** Ejemplo: Chipset Intel 875 (2003)
#+attr_latex: width=1.1\textwidth
#+caption: Diagrama de la comuniacación entre componentes de un sistema de cómputo basado en el chipset Intel 875 (Pentium 4, 2003)
[[../img/dot/chipset_857.png]]

** Otros arreglos
- El ejemplo presentado es para un sistema de escritorio típico
  - Y bastante viejo ya
- En entornos de alto rendimiento, puede haber múltiples canales entre
  los componentes
  - Para reducir el impacto de la contención
  - Particularmente en los componentes con mayor demanda de ancho de banda
- En entornos móviles / de bajo costo, se hacen /concesiones/
  permitiendo mayor contención
  - P.ej. estructurar la comunicación a todos los periféricos
    alrededor del bus USB
  - Frecuente en equipos ARM

* Interrupciones y excepciones

** El procesador y los /eventos/ externos
- El procesador no tiene cómo reaccionar /internamente/ a eventos que
  ocurran en el sistema
- La ejecución es lineal: Avanza por la lista de instrucciones del
  programa
- Lo que permite el manejo de toda la E/S, interactividad,
  multiprogramación es el mecanismo de /interrupciones/ y
  /excepciones/.

** Interrupciones y excepciones

- Interrupción :: Todo evento recibido por el sistema, de origen
                  /externo/ al flujo de la ejecución
  - Actividad en la red
  - Teclado o mouse
  - Alarma del temporizador
  - Datos del disco listos

- Excepción :: Eventos inesperados originados por el flujo del
               proceso
  - División sobre cero
  - Instrucción ilegal
  - Acceso a memoria no direccionada
  - También conocidas como /trampas/ (/traps/)

** Manejo de interrupciones y excepciones
- Todo /evento/ es recibido por el sistema operativo (no por los
  procesos)
- Cuando ocurre cualquier /evento/, el hardware /lanza una
  interrupción/ que interrumpe el flujo de ejecución
- Rutina de /manejo de interrupciones/
  - Grabar estado del proceso desplazado y /cambiar contexto/
  - Atender la interrupción en /modo privilegiado/ (¡el menor tiempo
    posible!)
  - Una vez procesada, volver a invocar al /planificador/

** ¿Cuándo una interrupción es /no enmascarable/?
- Depende de la arquitectura y los objetivos del sistema
- Algunos ejemplos:
  - Error de paridad en la memoria (IBM PC)
  - Llamadas a hardware incompatible (primeros /clones/ de IBM;
    llamada atrapada y procesada por el manejador de interrupciones en
    el BIOS)
  - Diversas combinaciones de teclas para invocar a un reinicio (o
    lanzar un depurador)
  - Consolas de 8 bits (Nintendo NES): Bloquear modificaciones al
    buffer de pantalla durante el refresco vertical

** Acceso directo a memoria (DMA)
#+BEGIN_CENTER
Problema: En la sección de un proceso en que está /limitado por
entrada-salida/, la transferencia de información se vuelve cuello de
botella
#+END_CENTER
- Modo /entrada/salida programada/
- Gran cantidad y frecuencia de interrupciones
- Imposible realizar trabajo real
#+BEGIN_CENTER
Respuesta: /Acceso Directo a Memoria/
#+END_CENTER

** Acceso directo a memoria (DMA)
- Orientado a dispositivos de gran ancho de banda
  - Unidades de disco
  - Multimedia
  - Red
  - Memoria y caché
- Transferencia en bloques, empleando un /controlador/
  - Dirección física base de memoria
  - Cantidad de datos a transferir
  - /Puerto/ del dispositivo
  - Dirección de la transferencia (/desde/ o /hacia/ memoria)
- Limitante: Contención en el bus de memoria

** Coherencia de caché
#+BEGIN_CENTER
¿Qué problema puede causar una transferencia /no iniciada por el
procesador/?
#+END_CENTER
- Incongruencia entre la memoria real y /páginas/ de caché existentes
  - Caché coherente :: Mecanismos /en hardware/ que notifican a los
       controladores de caché que las páginas están /sucias/
  - No coherente :: El sistema operativo debe realizar esta operación
- Sistemas híbridos en lo relativo a la coherencia
  - Caché de nivel superior (en el procesador) no coherente, cachés
    inferiores coherentes

** Llamadas al sistema
- De cierto modo análogas/complementarias a las interrupciones
- Mecanismo para que un proceso /solicite un servicio/ al sistema
  operativo
- Cada sistema operativo /expone/ un diferente juego de llamadas al
  sistema a través de su API
- Es en buena medida lo que determina la /compatibilidad de código/
  entre sistemas operativos
  - Contraposición: Compatibilidad binaria
  - APIs implementados por diversos sistemas: POSIX, Win32

** Flujo de control en una llamada al sistema
#+attr_latex: width=\textwidth
#+caption: Transición del flujo entre espacio usuario y espacio núcleo en una llamada al sistema (Silberschatz, Galvin, Gagne; p.22)
[[../img/dot/llamada_al_sistema.png]]
** Tipos de llamadas al sistema (1)
#+BEGIN_CENTER
Lista incompleta, meramente ejemplificando
#+END_CENTER
- Control de procesos :: Crear o finalizar un proceso, obtener
     atributos del proceso, esperar cierto tiempo, asignar o liberar
     memoria, etc.

- Manipulación de archivos :: Crear, borrar o renombrar un archivo;
     abrir o cerrar un archivo existente; modificar sus /metadatos/;
     leer o escribir de un /descriptor de archivo/ abierto, etc.

** Tipos de llamadas al sistema (2)
#+BEGIN_CENTER
Lista incompleta, meramente ejemplificando
#+END_CENTER
- Manipulación de dispositivos :: Solicitar o liberar un dispositivo;
     leer, escribir o reposicionarlo, y otras varias. Muchas de estas
     llamadas son análogas a las de manipulación de archivos, y varios
     sistemas operativos las ofrecen como una sola.
- Mantenimiento de la información :: Obtener o modificar la hora del
     sistema; obtener detalles acerca de procesos o archivos, etc.

** Tipos de llamadas al sistema (3)
#+BEGIN_CENTER
Lista incompleta, meramente ejemplificando
#+END_CENTER
- Comunicaciones :: Establecer una comunicación con determinado
                    proceso (local o remoto), aceptar una solicitud de
                    comunicación de otro proceso, intercambiar
                    información sobre un canal establecido

- Protección :: Consultar o modificar la información relativa al
                acceso de objetos en el disco, otros procesos, o la
                misma sesión de usuario

** Depuración por /trazas/
- La mayor parte de los sistemas operativos ofrecen programas que
  ayudan a /depurar la ejecución/ de otros programas
- Pueden /envolver/ al API del sistema, y permitir seguir la /traza/
  (/trace/) de la ejecución de un proceso
- Por ejemplo:
  - =strace= en Linux
  - =truss= en Unixes históricos
  - =ktrace=, =kdump= en *BSD
  - =dtrace= en Solaris $\ge 10$ (2005)
- Permite entender /buena parte/ de lo que realiza un proceso —
  Prácticamente, toda su interacción con el sistema
  - A veces, demasiada información

** Ejemplo: =$ strace pwd=
#+begin_src c
execve("/bin/pwd", ["pwd"], [/* 43 vars */]) = 0
brk(0)                                  = 0x8414000
access("/etc/ld.so.nohwcap", F_OK)      = -1 ENOENT (No such file or directory)
mmap2(NULL, 8192, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0xb773d000
             (...)
getcwd("/home/gwolf/vcs/sistemas_operativos", 4096) = 36
fstat64(1, {st_mode=S_IFCHR|0620, st_rdev=makedev(136, 1), ...}) = 0
mmap2(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0xb773c000
write(1, "/home/gwolf/vcs/sistemas_operati"..., 36/home/gwolf/vcs/sistemas_operativos
) = 36
close(1)                                = 0
munmap(0xb773c000, 4096)                = 0
close(2)                                = 0
exit_group(0)                           = ?
#+end_src

* Multiprocesamiento
** Multiprocesamiento y multiprogramación
#+BEGIN_CENTER
Conceptos relacionados, empleados coloquialmente de forma
intercambiable, pero muy distintos:
#+END_CENTER
- Multiprogramación :: /Ilusión/ de estar ejecutando varios procesos
     al mismo tiempo, por medio de la /alternación rápidamente/ entre
     ellos
     - En un principio, no tan rápidamente; hoy en día, cientos a
       miles de veces por segundo
- Multiprocesamiento :: Entorno donde hay más de un procesador central
     (CPU).
     - Por muchos años, reservado a usos muy especializados
     - Hoy en día, la norma.

** Multiprogramación, multiprocesamiento, híbrido...
#+attr_latex: height=0.5\textheight
#+caption: Esquema de la ejecución de tres procesos en un sistema secuencial, multiprogramado, multiprocesado, e híbrido
[[../img/ditaa/multiproceso_y_multiprogramacion.png]]

** Formalizando un poco
- /Sólamente/ un sistema multiprocesador tiene la capacidad /real/ de
  atender /simultáneamente/ a diversos procesos
- Hoy en día es muy raro aplicar /de forma exclusiva/ a cualquiera de
  estas modalidades
  - Multiprogramado puro: Sigue siendo común en equipos
    no-multiprocesados
  - ...Pero cada vez son menos

** Acostumbrémonos, porque...
#+BEGIN_CENTER
El tema que más recurrentemente abordaremos en el curso es /la
complejidad/ que proviene tanto de la multiprogramación como de la
multitarea

Particularmente la abordaremos en las dos siguientes unidades:
/Administración de procesos/ y /Planificación de procesos/.
#+END_CENTER

** La irrupción del multiprocesamiento
- Existe desde los 1960
- Entornos de alto rendimiento, /muy especializados/
  - Requieren una programación hecha /con cuidado especial/
- Hace apenas 10-15 años, muchos sistemas operativos no detectaban
  siquiera más de un procesador
  - Incluso de rango servidor
  - Era muy raro encontrarlos en hardware de uso frecuente
- Pero hacia el 2005... Nos alcanzó Gordon E. Moore

** ¿Gordon E. Moore?
- Ingeniero electrónico, fundador de /Fairchild Semiconductor/
- Publicó en 1965 /[[http://cs.utexas.edu/~fussell/courses/cs352h/papers/moore.pdf][Cramming more components onto integrated circuits]]/
  (/Apretujando más componentes en circuitos integrados/)
- Observando el desarrollo desde 1959, predice que cada año se
  duplicará la cantidad de transistores en los circuitos integrados,
  al menos por los próximos 10 años

** La Ley de Moore, 1965
#+attr_latex: height=0.7\textheight
#+caption: La /Ley de Moore/, en su artículo publicado en 1965, prediciendo la miniaturización por diez años
[[../img/moore_orig.png]]

** La Ley de Moore, hoy
#+latex: \begin{columns}\begin{column}{0.7\textwidth}
#+attr_latex: height=0.9\textheight
[[../img/gnuplot/ley_de_moore.png]]
#+latex: \end{column}\begin{column}{0.3\textwidth}
#+BEGIN_CENTER
Y a cinco decadas, la Ley de Moore se sigue cumpliendo...
#+END_CENTER
#+latex: \end{column}\end{columns}

** ¿Moore y el multiprocesamiento?
#+BEGIN_CENTER
¿Qué tiene que ver la Ley de Moore y el multiprocesamiento?
#+END_CENTER
- Hasta $\approx 2005$, la velocidad de los CPUs crecía constantemente
  - En el ámbito comercial, excediendo los 3 GHz
  - Llevando a problemas serios de calentamiento
- El diferencial de velocidad con el acceso a memoria crece cada vez
  más
- Hace falta un cambio de estrategia...

** Chips multiprocesador
- Los principales fabricantes de CPUs comenzaron a diseñar chips
  conteniendo más de un /núcleo/ — Esto es, más de un CPU independiente
  - (Y algunas facilidades adicionales — Por ejemplo, mucho mayor
    caché /dentro del mismo/ chip)
- El reloj de los procesadores no sólo no ha crecido, sino que en
  general /se ha reducido/ a cerca de 1GHz
  - Obviamente, el rendimiento y la densificación siguen avanzando
- Pero ahora la ganancia de velocidad ya no llega en automático con el
  nuevo hardware
  - El sistema operativo tiene que saber /aprovechar/ al
    multiprocesamiento

** ¿Cómo multiprocesamos?
#+BEGIN_CENTER
Hoy en día, cuando hablamos de multiprocesamiento, /casi/ siempre
hablamos de multiprocesamiento simétrico
\vfill

...Pero no es el único tipo de multiprocesamiento que hay
#+END_CENTER

** Multiprocesamiento simétrico (SMP)
- Todos los procesadores /son iguales/
- Pueden realizar las mismas operaciones en el mismo tiempo
- Un proceso podría /migrarse/ de un procesador a otro de forma
  transparente
  - Únicamente manteniendo información básica
- Tienen /acceso a la misma memoria/
  - Aunque cada uno puede tener su propio caché) \rarrow
    *¡Necesidad de coherencia!*

** Multiprocesamiento asimétrico
#+BEGIN_CENTER
Puede haber varios puntos de asimetría:
#+END_CENTER
- Distinta /arquitectrura/ \arrow Típicamente algunos se dedicarán a una
  tarea específica
- Coprocesadores, o procesadores coadyuvantes
  - Caso de las tarjetas gráficas (GPUs)
  - Podrían verse /casi/ como una red alta velocidad de computadoras
    /independientes/
- Memoria y responsabilidades muy distintas a las del sistema central

** Acceso no-uniforme a memoria (NUMA)
#+BEGIN_CENTER
(/Non-Uniform Memory Access/)
#+END_CENTER
- Procesadores de la misma arquitectura/tipo
  - Podrían formar parte de un sistema SMP
- Pero con /afinidad/ a bancos específicos de memoria
  - Memoria /cercana/ o /lejana/
  - Al /planificar/ los procesos, se destinan los procesadores cercanos
  - Hay un /canal compartido/ de memoria
- Típicamente computadoras grandes con /nodos/ o /blades/
- Pueden ubicarse como en un punto medio entre SMP y el /cómputo
  distribuído/
  - Cómputo distribuído fuertemente acoplado

** Más allá: Cómputo distribuído
- Distribuir un proceso de cómputo para ser realizado /entre
  computadoras independientes
  - Más formalmente: Entre procesadores /que no comparten memoria/
    (almacenamiento primario)
- Dos modalidades principales (mas un /adosado/):
  - Cúmulos (/clusters/)
  - Mallas (/grids/)
  - Cómputo /en la nube/

** Cúmulos (clusters)
- Computadoras conectadas por una red local de alta velocidad
- Cada una corre su propia instancia de sistema operativo y programas
- Principales orientaciones:
  - Alto rendimiento :: Cómputo matemático, cálculos...
  - Alta disponibilidad :: Prestación de servicios críticos
  - Balanceo de cargas :: Atención a solicitudes complejas, que pueden
       saturar a servidores individuales
- Típicamente son equipos homogéneos y dedicados
- Muy comunes en universidades; bajo costo, altas prestaciones

** Mallas (grids)
- Computadoras distribuidas geográficamente
- Conectadas sobre Internet (o redes de área amplia)
- Pueden ser heterogéneas (en capacidades y en arquitectura)
- Presentan /elasticidad/ para permitir conexiones/desconexiones de
  nodos en el tiempo de vida de un cálculo
#+BEGIN_CENTER
¿Quién quiere presentar el ejemplo de alguna malla?
#+END_CENTER

** Cómputo en la nube
- Abordaremos el tema de nuevo tras hablar de la /virtualización/
- Caso específico y /de moda/
- Partición de recursos (/cliente-servidor/)
- Orientado a la /tercerización/ de servicios específicos
- La /implementación/ de un servicio deja de ser relevante \rarrow
  Procesos /opacos/
- Conceptos relacionados:
  - /Servicios Web/
  - Plataforma como servicio (/PaaS/)
  - Software como servicio (/SaaS/)
  - Infraestructura como servicio (/IaaS/)

* Conceptos nuevos
** En esta presentación vimos...
- Jerarquía de almacenamiento
  - Registros
    - Acumulador
    - Propósito general (RISC)
  - Memoria principal o almacenamiento primario
    - /Cuello de botella de von Neumann/
    - Caché
- Tiempo de acceso, tasa de transferencia
- Comunicación con dispositivos a través de /canales/
  - Arquitectura ejemplo: x86 con /Northbridge/ y /Southbridge/
  - Contención

** En esta presentación vimos...
- Interrupciones y excepciones
  - Mecanismo para interrumpir/desviar la ejecución lineal del
    procesador
  - Interrupción: Externo al flujo de ejecución; Excepción: originada
    por el flujo del proceso
  - Presentación de los /manejadores de interrupciones/
  - Acceso directo a memoria
    - Coherencia de caché
- Llamadas al sistema
  - API del sistema operativo; compatibilidad de código (¡no binaria!)
  - Categorías de llamada al sistema
  - Depuración por trazas

** En esta presentación vimos...
- Multiprogramación y multiprocesamiento
  - ¿Por qué nos es inescapable? \rarrow Ley de Moore
- Tipos de multiprocesamiento
  - Simétrico
  - Asimétrico
  - NUMA
- Cómputo distribuído
  - Cúmulos (/clusters/)
  - Mallas (/grids/)
  - /La nube/
