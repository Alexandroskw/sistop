#+SETUPFILE: ../setup_laminas.org
#+TITLE: Administración de procesos: Primitivas de sincronización
#+DATE: 2013-02-13 — 2013-02-??

* ¿Qué queremos evitar?
** Concurrencia
- No tenemos que preocuparnos cuando todos los datos que maneja un
  hilo son /locales/
- Al utilizar /variables globales/ o recursos externos, debemos
  recordar que el planificador puede interrumpir el flujo /en
  cualquier momento/
- No tenemos garantía del ordenamiento que obtendremos

** Los problemas de la concurrencia (1)
#+latex: \begin{columns}\begin{column}{0.5\textwidth}
#+BEGIN_SRC ruby
class EjemploHilos
  def initialize
    @x = 0
  end
  def f1
    sleep 0.1
    print '+'
    @x += 3
  end
#+end_src
#+latex: \end{column} \begin{column}{0.5\textwidth}
#+begin_src ruby
  def f2
    sleep 0.1
    print '*'
    @x *= 2
  end
  def run
    t1 = Thread.new {f1}
    t2 = Thread.new {f2}
    sleep 0.1
    print '%d ' % @x
  end
end
#+END_SRC
#+latex: \end{column}\end{columns}
#+begin_src ruby
>> e = EjemploHilos.new;10.times{e.run}
0 *+3 *+9 *+21 +*48 *+99 +*204 *+411 +*828 *+1659

>> e = EjemploHilos.new;10.times{e.run}
+0 *+6 *+*18 42 +*+90 **186 +375 +**756 ++1515 *3036
#+end_src

** Los problemas de la concurrencia (2)
- No son dos hilos compitiendo por el acceso a la variable
  - Son tres
  - El /jefe/ también entra en la competencia a la hora de imprimir
- A veces, el órden de la ejecución es (¿parece ser?) =(@x *2) + 3=,
  a veces =(@x + 3) * 2=
  - A veces la impresión ocurre en otro órden: =+**756= o =++1515=
- Esto porque tenemos una /condición de carrera/ en el acceso a la
  variable compartida

** Condición de carrera (Race condition)
- Error de programación
- Implica a dos procesos (o hilos)
- Fallan al comunicarse su estado mutuo
- Lleva a /resultados inconsistentes/
  - Problema muy común
  - Difícil de depurar
- Ocurre por no considerar la /no atomicidad/ de una operación
- *Categoría importante de fallos de seguridad*

** Operación atómica
- Operación que tenemos la garantía que se ejecutará /o no/ como /una
  sóla unidad de ejecución/
- /No implica/ que el sistema no le retirará el flujo de ejecución
  - /El efecto de que se le retire el flujo/ no llevará a
    comportamiento inconsistente.
  - Requiere sincronización /explícita/ entre los procesos que la realicen

** Sección crítica
Es el área de código que:
- Realiza el acceso (¿modificación? ¿lectura?) de datos compartidos
- Requiere /ser protegida de accesos simultáneos/
- Dicha protección tiene que ser implementada /siempre, y
  manualmente/ por el programador
  - Identificarlas requiere inteligencia
- Debe ser protegida /empleando mecanismos atómicos/
  - Si no, el problema podría aminorarse — Pero no prevenirse
  - ¡Cuidado con los accesos casi-simultáneos!

** Bloqueo mutuo
#+BEGIN_CENTER
Algunos autores lo presentan como /interbloqueo/.

En inglés, /deadlock/
#+END_CENTER
- Dos o más procesos poseen determinados recursos
- Cada uno de ellos queda detenido esperando a alguno de los que tiene
  otro

** Bloqueo mutuo
#+attr_latex: width=0.5\textwidth
#+caption: Esquema clásico de un bloqueo mutuo simple: Los procesos /A/ y /B/ esperan mutuamente para el acceso a las unidades /1/ y /2/.

#+begin_src dot :exports results :file ltxpng/bloqueo_mutuo_simple.png
digraph G {
	layout = circo;

	A [label = "Proceso\nA"];
	B [label = "Proceso\nB"];
	1 [label = "Unidad\n1", shape = box];
	2 [label = "Unidad\n2", shape = box];

	A -> 1 [label = "Asignada"];
	B -> 2 [label = "Asignada"];
	A -> 2 [label = "Solicitada", style = dotted];
	B -> 1 [label = "Solicitada", style = dotted];
}
#+end_src
#+results:
[[file:ltxpng/bloqueo_mutuo_simple.png]]

** Bloqueo mutuo
- El sistema operativo puede seguir procesando normalmente
  - Pero ninguno de los procesos involucrados puede avanzar
  - ¿Única salida? Que el administrador del sistema interrumpa a
    alguno de los procesos
    - …Implica probable pérdida de información

** Inanición
#+BEGIN_CENTER
En inglés, /resource starvation/
#+END_CENTER
- Situación en que uno o más procesos están atravesando exitosamente
  una sección crítica
  - Pero el flujo no permite que otro proceso, posiblemente de otra
    clase, entre a dicha sección
- El sistema continúa siendo productivo, pero uno de los recursos
  puede estar detenido por un tiempo arbitrariamente largo.

** Primer acercamiento: /Reservas de autobús/
#+BEGIN_CENTER
¡Inseguro! ¿Qué hizo el programador bien? ¿qué hizo mal?
#+END_CENTER
#+begin_src perl
my ($proximo_asiento :shared, $capacidad :shared, $bloq :shared);
$capacidad = 40;
sub asigna_asiento {
  while ($bloq) { sleep 0.1; }
  $bloq = 1;
  if ($proximo_asiento < $capacidad) {
    $asignado = $proximo_asiento;
    $proximo_asiento += 1;
    print "Asiento asignado: $asignado\n";
  } else {
    print "No hay asientos disponibles\n";
    return 1;
  }
  $bloq = 0;
  return 0;
}
#+end_src
#+BEGIN_CENTER
/Tip/: Sección crítica entre las líneas 6 y 8 (¿o hasta 14?)
#+END_CENTER

** ¿Por qué es inseguro el ejemplo anterior?
#+BEGIN_CENTER
Líneas 4 y 5:
#+END_CENTER
- Espera activa (/spinlock/): Desperdicio de recursos
  - Aunque esta espera activa lleva dentro un =sleep=, sigue siendo
    espera activa.
  - Eso hace que el código sea /poco considerado/ — No que sea inseguro
- ¿Quién protege a =$bloq= de modificaciones no-atómicas?

** Las secciones críticas deben protegerse a otro nivel
- Las primitivas que empleemos para sincronización /deben ser
  atómicas/
- La única forma de asegurar su atomicidad es /implementándolas a un
  nivel más bajo/ que el del código que deben proteger
  - (Al menos) el proceso debe implementar la protección entre hilos
  - (Al menos) el sistema operativo debe implementar la protección
    entre procesos

* Primitivas de sincronización
** Requisitos para las /primitivas/
- Implementadas a un nivel más bajo que el código que protegen
  - Desde el sistema operativo
  - Desde bibliotecas de sistema
  - Desde la máquina virtual (p.ej. JVM)
- ¡No las implementes tú mismo!
  - Parecen conceptos simples... Pero no lo son
  - Utilicemos el conocimiento acumulado de medio siglo
** Mutex
- Contracción de /Mutual Exclusion/, exclusión mutua
- Un mecanismo que asegura que la región protegida del código se
  ejecutará como si fuera atómica
  - /No garantiza que el planificador no interrumpa/ — Eso rompería el
    multiprocesamiento preventivo.
  - Requiere que /cada hilo o proceso/ implemente (¡y respete!) al
    mutex
- Mantiene en espera a los procesos adicionales que quieran emplearlo
  - Sin garantizar ordenamiento
- Ejemplo: La llave del baño en un entorno de oficina mediana
** Semáforos
- Propuestos por Edsger Djikstra (1965)
- Estructuras de datos simples para la sincronización y (muy
  limitada) comunicación entre procesos
  - ¡Increíblemente versátiles para lo limitado de su interfaz!
- Se han publicado muchos patrones basados en su interfaz, modelando
  interacciones muy complejas

** Las tres operaciones de los semáforos
- Inicializar :: Puede inicializarse a cualquier valor entero. Una
                   vez inicializado, el valor /ya no puede ser leído/.
- Decrementar :: Disminuye en 1 el valor del semáforo. Si el
                 resultado es negativo, el hilo /se bloquea/ y no
                 puede continuar hasta que /otro hilo/ incremente
                 al semáforo.

		 Puede denominarse =wait=, =down=, =acquire=, =P=
                 (/proberen te verlagen/, /intentar decrementar/)
- Incrementar :: Incrementa en 1 el valor del semáforo. Si hay
                 hilos esperando, uno de ellos es despertado.

		 Puede denominarse =signal=, =up=, =release=,
                 =post= o =V= (/verhogen/, /incrementar/).

** Los semáforos en C (POSIX pthreads)

#+begin_src C
int sem_init(sem_t *sem, int pshared, unsigned int value);
int sem_post(sem_t *sem);
int sem_wait(sem_t *sem);
int sem_trywait(sem_t *sem);
#+end_src

- =pshared= indica si se compartirá entre procesos o sólo entre hilos
  (por optimización de estructuras)
- =sem_trywait= extiende la interfaz de Djikstra: Verifica si el
  semáforo puede ser decrementado, pero en vez de bloquearse, regresa
  al invocante un error
  - El proceso /debe tener la lógica/ para no proceder a la sección
    crítica

** Problemática con mutexes y semáforos
- No sólo hay que encontrar el mecanismo correcto para proteger
  nuestras secciones críticas
  - hay que /implementarlo correctamente/
  - La semántica de paso de mensajes por esta vía puede ser confusa
- Un encapsulamiento /más claro/ puede reducir problemas
- Puede haber procesos que compitan por recursos /de forma hostil/

** Competencia hostil por recursos
#+BEGIN_CENTER
Qué pasa si en vez de esto:
#+END_CENTER
#+BEGIN_SRC C
sem_wait(semaforo);
seccion_critica();
sem_post(semaforo);
#+END_SRC
#+BEGIN_CENTER
Tenemos esto:
#+END_CENTER
#+BEGIN_SRC C
while (sem_trywait(semaforo) != 0) {}
seccion_critica();
sem_post(semaforo);
#+END_SRC

** La estupidez humana puede ser infinita
#+BEGIN_SRC C
/* Mecanismo de protección: Crucemos los dedos... */
/* A fin de cuentas, corremos con baja frecuencia! */
seccion_critica();
#+END_SRC

** Monitores
- Estructuras abstractas (/ADTs/ u /objetos/) provistas por el lenguaje
  o entorno de desarrollo
- /Encapsulan/ tanto a los datos /como a las funciones que los pueden
  manipular/
- Impiden el acceso directo a las funciones potencialmente peligrosas
- /Exponen/ una serie de /métodos públicos/
  - Y pueden implementar /métodos privados/
- Al no presentar una interfaz que puedan /subvertir/, aseguran que
  todo el código que asegura el /acceso concurrente seguro/ es empleado
- Pueden ser presentados como /bibliotecas/

** Visión esquemática de los monitores
#+attr_latex: width=0.6\textwidth
#+caption: Vista esquemática de un monitor. No es ya un conjunto de procedimientos aislados, sino que una abstracción que permite realizar únicamente las operaciones públicas sobre datos encapsulados. (Silberschatz, p.239)
[[../img/monitor.png]]

** Monitores en Java
#+BEGIN_CENTER
/Java/ implementa sincronización vía monitores entre hilos como una
propiedad de la declaración de método, y lo implementa directamente en
la JVM. (Silberschatz):
#+END_CENTER
#+begin_src java
public class SimpleClass {
  // . . .
  public synchronized void safeMethod() {
    /* Implementation of safeMethod() */
  // . . .
  }
}
#+end_src
La JVM implementa:
- Mutexes a través de la declaración =synchronized=
- /variables de condición/
- Una semántica parecida (¡no idéntica!) a la de semáforos con =var.wait()= y =var.signal()=
#+END_CENTER

** Soluciones en hardware
- Decimos una y otra vez que /la concurrencia está aquí para quedarse/
- El hardware especializado para cualquier cosa (interrupciones, MMU,
  punto flotante, etc.) es siempre caro, hasta que baja de precio
- ¿No podría el hardware ayudarnos a implementar operaciones atómicas?
#+begin_center
Veamos algunas estrategias
#+end_center

** Inhabilitación de interrupciones
#+begin_center
Efectivamente evita que las secciones críticas sean interrumpidas,
pero...
#+end_center
- Inútil cuando hay multiprocesamiento real
  - A menos que detenga también la ejecución en los demás CPUs
- Matar moscas a cañonazos
- Inhabilita el multiproceso preventivo
  - Demasiado peligroso

** Instrucciones atómicas /reales/: =test_and_set= (1)
   Siguiendo una implementación /en hardware/ correspondiente a:
   #+BEGIN_SRC C
   boolean test_and_set_lock(int i) {
       if (i == 0) {
           i = 1;
           return true;
       } else return false;
   }
   void free_lock(int i) {
       if (i == 1) i = 0;
   }
   #+END_SRC

** Instrucciones atómicas /reales/: =test_and_set= (2)
   Bastaría con:
   #+begin_src C
   while (test_and_set(candado)) {}
   seccion_critica();
   free_lock(candado);
   #+end_src

   #+begin_center
   ¿Qué problema le vemos?
   #+end_center

** Problemas con =test_and_set=
- Espera activa
  - Se utiliza sólo en código no interrumpible (p.ej. gestor de
    interrupciones en el núcleo)
- Código no portable
- Imposible de implementar en arquitecturas RISC limpias
  - Doble acceso a memoria en una sóla instrucción
  - ...Muy caro de implementar en arquitecturas CISC
- Susceptible a problemas de coherencia de cache

** Memoria transaccional
- Idea base: Semántica de bases de datos en el acceso a memoria
- Permite agrupar varias operaciones en una sóla /transacción/
  - Una vez terminada, /confirmar/ (/commit/) todos los cambios
  - O, en caso de error, /rechazarlos/ (/rollback/)
- Si algún otro proceso modifica alguna de las localidades en
  cuestión, el proceso se /rechaza/
- Toda lectura de memoria antes de /confirmar/ entrega los datos
  previos

** Memoria transaccional: Ejemplo de semántica
   #+BEGIN_SRC C
   do {
       begin_transaction();
       var1 = var2 * var3;
       var3 = var2 - var1;
       var2 = var1 / var2;
   } while (! commit_transaction());
   #+END_SRC

   Ejemplo poco eficiente, elegido meramente por claridad: Efectúa
   múltiples cálculos dentro de una espera activa efectiva

** Semántica de memoria transaccional en software (STM)
- Implementaciones como la mencionada disponibles en varios lenguajes
- Computacionalmente caras
  - Invariablemente /mucho/ más lentas
  - Y menos eficientes en espacio
  - ...Pero en hardware tampoco serían mucho más baratas — y sí
    tendrían restricciones (en tamaño o cantidad de transacciones
    simultáneas)
- Puede llevar a inconsistencias si implican /cualquier estructura/
  fuera del control de la transacción (archivos, dispositivos, IPC)
- Construcción poderosa (¡y cómoda!)

* Patrones basados en semáforos
** Señalizar
- Un hilo debe informar a otro que cierta condición está cumplida
- Ejemplo: Un hilo prepara una conexión en red mientras el otro
  prepara los datos a enviar
  - No podemos arriesgarnos a comenzar la transmisión hasta que la
    conexión esté lista
#+latex: \begin{columns}\begin{column}{0.5\textwidth}
#+begin_src python
# Antes de lanzar los hilos
senal = Semaphore(0)

def prepara_conexion():
  crea_conexion()
  senal.release()
#+end_src
#+latex: \end{column} \begin{column}{0.5\textwidth}
#+begin_src python
def envia_datos():
  calcula_datos()
  senal.acquire()
  envia_por_red()
#+end_src
#+latex: \end{column}\end{columns}

** /Rendezvous/
- Nombre tomado del francés para /preséntense/ (utilizado ampliamente
  en inglés para /tiempo y lugar de encuentro/)
- Dos hilos deben esperarse mutuamente en cierto punto para continuar
  en conjunto
  - Empleamos dos semáforos
- Por ejemplo, en un GUI:
  - Un hilo prepara la interfaz gráfica y actualiza sus eventos
  - Otro hilo efectúa cálculos para mostrar
  - Queremos mostrar la simulación desde el principio, no debe iniciar
    el cálculo antes de que haya una interfaz mostrada
  - No queremos que la interfaz se presente en blanco

** /Rendesvous/
#+latex: \begin{columns}\begin{column}{0.5\textwidth}
#+begin_src python
guiListo = Semaphore(0)
calculoListo = Semaphore(0)
threading.Thread(target=maneja_gui, args=[]).start()
threading.Thread(target=maneja_calculo, args=[]).start()
def maneja_gui():
  inicializa_gui()
  guiListo.release()
  calculoListo.acquire()
  recibe_eventos()
#+end_src
#+latex: \end{column} \begin{column}{0.5\textwidth}
#+begin_src python
def maneja_calculo():
  inicializa_datos()
  calculoListo.release()
  guiListo.acquire()
  procesa_calculo()
#+end_src
#+latex: \end{column}\end{columns}

** Mutex
Un mutex puede implementarse con un semáforo inicializado a 1:
#+begin_src python
mutex = Semaphore(1)
# ...Inicializamos estado y lanzamos hilos
mutex.acquire()
# Estamos en la region de exclusion mutua
x = x + 1
mutex.release()
# Continua la ejecucion paralela
#+end_src
** Multiplex
** Torniquete
** Apagador
** Barrera
** Cola

* Abordando los problemas clásicos
